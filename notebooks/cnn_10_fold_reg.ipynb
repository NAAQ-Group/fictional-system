{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dd27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Activation, GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import HeNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1865543",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "num_epochs = 100\n",
    "num_batch_size = 256\n",
    "dataset_path = './audio/'\n",
    "metadata = pd.read_csv('./metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f31c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=num_rows)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file:\", file_name)\n",
    "        return None\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f46854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode outside the loop for consistency\n",
    "le = LabelEncoder()\n",
    "le.fit(metadata[\"class\"])\n",
    "num_labels = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b51c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store accuracy of each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "# Save model and track training accuracy\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a9cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = metadata[metadata['fold'] == 1]\n",
    "data_2 = metadata[metadata['fold'] == 2]\n",
    "data_3 = metadata[metadata['fold'] == 3]\n",
    "data_4 = metadata[metadata['fold'] == 4]\n",
    "data_5 = metadata[metadata['fold'] == 5]\n",
    "data_6 = metadata[metadata['fold'] == 6]\n",
    "data_7 = metadata[metadata['fold'] == 7]\n",
    "data_8 = metadata[metadata['fold'] == 8]\n",
    "data_9 = metadata[metadata['fold'] == 9]\n",
    "data_10 = metadata[metadata['fold'] == 10]\n",
    "data_folds = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2c2274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>101415-3-0-2.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>101415-3-0-3.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>101415-3-0-8.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>102106-3-0-0.wav</td>\n",
       "      <td>102106</td>\n",
       "      <td>2.243852</td>\n",
       "      <td>3.884477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>102305-6-0-0.wav</td>\n",
       "      <td>102305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.611610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>gun_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>99180-9-0-2.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>99180-9-0-36.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>99180-9-0-48.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>99180-9-0-49.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>99180-9-0-7.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       slice_file_name    fsID      start        end  salience  fold  classID  \\\n",
       "64    101415-3-0-2.wav  101415   1.000000   5.000000         1     1        3   \n",
       "65    101415-3-0-3.wav  101415   1.500000   5.500000         1     1        3   \n",
       "66    101415-3-0-8.wav  101415   4.000000   8.000000         1     1        3   \n",
       "105   102106-3-0-0.wav  102106   2.243852   3.884477         2     1        3   \n",
       "106   102305-6-0-0.wav  102305   0.000000   2.611610         1     1        6   \n",
       "...                ...     ...        ...        ...       ...   ...      ...   \n",
       "8676   99180-9-0-2.wav   99180   1.000000   5.000000         1     1        9   \n",
       "8677  99180-9-0-36.wav   99180  18.000000  22.000000         1     1        9   \n",
       "8678  99180-9-0-48.wav   99180  24.000000  28.000000         1     1        9   \n",
       "8679  99180-9-0-49.wav   99180  24.500000  28.500000         1     1        9   \n",
       "8680   99180-9-0-7.wav   99180   3.500000   7.500000         1     1        9   \n",
       "\n",
       "             class  \n",
       "64        dog_bark  \n",
       "65        dog_bark  \n",
       "66        dog_bark  \n",
       "105       dog_bark  \n",
       "106       gun_shot  \n",
       "...            ...  \n",
       "8676  street_music  \n",
       "8677  street_music  \n",
       "8678  street_music  \n",
       "8679  street_music  \n",
       "8680  street_music  \n",
       "\n",
       "[873 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0c79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_set(dataframe):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=\"Extracting features\"):\n",
    "        file_path = os.path.join(dataset_path, f\"fold{row['fold']}\", row[\"slice_file_name\"])\n",
    "        class_label = row[\"class\"]\n",
    "        data = extract_features(file_path)\n",
    "        if data is not None:\n",
    "            features.append([data, class_label])\n",
    "            labels.append(row[\"class\"])\n",
    "    featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "    return features, featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee05e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 831/873 [01:10<00:02, 20.47it/s]C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "Extracting features:  96%|█████████▌| 834/873 [01:10<00:01, 21.78it/s]C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "Extracting features: 100%|██████████| 873/873 [01:12<00:00, 12.06it/s]\n",
      "Extracting features: 100%|██████████| 888/888 [01:05<00:00, 13.57it/s]\n",
      "Extracting features: 100%|██████████| 925/925 [01:01<00:00, 15.04it/s]\n",
      "Extracting features: 100%|██████████| 990/990 [01:13<00:00, 13.41it/s]\n",
      "Extracting features: 100%|██████████| 936/936 [01:04<00:00, 14.49it/s]\n",
      "Extracting features: 100%|██████████| 823/823 [00:54<00:00, 14.98it/s]\n",
      "Extracting features: 100%|██████████| 838/838 [01:01<00:00, 13.59it/s]\n",
      "Extracting features: 100%|██████████| 806/806 [01:03<00:00, 12.67it/s]\n",
      "Extracting features: 100%|██████████| 816/816 [01:05<00:00, 12.51it/s]\n",
      "Extracting features: 100%|██████████| 837/837 [01:14<00:00, 11.24it/s]\n"
     ]
    }
   ],
   "source": [
    "features_1, featuresdf_1 = extract_set(data_1)\n",
    "features_2, featuresdf_2 = extract_set(data_2)\n",
    "features_3, featuresdf_3 = extract_set(data_3)\n",
    "features_4, featuresdf_4 = extract_set(data_4)\n",
    "features_5, featuresdf_5 = extract_set(data_5)\n",
    "features_6, featuresdf_6 = extract_set(data_6)\n",
    "features_7, featuresdf_7 = extract_set(data_7)\n",
    "features_8, featuresdf_8 = extract_set(data_8)\n",
    "features_9, featuresdf_9 = extract_set(data_9)\n",
    "features_10, featuresdf_10 = extract_set(data_10)\n",
    "\n",
    "all_features = [features_1, features_2, features_3, features_4, features_5, features_6, features_7, features_8, features_9, features_10]\n",
    "\n",
    "all_features_df = [featuresdf_1, featuresdf_2, featuresdf_3, featuresdf_4, featuresdf_5, featuresdf_6, featuresdf_7, featuresdf_8, featuresdf_9, featuresdf_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b46606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-525.06586, -519.55695, -518.64276, -518.897...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-524.8159, -521.7542, -520.1264, -521.55524,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-133.84369, -161.87689, -246.68976, -244.979...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-268.53568, -244.676, -250.90111, -222.67284...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-145.07484, -90.33111, -93.73102, -105.46187...</td>\n",
       "      <td>gun_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>[[-156.50749, -163.36191, -215.15918, -218.828...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>[[-123.989105, -134.89343, -156.30284, -154.51...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>[[-162.53307, -154.248, -156.98843, -153.72377...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>[[-101.44252, -102.41235, -158.99976, -152.564...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>[[-114.2226, -120.25398, -177.69623, -183.1599...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature   class_label\n",
       "0    [[-525.06586, -519.55695, -518.64276, -518.897...      dog_bark\n",
       "1    [[-524.8159, -521.7542, -520.1264, -521.55524,...      dog_bark\n",
       "2    [[-133.84369, -161.87689, -246.68976, -244.979...      dog_bark\n",
       "3    [[-268.53568, -244.676, -250.90111, -222.67284...      dog_bark\n",
       "4    [[-145.07484, -90.33111, -93.73102, -105.46187...      gun_shot\n",
       "..                                                 ...           ...\n",
       "868  [[-156.50749, -163.36191, -215.15918, -218.828...  street_music\n",
       "869  [[-123.989105, -134.89343, -156.30284, -154.51...  street_music\n",
       "870  [[-162.53307, -154.248, -156.98843, -153.72377...  street_music\n",
       "871  [[-101.44252, -102.41235, -158.99976, -152.564...  street_music\n",
       "872  [[-114.2226, -120.25398, -177.69623, -183.1599...  street_music\n",
       "\n",
       "[873 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27848e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data to get consistent label encoding\n",
    "all_labels = [label for df in all_features_df for label in df['class_label']]\n",
    "le = LabelEncoder()\n",
    "le.fit(all_labels)  # Fit once across all data\n",
    "\n",
    "X_folds = []\n",
    "y_folds = []\n",
    "\n",
    "for features_df in all_features_df:\n",
    "    X = np.array(features_df['feature'].tolist())\n",
    "    y = le.transform(features_df['class_label'])  # Encode\n",
    "    y = to_categorical(y)  # One-hot\n",
    "    X_folds.append(X)\n",
    "    y_folds.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c01c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=2, input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7576162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(fold_number):\n",
    "    test_x = X_folds[fold_number - 1]\n",
    "    test_y = y_folds[fold_number - 1]\n",
    "\n",
    "    train_x = np.concatenate([X_folds[i] for i in range(10) if i != (fold_number - 1)], axis=0)\n",
    "    train_y = np.concatenate([y_folds[i] for i in range(10) if i != (fold_number - 1)], axis=0)\n",
    "\n",
    "    print(train_x.shape)\n",
    "    print(test_x.shape)\n",
    "    print(train_y.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    x_train = train_x.reshape(train_x.shape[0], num_rows, num_columns, num_channels)\n",
    "    x_test = test_x.reshape(test_x.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "    y_train_cat = train_y\n",
    "    y_test_cat = test_y\n",
    "\n",
    "    # Optional normalization (you may shift this to extract_features if better)\n",
    "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "    x_test = (x_test - np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    print('y_train shape:', train_y.shape)\n",
    "    print('y_test shape:', test_y.shape)\n",
    "\n",
    "    model = build_model((num_rows, num_columns, num_channels), num_labels)\n",
    "\n",
    "    # Compute class weights\n",
    "    y_train_labels = np.argmax(y_train_cat, axis=1)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_path = f\"saved_models/weights.fold{fold_number}.best.keras\"\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    print(f\"\\nTraining Fold {fold_number}...\")\n",
    "    start = datetime.now()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train_cat,\n",
    "        batch_size=num_batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_test, y_test_cat),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[checkpointer, earlystopper, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    duration = datetime.now() - start\n",
    "    print(f\"Fold {fold_number} training completed in time: {duration}\")\n",
    "\n",
    "    # Save final model\n",
    "    final_model_path = f\"saved_models/urban_sound_model_fold{fold_number}.final.keras\"\n",
    "    model.save(final_model_path)\n",
    "\n",
    "    # Post-training evaluation\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test_cat, axis=1)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nFold {fold_number} Post-Training Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold_number} Post-Training Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(model.evaluate(x_test, y_test_cat, verbose=0))\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82451667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combined():\n",
    "    # Combine all folds into one dataset\n",
    "    X = np.concatenate(X_folds, axis=0)\n",
    "    y = np.concatenate(y_folds, axis=0)  # Assume already one-hot encoded\n",
    "\n",
    "    num_labels = y.shape[1]\n",
    "\n",
    "    # Train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=np.argmax(y, axis=1))\n",
    "\n",
    "    # Reshape for CNN\n",
    "    x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "    # Optional normalization (uncomment if needed)\n",
    "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "    x_test = (x_test - np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "    # Build model\n",
    "    model = build_model((num_rows, num_columns, num_channels), num_labels)\n",
    "\n",
    "    # Compute class weights\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_path = \"saved_models/weights.combined.best.keras\"\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nTraining Combined dataset...\")\n",
    "    start = datetime.now()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=num_batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[checkpointer, earlystopper, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    duration = datetime.now() - start\n",
    "    print(f\"Training completed in time: {duration}\")\n",
    "\n",
    "    # Save final model\n",
    "    final_model_path = \"saved_models/urban_sound_model_combined.final.keras\"\n",
    "    model.save(final_model_path)\n",
    "\n",
    "    # Post-training evaluation\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nPost-Training Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Post-Training Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"Evaluation:\", model.evaluate(x_test, y_test, verbose=0))\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db1c54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7858, 40, 174, 1)\n",
      "x_test shape: (874, 40, 174, 1)\n",
      "y_train shape: (7858, 10)\n",
      "y_test shape: (874, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Combined dataset...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.1319 - loss: 2.2368\n",
      "Epoch 1: val_loss improved from inf to 2.02181, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 384ms/step - accuracy: 0.1336 - loss: 2.2351 - val_accuracy: 0.3593 - val_loss: 2.0218 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.3380 - loss: 1.9205\n",
      "Epoch 2: val_loss improved from 2.02181 to 1.69353, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 442ms/step - accuracy: 0.3389 - loss: 1.9179 - val_accuracy: 0.4657 - val_loss: 1.6935 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.4687 - loss: 1.5988\n",
      "Epoch 3: val_loss improved from 1.69353 to 1.51963, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 402ms/step - accuracy: 0.4693 - loss: 1.5968 - val_accuracy: 0.4886 - val_loss: 1.5196 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5188 - loss: 1.3832\n",
      "Epoch 4: val_loss improved from 1.51963 to 1.36524, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 402ms/step - accuracy: 0.5191 - loss: 1.3822 - val_accuracy: 0.5343 - val_loss: 1.3652 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5535 - loss: 1.2613\n",
      "Epoch 5: val_loss improved from 1.36524 to 1.27128, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 409ms/step - accuracy: 0.5535 - loss: 1.2610 - val_accuracy: 0.5572 - val_loss: 1.2713 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.5604 - loss: 1.2004\n",
      "Epoch 6: val_loss improved from 1.27128 to 1.26790, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 423ms/step - accuracy: 0.5607 - loss: 1.1997 - val_accuracy: 0.5469 - val_loss: 1.2679 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5854 - loss: 1.1285\n",
      "Epoch 7: val_loss improved from 1.26790 to 1.24783, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 416ms/step - accuracy: 0.5854 - loss: 1.1287 - val_accuracy: 0.5629 - val_loss: 1.2478 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.5974 - loss: 1.0836\n",
      "Epoch 8: val_loss improved from 1.24783 to 1.16989, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 402ms/step - accuracy: 0.5971 - loss: 1.0839 - val_accuracy: 0.5915 - val_loss: 1.1699 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5991 - loss: 1.0585\n",
      "Epoch 9: val_loss improved from 1.16989 to 1.12567, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 411ms/step - accuracy: 0.5995 - loss: 1.0583 - val_accuracy: 0.5858 - val_loss: 1.1257 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6230 - loss: 1.0267\n",
      "Epoch 10: val_loss improved from 1.12567 to 1.08379, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 398ms/step - accuracy: 0.6229 - loss: 1.0266 - val_accuracy: 0.6156 - val_loss: 1.0838 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6236 - loss: 1.0133\n",
      "Epoch 11: val_loss did not improve from 1.08379\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6238 - loss: 1.0127 - val_accuracy: 0.5870 - val_loss: 1.1261 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6360 - loss: 0.9975\n",
      "Epoch 12: val_loss improved from 1.08379 to 1.07217, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step - accuracy: 0.6362 - loss: 0.9967 - val_accuracy: 0.6064 - val_loss: 1.0722 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6465 - loss: 0.9517\n",
      "Epoch 13: val_loss improved from 1.07217 to 1.02007, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 400ms/step - accuracy: 0.6466 - loss: 0.9512 - val_accuracy: 0.6407 - val_loss: 1.0201 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6746 - loss: 0.8990\n",
      "Epoch 14: val_loss improved from 1.02007 to 0.98826, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 406ms/step - accuracy: 0.6742 - loss: 0.8995 - val_accuracy: 0.6705 - val_loss: 0.9883 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6760 - loss: 0.8756\n",
      "Epoch 15: val_loss improved from 0.98826 to 0.96633, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 400ms/step - accuracy: 0.6760 - loss: 0.8757 - val_accuracy: 0.6579 - val_loss: 0.9663 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6810 - loss: 0.8730\n",
      "Epoch 16: val_loss improved from 0.96633 to 0.96188, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 403ms/step - accuracy: 0.6809 - loss: 0.8729 - val_accuracy: 0.6648 - val_loss: 0.9619 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6751 - loss: 0.8649\n",
      "Epoch 17: val_loss did not improve from 0.96188\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.6752 - loss: 0.8647 - val_accuracy: 0.6384 - val_loss: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6840 - loss: 0.8495\n",
      "Epoch 18: val_loss improved from 0.96188 to 0.91175, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 399ms/step - accuracy: 0.6842 - loss: 0.8490 - val_accuracy: 0.6762 - val_loss: 0.9118 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6909 - loss: 0.8279\n",
      "Epoch 19: val_loss did not improve from 0.91175\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.6910 - loss: 0.8278 - val_accuracy: 0.6487 - val_loss: 0.9757 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6989 - loss: 0.7901\n",
      "Epoch 20: val_loss improved from 0.91175 to 0.86263, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step - accuracy: 0.6991 - loss: 0.7901 - val_accuracy: 0.6899 - val_loss: 0.8626 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7091 - loss: 0.7805\n",
      "Epoch 21: val_loss did not improve from 0.86263\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.7090 - loss: 0.7806 - val_accuracy: 0.6796 - val_loss: 0.8936 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7206 - loss: 0.7609\n",
      "Epoch 22: val_loss did not improve from 0.86263\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.7207 - loss: 0.7606 - val_accuracy: 0.6865 - val_loss: 0.8774 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7250 - loss: 0.7440\n",
      "Epoch 23: val_loss improved from 0.86263 to 0.86092, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 399ms/step - accuracy: 0.7250 - loss: 0.7440 - val_accuracy: 0.6831 - val_loss: 0.8609 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7283 - loss: 0.7242\n",
      "Epoch 24: val_loss improved from 0.86092 to 0.79632, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 399ms/step - accuracy: 0.7284 - loss: 0.7242 - val_accuracy: 0.7094 - val_loss: 0.7963 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7509 - loss: 0.6909\n",
      "Epoch 25: val_loss did not improve from 0.79632\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.7506 - loss: 0.6914 - val_accuracy: 0.7082 - val_loss: 0.8067 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7395 - loss: 0.7152\n",
      "Epoch 26: val_loss did not improve from 0.79632\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.7395 - loss: 0.7149 - val_accuracy: 0.6991 - val_loss: 0.8310 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7504 - loss: 0.6790\n",
      "Epoch 27: val_loss did not improve from 0.79632\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.7504 - loss: 0.6789 - val_accuracy: 0.7174 - val_loss: 0.7968 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7698 - loss: 0.6362\n",
      "Epoch 28: val_loss improved from 0.79632 to 0.77564, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 399ms/step - accuracy: 0.7696 - loss: 0.6369 - val_accuracy: 0.7197 - val_loss: 0.7756 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7624 - loss: 0.6457\n",
      "Epoch 29: val_loss improved from 0.77564 to 0.76696, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step - accuracy: 0.7624 - loss: 0.6457 - val_accuracy: 0.7254 - val_loss: 0.7670 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7649 - loss: 0.6328\n",
      "Epoch 30: val_loss did not improve from 0.76696\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.7651 - loss: 0.6328 - val_accuracy: 0.7346 - val_loss: 0.7679 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7635 - loss: 0.6353\n",
      "Epoch 31: val_loss improved from 0.76696 to 0.74705, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 398ms/step - accuracy: 0.7636 - loss: 0.6351 - val_accuracy: 0.7437 - val_loss: 0.7471 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7772 - loss: 0.6204\n",
      "Epoch 32: val_loss improved from 0.74705 to 0.74147, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 396ms/step - accuracy: 0.7771 - loss: 0.6203 - val_accuracy: 0.7403 - val_loss: 0.7415 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7792 - loss: 0.6074\n",
      "Epoch 33: val_loss did not improve from 0.74147\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.7793 - loss: 0.6075 - val_accuracy: 0.7277 - val_loss: 0.7635 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7788 - loss: 0.6059\n",
      "Epoch 34: val_loss improved from 0.74147 to 0.70420, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 395ms/step - accuracy: 0.7788 - loss: 0.6062 - val_accuracy: 0.7609 - val_loss: 0.7042 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7776 - loss: 0.6205\n",
      "Epoch 35: val_loss did not improve from 0.70420\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.7778 - loss: 0.6201 - val_accuracy: 0.7346 - val_loss: 0.7328 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7835 - loss: 0.5990\n",
      "Epoch 36: val_loss did not improve from 0.70420\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.7834 - loss: 0.5992 - val_accuracy: 0.7414 - val_loss: 0.7531 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7951 - loss: 0.5707\n",
      "Epoch 37: val_loss improved from 0.70420 to 0.68651, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 404ms/step - accuracy: 0.7950 - loss: 0.5710 - val_accuracy: 0.7746 - val_loss: 0.6865 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7906 - loss: 0.5796\n",
      "Epoch 38: val_loss did not improve from 0.68651\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.7906 - loss: 0.5797 - val_accuracy: 0.7563 - val_loss: 0.7208 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7859 - loss: 0.5880\n",
      "Epoch 39: val_loss did not improve from 0.68651\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.7860 - loss: 0.5880 - val_accuracy: 0.7563 - val_loss: 0.7041 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7907 - loss: 0.5829\n",
      "Epoch 40: val_loss did not improve from 0.68651\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.7907 - loss: 0.5827 - val_accuracy: 0.7403 - val_loss: 0.7246 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8072 - loss: 0.5479\n",
      "Epoch 41: val_loss did not improve from 0.68651\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.8070 - loss: 0.5483 - val_accuracy: 0.7483 - val_loss: 0.7079 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8031 - loss: 0.5441\n",
      "Epoch 42: val_loss did not improve from 0.68651\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8030 - loss: 0.5444 - val_accuracy: 0.7609 - val_loss: 0.6923 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7910 - loss: 0.5695\n",
      "Epoch 43: val_loss improved from 0.68651 to 0.67311, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step - accuracy: 0.7911 - loss: 0.5692 - val_accuracy: 0.7757 - val_loss: 0.6731 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8027 - loss: 0.5418\n",
      "Epoch 44: val_loss did not improve from 0.67311\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8027 - loss: 0.5420 - val_accuracy: 0.7723 - val_loss: 0.6802 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8052 - loss: 0.5323\n",
      "Epoch 45: val_loss improved from 0.67311 to 0.66154, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 400ms/step - accuracy: 0.8051 - loss: 0.5325 - val_accuracy: 0.7803 - val_loss: 0.6615 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7975 - loss: 0.5389\n",
      "Epoch 46: val_loss did not improve from 0.66154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.7977 - loss: 0.5389 - val_accuracy: 0.7735 - val_loss: 0.6810 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8059 - loss: 0.5456\n",
      "Epoch 47: val_loss did not improve from 0.66154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.8058 - loss: 0.5455 - val_accuracy: 0.7815 - val_loss: 0.6641 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8079 - loss: 0.5329\n",
      "Epoch 48: val_loss did not improve from 0.66154\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.8078 - loss: 0.5331 - val_accuracy: 0.7803 - val_loss: 0.6687 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8092 - loss: 0.5348\n",
      "Epoch 49: val_loss did not improve from 0.66154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.8091 - loss: 0.5349 - val_accuracy: 0.7735 - val_loss: 0.6710 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8145 - loss: 0.5310\n",
      "Epoch 50: val_loss did not improve from 0.66154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.8144 - loss: 0.5311 - val_accuracy: 0.7780 - val_loss: 0.6736 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8077 - loss: 0.5398\n",
      "Epoch 51: val_loss did not improve from 0.66154\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.8078 - loss: 0.5394 - val_accuracy: 0.7769 - val_loss: 0.6680 - learning_rate: 1.2500e-04\n",
      "Training completed in time: 0:08:18.983303\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "Post-Training Train Accuracy: 0.8106\n",
      "Post-Training Test Accuracy: 0.7803\n",
      "Evaluation: [0.6615424156188965, 0.7803203463554382]\n",
      "0.8106388449668884\n",
      "0.7803203661327232\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_combined()\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "740c05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7859, 40, 174)\n",
      "(873, 40, 174)\n",
      "(7859, 10)\n",
      "(873, 10)\n",
      "x_train shape: (7859, 40, 174, 1)\n",
      "x_test shape: (873, 40, 174, 1)\n",
      "y_train shape: (7859, 10)\n",
      "y_test shape: (873, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.1595 - loss: 2.2361\n",
      "Epoch 1: val_loss improved from inf to 2.05845, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 347ms/step - accuracy: 0.1614 - loss: 2.2338 - val_accuracy: 0.2806 - val_loss: 2.0584 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.3506 - loss: 1.8711\n",
      "Epoch 2: val_loss improved from 2.05845 to 1.89391, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.3514 - loss: 1.8687 - val_accuracy: 0.4261 - val_loss: 1.8939 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.4689 - loss: 1.5425\n",
      "Epoch 3: val_loss improved from 1.89391 to 1.73922, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.4695 - loss: 1.5405 - val_accuracy: 0.4364 - val_loss: 1.7392 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.5134 - loss: 1.3358\n",
      "Epoch 4: val_loss improved from 1.73922 to 1.66427, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.5136 - loss: 1.3352 - val_accuracy: 0.4948 - val_loss: 1.6643 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.5419 - loss: 1.2491\n",
      "Epoch 5: val_loss did not improve from 1.66427\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - accuracy: 0.5421 - loss: 1.2485 - val_accuracy: 0.4754 - val_loss: 1.6648 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.5779 - loss: 1.1673\n",
      "Epoch 6: val_loss improved from 1.66427 to 1.59743, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 249ms/step - accuracy: 0.5781 - loss: 1.1667 - val_accuracy: 0.5292 - val_loss: 1.5974 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.6036 - loss: 1.0964\n",
      "Epoch 7: val_loss improved from 1.59743 to 1.56486, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.6034 - loss: 1.0965 - val_accuracy: 0.5361 - val_loss: 1.5649 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.6204 - loss: 1.0398\n",
      "Epoch 8: val_loss improved from 1.56486 to 1.48203, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.6201 - loss: 1.0404 - val_accuracy: 0.5670 - val_loss: 1.4820 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.6167 - loss: 1.0340\n",
      "Epoch 9: val_loss did not improve from 1.48203\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 250ms/step - accuracy: 0.6167 - loss: 1.0340 - val_accuracy: 0.4994 - val_loss: 1.5040 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.6304 - loss: 0.9974\n",
      "Epoch 10: val_loss did not improve from 1.48203\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.6303 - loss: 0.9975 - val_accuracy: 0.5395 - val_loss: 1.5150 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6415 - loss: 0.9669\n",
      "Epoch 11: val_loss did not improve from 1.48203\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.6416 - loss: 0.9668 - val_accuracy: 0.5200 - val_loss: 1.5078 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6536 - loss: 0.9454\n",
      "Epoch 12: val_loss improved from 1.48203 to 1.46488, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.6537 - loss: 0.9450 - val_accuracy: 0.5521 - val_loss: 1.4649 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6650 - loss: 0.9161\n",
      "Epoch 13: val_loss did not improve from 1.46488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.6651 - loss: 0.9158 - val_accuracy: 0.5258 - val_loss: 1.5022 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6722 - loss: 0.9129\n",
      "Epoch 14: val_loss did not improve from 1.46488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.6725 - loss: 0.9119 - val_accuracy: 0.5361 - val_loss: 1.4743 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6858 - loss: 0.8388\n",
      "Epoch 15: val_loss did not improve from 1.46488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.6857 - loss: 0.8395 - val_accuracy: 0.5155 - val_loss: 1.4839 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6911 - loss: 0.8473\n",
      "Epoch 16: val_loss improved from 1.46488 to 1.45719, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.6910 - loss: 0.8473 - val_accuracy: 0.5040 - val_loss: 1.4572 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6922 - loss: 0.8142\n",
      "Epoch 17: val_loss did not improve from 1.45719\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - accuracy: 0.6923 - loss: 0.8143 - val_accuracy: 0.5017 - val_loss: 1.5457 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7000 - loss: 0.8014\n",
      "Epoch 18: val_loss did not improve from 1.45719\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.7003 - loss: 0.8010 - val_accuracy: 0.5109 - val_loss: 1.4812 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7146 - loss: 0.7905\n",
      "Epoch 19: val_loss improved from 1.45719 to 1.44125, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.7147 - loss: 0.7904 - val_accuracy: 0.5223 - val_loss: 1.4413 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7095 - loss: 0.7775\n",
      "Epoch 20: val_loss did not improve from 1.44125\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.7098 - loss: 0.7769 - val_accuracy: 0.5235 - val_loss: 1.4731 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.7270 - loss: 0.7520\n",
      "Epoch 21: val_loss did not improve from 1.44125\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.7270 - loss: 0.7517 - val_accuracy: 0.5029 - val_loss: 1.4568 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.7365 - loss: 0.7195\n",
      "Epoch 22: val_loss did not improve from 1.44125\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.7365 - loss: 0.7195 - val_accuracy: 0.5006 - val_loss: 1.5122 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7547 - loss: 0.6809\n",
      "Epoch 23: val_loss did not improve from 1.44125\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7544 - loss: 0.6813 - val_accuracy: 0.4948 - val_loss: 1.5512 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7543 - loss: 0.6773\n",
      "Epoch 24: val_loss did not improve from 1.44125\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.7543 - loss: 0.6772 - val_accuracy: 0.4983 - val_loss: 1.5667 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7588 - loss: 0.6794\n",
      "Epoch 25: val_loss did not improve from 1.44125\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.7592 - loss: 0.6786 - val_accuracy: 0.5189 - val_loss: 1.5402 - learning_rate: 5.0000e-04\n",
      "Fold 1 training completed in time: 0:03:25.948579\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\n",
      "Fold 1 Post-Training Train Accuracy: 0.7696\n",
      "Fold 1 Post-Training Test Accuracy: 0.5223\n",
      "[1.4412517547607422, 0.5223367810249329]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(1)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4793c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7844, 40, 174)\n",
      "(888, 40, 174)\n",
      "(7844, 10)\n",
      "(888, 10)\n",
      "x_train shape: (7844, 40, 174, 1)\n",
      "x_test shape: (888, 40, 174, 1)\n",
      "y_train shape: (7844, 10)\n",
      "y_test shape: (888, 10)\n",
      "\n",
      "Training Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.1353 - loss: 2.2407\n",
      "Epoch 1: val_loss improved from inf to 1.96520, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 252ms/step - accuracy: 0.1373 - loss: 2.2387 - val_accuracy: 0.3592 - val_loss: 1.9652 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.3733 - loss: 1.8236\n",
      "Epoch 2: val_loss improved from 1.96520 to 1.63172, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.3744 - loss: 1.8202 - val_accuracy: 0.4279 - val_loss: 1.6317 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.4723 - loss: 1.5020\n",
      "Epoch 3: val_loss improved from 1.63172 to 1.57146, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.4730 - loss: 1.5001 - val_accuracy: 0.4628 - val_loss: 1.5715 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.5425 - loss: 1.3164\n",
      "Epoch 4: val_loss improved from 1.57146 to 1.48004, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.5427 - loss: 1.3156 - val_accuracy: 0.4955 - val_loss: 1.4800 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.5565 - loss: 1.2368\n",
      "Epoch 5: val_loss improved from 1.48004 to 1.37536, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.5568 - loss: 1.2358 - val_accuracy: 0.4921 - val_loss: 1.3754 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.5805 - loss: 1.1597\n",
      "Epoch 6: val_loss improved from 1.37536 to 1.33938, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.5808 - loss: 1.1591 - val_accuracy: 0.4775 - val_loss: 1.3394 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6027 - loss: 1.0923\n",
      "Epoch 7: val_loss improved from 1.33938 to 1.32943, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.6027 - loss: 1.0922 - val_accuracy: 0.4730 - val_loss: 1.3294 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6270 - loss: 1.0279\n",
      "Epoch 8: val_loss improved from 1.32943 to 1.31356, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.6268 - loss: 1.0281 - val_accuracy: 0.4538 - val_loss: 1.3136 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6170 - loss: 1.0252\n",
      "Epoch 9: val_loss did not improve from 1.31356\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6173 - loss: 1.0251 - val_accuracy: 0.4651 - val_loss: 1.3181 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.6546 - loss: 0.9637\n",
      "Epoch 10: val_loss improved from 1.31356 to 1.30968, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.6544 - loss: 0.9638 - val_accuracy: 0.4673 - val_loss: 1.3097 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.6516 - loss: 0.9481\n",
      "Epoch 11: val_loss did not improve from 1.30968\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 253ms/step - accuracy: 0.6514 - loss: 0.9483 - val_accuracy: 0.4876 - val_loss: 1.3490 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.6570 - loss: 0.9124\n",
      "Epoch 12: val_loss improved from 1.30968 to 1.28657, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 247ms/step - accuracy: 0.6571 - loss: 0.9126 - val_accuracy: 0.4887 - val_loss: 1.2866 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.6727 - loss: 0.8778\n",
      "Epoch 13: val_loss did not improve from 1.28657\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.6725 - loss: 0.8784 - val_accuracy: 0.4966 - val_loss: 1.2870 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.6761 - loss: 0.8815\n",
      "Epoch 14: val_loss did not improve from 1.28657\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.6760 - loss: 0.8817 - val_accuracy: 0.5203 - val_loss: 1.3166 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.6869 - loss: 0.8661\n",
      "Epoch 15: val_loss did not improve from 1.28657\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 247ms/step - accuracy: 0.6870 - loss: 0.8656 - val_accuracy: 0.4910 - val_loss: 1.3284 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.7014 - loss: 0.8135\n",
      "Epoch 16: val_loss did not improve from 1.28657\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.7015 - loss: 0.8134 - val_accuracy: 0.5079 - val_loss: 1.3144 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7028 - loss: 0.7908\n",
      "Epoch 17: val_loss improved from 1.28657 to 1.27429, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - accuracy: 0.7029 - loss: 0.7910 - val_accuracy: 0.5146 - val_loss: 1.2743 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7161 - loss: 0.7650\n",
      "Epoch 18: val_loss did not improve from 1.27429\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - accuracy: 0.7160 - loss: 0.7654 - val_accuracy: 0.4899 - val_loss: 1.3657 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.7252 - loss: 0.7574\n",
      "Epoch 19: val_loss did not improve from 1.27429\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.7250 - loss: 0.7576 - val_accuracy: 0.4955 - val_loss: 1.3706 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.7307 - loss: 0.7356\n",
      "Epoch 20: val_loss did not improve from 1.27429\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.7307 - loss: 0.7357 - val_accuracy: 0.5101 - val_loss: 1.3599 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7425 - loss: 0.7166\n",
      "Epoch 21: val_loss did not improve from 1.27429\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.7423 - loss: 0.7170 - val_accuracy: 0.4966 - val_loss: 1.4026 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.7327 - loss: 0.7242\n",
      "Epoch 22: val_loss did not improve from 1.27429\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.7331 - loss: 0.7235 - val_accuracy: 0.5146 - val_loss: 1.3796 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.7576 - loss: 0.6849\n",
      "Epoch 23: val_loss did not improve from 1.27429\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.7576 - loss: 0.6848 - val_accuracy: 0.5090 - val_loss: 1.3877 - learning_rate: 5.0000e-04\n",
      "Fold 2 training completed in time: 0:02:59.626086\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\n",
      "Fold 2 Post-Training Train Accuracy: 0.7560\n",
      "Fold 2 Post-Training Test Accuracy: 0.5146\n",
      "[1.2742854356765747, 0.5146396160125732]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(2)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4fc9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7807, 40, 174)\n",
      "(925, 40, 174)\n",
      "(7807, 10)\n",
      "(925, 10)\n",
      "x_train shape: (7807, 40, 174, 1)\n",
      "x_test shape: (925, 40, 174, 1)\n",
      "y_train shape: (7807, 10)\n",
      "y_test shape: (925, 10)\n",
      "\n",
      "Training Fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.1477 - loss: 2.2306\n",
      "Epoch 1: val_loss improved from inf to 2.06399, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.1492 - loss: 2.2278 - val_accuracy: 0.2011 - val_loss: 2.0640 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.3605 - loss: 1.8398\n",
      "Epoch 2: val_loss improved from 2.06399 to 1.81927, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 324ms/step - accuracy: 0.3613 - loss: 1.8367 - val_accuracy: 0.3232 - val_loss: 1.8193 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.4685 - loss: 1.4715\n",
      "Epoch 3: val_loss improved from 1.81927 to 1.64063, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4690 - loss: 1.4705 - val_accuracy: 0.4000 - val_loss: 1.6406 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.5192 - loss: 1.3398\n",
      "Epoch 4: val_loss improved from 1.64063 to 1.63278, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5197 - loss: 1.3385 - val_accuracy: 0.3903 - val_loss: 1.6328 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.5513 - loss: 1.2137\n",
      "Epoch 5: val_loss improved from 1.63278 to 1.55780, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 327ms/step - accuracy: 0.5514 - loss: 1.2133 - val_accuracy: 0.4324 - val_loss: 1.5578 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.5735 - loss: 1.1500\n",
      "Epoch 6: val_loss did not improve from 1.55780\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.5738 - loss: 1.1498 - val_accuracy: 0.4076 - val_loss: 1.5988 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5847 - loss: 1.1080\n",
      "Epoch 7: val_loss improved from 1.55780 to 1.54417, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step - accuracy: 0.5848 - loss: 1.1079 - val_accuracy: 0.4530 - val_loss: 1.5442 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.6108 - loss: 1.0605\n",
      "Epoch 8: val_loss did not improve from 1.54417\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 283ms/step - accuracy: 0.6107 - loss: 1.0604 - val_accuracy: 0.4897 - val_loss: 1.5620 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6186 - loss: 1.0235\n",
      "Epoch 9: val_loss did not improve from 1.54417\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 291ms/step - accuracy: 0.6188 - loss: 1.0235 - val_accuracy: 0.4638 - val_loss: 1.5893 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6340 - loss: 1.0035\n",
      "Epoch 10: val_loss did not improve from 1.54417\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - accuracy: 0.6339 - loss: 1.0032 - val_accuracy: 0.4692 - val_loss: 1.5576 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.6463 - loss: 0.9697\n",
      "Epoch 11: val_loss did not improve from 1.54417\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.6464 - loss: 0.9693 - val_accuracy: 0.4400 - val_loss: 1.6196 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.6622 - loss: 0.9367\n",
      "Epoch 12: val_loss did not improve from 1.54417\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.6620 - loss: 0.9365 - val_accuracy: 0.5005 - val_loss: 1.5599 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.6712 - loss: 0.9159\n",
      "Epoch 13: val_loss did not improve from 1.54417\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.6712 - loss: 0.9154 - val_accuracy: 0.4659 - val_loss: 1.6181 - learning_rate: 5.0000e-04\n",
      "Fold 3 training completed in time: 0:01:56.858909\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "Fold 3 Post-Training Train Accuracy: 0.6711\n",
      "Fold 3 Post-Training Test Accuracy: 0.4530\n",
      "[1.544167160987854, 0.45297297835350037]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(3)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa6c8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7742, 40, 174)\n",
      "(990, 40, 174)\n",
      "(7742, 10)\n",
      "(990, 10)\n",
      "x_train shape: (7742, 40, 174, 1)\n",
      "x_test shape: (990, 40, 174, 1)\n",
      "y_train shape: (7742, 10)\n",
      "y_test shape: (990, 10)\n",
      "\n",
      "Training Fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.1371 - loss: 2.2394\n",
      "Epoch 1: val_loss improved from inf to 2.02662, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 284ms/step - accuracy: 0.1390 - loss: 2.2370 - val_accuracy: 0.2586 - val_loss: 2.0266 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.3498 - loss: 1.8144\n",
      "Epoch 2: val_loss improved from 2.02662 to 1.64752, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.3508 - loss: 1.8120 - val_accuracy: 0.4556 - val_loss: 1.6475 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.4628 - loss: 1.4690\n",
      "Epoch 3: val_loss improved from 1.64752 to 1.50269, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.4635 - loss: 1.4675 - val_accuracy: 0.4798 - val_loss: 1.5027 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.5215 - loss: 1.3176\n",
      "Epoch 4: val_loss improved from 1.50269 to 1.43663, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 294ms/step - accuracy: 0.5219 - loss: 1.3165 - val_accuracy: 0.5071 - val_loss: 1.4366 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.5501 - loss: 1.2113\n",
      "Epoch 5: val_loss did not improve from 1.43663\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.5502 - loss: 1.2107 - val_accuracy: 0.5061 - val_loss: 1.4622 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.5783 - loss: 1.1364\n",
      "Epoch 6: val_loss improved from 1.43663 to 1.40823, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step - accuracy: 0.5783 - loss: 1.1362 - val_accuracy: 0.5091 - val_loss: 1.4082 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5959 - loss: 1.0834\n",
      "Epoch 7: val_loss improved from 1.40823 to 1.37349, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.5959 - loss: 1.0833 - val_accuracy: 0.5253 - val_loss: 1.3735 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6100 - loss: 1.0447\n",
      "Epoch 8: val_loss did not improve from 1.37349\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.6100 - loss: 1.0445 - val_accuracy: 0.5162 - val_loss: 1.3961 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6251 - loss: 1.0014\n",
      "Epoch 9: val_loss improved from 1.37349 to 1.36194, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 258ms/step - accuracy: 0.6251 - loss: 1.0019 - val_accuracy: 0.5172 - val_loss: 1.3619 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.6150 - loss: 1.0117\n",
      "Epoch 10: val_loss did not improve from 1.36194\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.6154 - loss: 1.0109 - val_accuracy: 0.5273 - val_loss: 1.3712 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.6406 - loss: 0.9677\n",
      "Epoch 11: val_loss did not improve from 1.36194\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step - accuracy: 0.6407 - loss: 0.9675 - val_accuracy: 0.5343 - val_loss: 1.4018 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6409 - loss: 0.9612\n",
      "Epoch 12: val_loss did not improve from 1.36194\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - accuracy: 0.6411 - loss: 0.9607 - val_accuracy: 0.5434 - val_loss: 1.3697 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6415 - loss: 0.9472\n",
      "Epoch 13: val_loss improved from 1.36194 to 1.34140, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.6419 - loss: 0.9462 - val_accuracy: 0.5505 - val_loss: 1.3414 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6795 - loss: 0.8723\n",
      "Epoch 14: val_loss improved from 1.34140 to 1.29071, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.6795 - loss: 0.8724 - val_accuracy: 0.5586 - val_loss: 1.2907 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6726 - loss: 0.8847\n",
      "Epoch 15: val_loss did not improve from 1.29071\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.6728 - loss: 0.8838 - val_accuracy: 0.5616 - val_loss: 1.2987 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6905 - loss: 0.8415\n",
      "Epoch 16: val_loss did not improve from 1.29071\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 260ms/step - accuracy: 0.6905 - loss: 0.8413 - val_accuracy: 0.5626 - val_loss: 1.3135 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.6980 - loss: 0.8205\n",
      "Epoch 17: val_loss did not improve from 1.29071\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.6980 - loss: 0.8205 - val_accuracy: 0.5586 - val_loss: 1.2976 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.7197 - loss: 0.7785\n",
      "Epoch 18: val_loss did not improve from 1.29071\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.7195 - loss: 0.7787 - val_accuracy: 0.5566 - val_loss: 1.3110 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.7180 - loss: 0.7640\n",
      "Epoch 19: val_loss did not improve from 1.29071\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 365ms/step - accuracy: 0.7180 - loss: 0.7642 - val_accuracy: 0.5394 - val_loss: 1.2955 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7262 - loss: 0.7413\n",
      "Epoch 20: val_loss improved from 1.29071 to 1.28160, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 294ms/step - accuracy: 0.7261 - loss: 0.7415 - val_accuracy: 0.5556 - val_loss: 1.2816 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7295 - loss: 0.7324\n",
      "Epoch 21: val_loss did not improve from 1.28160\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - accuracy: 0.7297 - loss: 0.7323 - val_accuracy: 0.5606 - val_loss: 1.2880 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7395 - loss: 0.7122\n",
      "Epoch 22: val_loss did not improve from 1.28160\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.7394 - loss: 0.7126 - val_accuracy: 0.5606 - val_loss: 1.3012 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7376 - loss: 0.7178\n",
      "Epoch 23: val_loss did not improve from 1.28160\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - accuracy: 0.7375 - loss: 0.7180 - val_accuracy: 0.5505 - val_loss: 1.2933 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.7361 - loss: 0.7052\n",
      "Epoch 24: val_loss improved from 1.28160 to 1.28062, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - accuracy: 0.7361 - loss: 0.7055 - val_accuracy: 0.5707 - val_loss: 1.2806 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7322 - loss: 0.7198\n",
      "Epoch 25: val_loss did not improve from 1.28062\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 287ms/step - accuracy: 0.7326 - loss: 0.7190 - val_accuracy: 0.5505 - val_loss: 1.3253 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.7374 - loss: 0.7121\n",
      "Epoch 26: val_loss did not improve from 1.28062\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 356ms/step - accuracy: 0.7376 - loss: 0.7116 - val_accuracy: 0.5687 - val_loss: 1.3037 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.7398 - loss: 0.6921\n",
      "Epoch 27: val_loss did not improve from 1.28062\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 320ms/step - accuracy: 0.7401 - loss: 0.6919 - val_accuracy: 0.5737 - val_loss: 1.2970 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.7524 - loss: 0.6591\n",
      "Epoch 28: val_loss did not improve from 1.28062\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.7522 - loss: 0.6598 - val_accuracy: 0.5586 - val_loss: 1.3159 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.7582 - loss: 0.6707\n",
      "Epoch 29: val_loss did not improve from 1.28062\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.7583 - loss: 0.6707 - val_accuracy: 0.5535 - val_loss: 1.2960 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.7672 - loss: 0.6417\n",
      "Epoch 30: val_loss did not improve from 1.28062\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.7671 - loss: 0.6420 - val_accuracy: 0.5566 - val_loss: 1.3070 - learning_rate: 2.5000e-04\n",
      "Fold 4 training completed in time: 0:04:25.594774\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\n",
      "Fold 4 Post-Training Train Accuracy: 0.7643\n",
      "Fold 4 Post-Training Test Accuracy: 0.5707\n",
      "[1.2806153297424316, 0.5707070827484131]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(4)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34bc6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7796, 40, 174)\n",
      "(936, 40, 174)\n",
      "(7796, 10)\n",
      "(936, 10)\n",
      "x_train shape: (7796, 40, 174, 1)\n",
      "x_test shape: (936, 40, 174, 1)\n",
      "y_train shape: (7796, 10)\n",
      "y_test shape: (936, 10)\n",
      "\n",
      "Training Fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.1505 - loss: 2.2479\n",
      "Epoch 1: val_loss improved from inf to 1.95827, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 254ms/step - accuracy: 0.1525 - loss: 2.2451 - val_accuracy: 0.3045 - val_loss: 1.9583 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.3845 - loss: 1.8256\n",
      "Epoch 2: val_loss improved from 1.95827 to 1.64503, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.3853 - loss: 1.8236 - val_accuracy: 0.3761 - val_loss: 1.6450 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.4773 - loss: 1.5120\n",
      "Epoch 3: val_loss improved from 1.64503 to 1.50889, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.4777 - loss: 1.5104 - val_accuracy: 0.4199 - val_loss: 1.5089 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.5295 - loss: 1.3442\n",
      "Epoch 4: val_loss improved from 1.50889 to 1.40682, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.5297 - loss: 1.3430 - val_accuracy: 0.4850 - val_loss: 1.4068 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.5487 - loss: 1.2418\n",
      "Epoch 5: val_loss improved from 1.40682 to 1.33457, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 310ms/step - accuracy: 0.5492 - loss: 1.2412 - val_accuracy: 0.5481 - val_loss: 1.3346 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.5827 - loss: 1.1773\n",
      "Epoch 6: val_loss improved from 1.33457 to 1.31002, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.5828 - loss: 1.1769 - val_accuracy: 0.5139 - val_loss: 1.3100 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.6012 - loss: 1.1018\n",
      "Epoch 7: val_loss did not improve from 1.31002\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 329ms/step - accuracy: 0.6012 - loss: 1.1023 - val_accuracy: 0.5459 - val_loss: 1.3106 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.6137 - loss: 1.0650\n",
      "Epoch 8: val_loss improved from 1.31002 to 1.22277, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 328ms/step - accuracy: 0.6139 - loss: 1.0651 - val_accuracy: 0.5705 - val_loss: 1.2228 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.6338 - loss: 1.0263\n",
      "Epoch 9: val_loss did not improve from 1.22277\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 306ms/step - accuracy: 0.6337 - loss: 1.0265 - val_accuracy: 0.5630 - val_loss: 1.2441 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6380 - loss: 1.0027\n",
      "Epoch 10: val_loss improved from 1.22277 to 1.21988, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 258ms/step - accuracy: 0.6379 - loss: 1.0031 - val_accuracy: 0.5385 - val_loss: 1.2199 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6490 - loss: 0.9848\n",
      "Epoch 11: val_loss improved from 1.21988 to 1.17103, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 250ms/step - accuracy: 0.6489 - loss: 0.9848 - val_accuracy: 0.5823 - val_loss: 1.1710 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6589 - loss: 0.9691\n",
      "Epoch 12: val_loss did not improve from 1.17103\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.6589 - loss: 0.9688 - val_accuracy: 0.5812 - val_loss: 1.1775 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.6628 - loss: 0.9160\n",
      "Epoch 13: val_loss improved from 1.17103 to 1.15190, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 301ms/step - accuracy: 0.6628 - loss: 0.9165 - val_accuracy: 0.5929 - val_loss: 1.1519 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.6743 - loss: 0.8916\n",
      "Epoch 14: val_loss improved from 1.15190 to 1.14635, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - accuracy: 0.6742 - loss: 0.8920 - val_accuracy: 0.5791 - val_loss: 1.1463 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6792 - loss: 0.9008\n",
      "Epoch 15: val_loss did not improve from 1.14635\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.6793 - loss: 0.9004 - val_accuracy: 0.6015 - val_loss: 1.1660 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.6891 - loss: 0.8697\n",
      "Epoch 16: val_loss did not improve from 1.14635\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 308ms/step - accuracy: 0.6892 - loss: 0.8695 - val_accuracy: 0.5737 - val_loss: 1.1661 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.6913 - loss: 0.8552\n",
      "Epoch 17: val_loss improved from 1.14635 to 1.12765, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.6914 - loss: 0.8550 - val_accuracy: 0.6079 - val_loss: 1.1276 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.6957 - loss: 0.8467\n",
      "Epoch 18: val_loss did not improve from 1.12765\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.6958 - loss: 0.8463 - val_accuracy: 0.5887 - val_loss: 1.1382 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7101 - loss: 0.8205\n",
      "Epoch 19: val_loss did not improve from 1.12765\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.7101 - loss: 0.8200 - val_accuracy: 0.5919 - val_loss: 1.1587 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.7085 - loss: 0.7793\n",
      "Epoch 20: val_loss did not improve from 1.12765\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.7085 - loss: 0.7796 - val_accuracy: 0.6100 - val_loss: 1.1406 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7099 - loss: 0.7845\n",
      "Epoch 21: val_loss improved from 1.12765 to 1.09136, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.7099 - loss: 0.7844 - val_accuracy: 0.6100 - val_loss: 1.0914 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7177 - loss: 0.7718\n",
      "Epoch 22: val_loss did not improve from 1.09136\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.7178 - loss: 0.7716 - val_accuracy: 0.5972 - val_loss: 1.1448 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.7307 - loss: 0.7429\n",
      "Epoch 23: val_loss did not improve from 1.09136\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.7308 - loss: 0.7430 - val_accuracy: 0.5940 - val_loss: 1.2002 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.7369 - loss: 0.7285\n",
      "Epoch 24: val_loss did not improve from 1.09136\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 347ms/step - accuracy: 0.7369 - loss: 0.7284 - val_accuracy: 0.5855 - val_loss: 1.1526 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.7485 - loss: 0.6981\n",
      "Epoch 25: val_loss did not improve from 1.09136\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 297ms/step - accuracy: 0.7485 - loss: 0.6985 - val_accuracy: 0.5983 - val_loss: 1.1899 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.7504 - loss: 0.6903\n",
      "Epoch 26: val_loss did not improve from 1.09136\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 335ms/step - accuracy: 0.7504 - loss: 0.6905 - val_accuracy: 0.6090 - val_loss: 1.1571 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.7622 - loss: 0.6895\n",
      "Epoch 27: val_loss did not improve from 1.09136\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 430ms/step - accuracy: 0.7623 - loss: 0.6889 - val_accuracy: 0.6100 - val_loss: 1.1313 - learning_rate: 5.0000e-04\n",
      "Fold 5 training completed in time: 0:04:04.471781\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\n",
      "Fold 5 Post-Training Train Accuracy: 0.7646\n",
      "Fold 5 Post-Training Test Accuracy: 0.6100\n",
      "[1.091357707977295, 0.6100427508354187]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(5)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8137e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7909, 40, 174)\n",
      "(823, 40, 174)\n",
      "(7909, 10)\n",
      "(823, 10)\n",
      "x_train shape: (7909, 40, 174, 1)\n",
      "x_test shape: (823, 40, 174, 1)\n",
      "y_train shape: (7909, 10)\n",
      "y_test shape: (823, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 6...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.1343 - loss: 2.2724\n",
      "Epoch 1: val_loss improved from inf to 2.03259, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 344ms/step - accuracy: 0.1359 - loss: 2.2697 - val_accuracy: 0.2746 - val_loss: 2.0326 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.3544 - loss: 1.8580\n",
      "Epoch 2: val_loss improved from 2.03259 to 1.76779, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 324ms/step - accuracy: 0.3555 - loss: 1.8551 - val_accuracy: 0.4399 - val_loss: 1.7678 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.4754 - loss: 1.5068\n",
      "Epoch 3: val_loss improved from 1.76779 to 1.53207, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 348ms/step - accuracy: 0.4758 - loss: 1.5046 - val_accuracy: 0.5006 - val_loss: 1.5321 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.5308 - loss: 1.2864\n",
      "Epoch 4: val_loss did not improve from 1.53207\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.5309 - loss: 1.2860 - val_accuracy: 0.4508 - val_loss: 1.5844 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.5712 - loss: 1.1887\n",
      "Epoch 5: val_loss improved from 1.53207 to 1.43519, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.5712 - loss: 1.1888 - val_accuracy: 0.5200 - val_loss: 1.4352 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5931 - loss: 1.1215\n",
      "Epoch 6: val_loss did not improve from 1.43519\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.5932 - loss: 1.1212 - val_accuracy: 0.4848 - val_loss: 1.4774 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6187 - loss: 1.0547\n",
      "Epoch 7: val_loss did not improve from 1.43519\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.6184 - loss: 1.0549 - val_accuracy: 0.4253 - val_loss: 1.5591 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6295 - loss: 1.0267\n",
      "Epoch 8: val_loss did not improve from 1.43519\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.6296 - loss: 1.0262 - val_accuracy: 0.4812 - val_loss: 1.5109 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6354 - loss: 0.9994\n",
      "Epoch 9: val_loss improved from 1.43519 to 1.42010, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.6357 - loss: 0.9987 - val_accuracy: 0.4982 - val_loss: 1.4201 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6454 - loss: 0.9792\n",
      "Epoch 10: val_loss did not improve from 1.42010\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.6455 - loss: 0.9787 - val_accuracy: 0.4714 - val_loss: 1.5039 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6658 - loss: 0.9253\n",
      "Epoch 11: val_loss did not improve from 1.42010\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6658 - loss: 0.9253 - val_accuracy: 0.4836 - val_loss: 1.4815 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6846 - loss: 0.8594\n",
      "Epoch 12: val_loss did not improve from 1.42010\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6842 - loss: 0.8604 - val_accuracy: 0.4301 - val_loss: 1.4902 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6876 - loss: 0.8643\n",
      "Epoch 13: val_loss did not improve from 1.42010\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6874 - loss: 0.8645 - val_accuracy: 0.4508 - val_loss: 1.5139 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6839 - loss: 0.8519\n",
      "Epoch 14: val_loss did not improve from 1.42010\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6840 - loss: 0.8518 - val_accuracy: 0.4885 - val_loss: 1.4719 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6929 - loss: 0.8345\n",
      "Epoch 15: val_loss did not improve from 1.42010\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.6931 - loss: 0.8339 - val_accuracy: 0.4897 - val_loss: 1.5171 - learning_rate: 5.0000e-04\n",
      "Fold 6 training completed in time: 0:02:06.130747\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "Fold 6 Post-Training Train Accuracy: 0.6987\n",
      "Fold 6 Post-Training Test Accuracy: 0.4982\n",
      "[1.4201035499572754, 0.4981774091720581]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(6)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2991e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7894, 40, 174)\n",
      "(838, 40, 174)\n",
      "(7894, 10)\n",
      "(838, 10)\n",
      "x_train shape: (7894, 40, 174, 1)\n",
      "x_test shape: (838, 40, 174, 1)\n",
      "y_train shape: (7894, 10)\n",
      "y_test shape: (838, 10)\n",
      "\n",
      "Training Fold 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.1569 - loss: 2.2173\n",
      "Epoch 1: val_loss improved from inf to 1.93765, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - accuracy: 0.1588 - loss: 2.2146 - val_accuracy: 0.2983 - val_loss: 1.9377 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.3749 - loss: 1.7972\n",
      "Epoch 2: val_loss improved from 1.93765 to 1.64848, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.3758 - loss: 1.7953 - val_accuracy: 0.3807 - val_loss: 1.6485 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.4800 - loss: 1.5246\n",
      "Epoch 3: val_loss improved from 1.64848 to 1.42071, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.4805 - loss: 1.5228 - val_accuracy: 0.4940 - val_loss: 1.4207 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.5290 - loss: 1.3349\n",
      "Epoch 4: val_loss improved from 1.42071 to 1.42071, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.5293 - loss: 1.3339 - val_accuracy: 0.4976 - val_loss: 1.4207 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.5695 - loss: 1.2155\n",
      "Epoch 5: val_loss improved from 1.42071 to 1.33301, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.5695 - loss: 1.2154 - val_accuracy: 0.5095 - val_loss: 1.3330 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5820 - loss: 1.1574\n",
      "Epoch 6: val_loss improved from 1.33301 to 1.21927, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.5820 - loss: 1.1575 - val_accuracy: 0.5656 - val_loss: 1.2193 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6069 - loss: 1.0875\n",
      "Epoch 7: val_loss did not improve from 1.21927\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6067 - loss: 1.0880 - val_accuracy: 0.5537 - val_loss: 1.2225 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6023 - loss: 1.0815\n",
      "Epoch 8: val_loss did not improve from 1.21927\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6025 - loss: 1.0814 - val_accuracy: 0.5621 - val_loss: 1.2212 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6138 - loss: 1.0595\n",
      "Epoch 9: val_loss did not improve from 1.21927\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 220ms/step - accuracy: 0.6139 - loss: 1.0590 - val_accuracy: 0.5442 - val_loss: 1.2413 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6230 - loss: 1.0115\n",
      "Epoch 10: val_loss improved from 1.21927 to 1.17755, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.6232 - loss: 1.0112 - val_accuracy: 0.5776 - val_loss: 1.1775 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6257 - loss: 0.9997\n",
      "Epoch 11: val_loss improved from 1.17755 to 1.07548, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - accuracy: 0.6260 - loss: 0.9993 - val_accuracy: 0.6289 - val_loss: 1.0755 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.6473 - loss: 0.9576\n",
      "Epoch 12: val_loss improved from 1.07548 to 1.06897, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.6473 - loss: 0.9574 - val_accuracy: 0.6086 - val_loss: 1.0690 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6656 - loss: 0.9263\n",
      "Epoch 13: val_loss did not improve from 1.06897\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.6656 - loss: 0.9261 - val_accuracy: 0.5979 - val_loss: 1.1163 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6661 - loss: 0.8946\n",
      "Epoch 14: val_loss did not improve from 1.06897\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.6661 - loss: 0.8949 - val_accuracy: 0.5800 - val_loss: 1.1671 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6784 - loss: 0.8864\n",
      "Epoch 15: val_loss did not improve from 1.06897\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6784 - loss: 0.8863 - val_accuracy: 0.6026 - val_loss: 1.0929 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6880 - loss: 0.8502\n",
      "Epoch 16: val_loss improved from 1.06897 to 1.05751, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.6880 - loss: 0.8503 - val_accuracy: 0.6217 - val_loss: 1.0575 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7004 - loss: 0.8307\n",
      "Epoch 17: val_loss improved from 1.05751 to 1.02950, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7002 - loss: 0.8311 - val_accuracy: 0.6360 - val_loss: 1.0295 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7089 - loss: 0.8122\n",
      "Epoch 18: val_loss did not improve from 1.02950\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.7087 - loss: 0.8123 - val_accuracy: 0.6277 - val_loss: 1.0650 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7108 - loss: 0.7943\n",
      "Epoch 19: val_loss did not improve from 1.02950\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7107 - loss: 0.7944 - val_accuracy: 0.6229 - val_loss: 1.0972 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7117 - loss: 0.7812\n",
      "Epoch 20: val_loss did not improve from 1.02950\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.7119 - loss: 0.7809 - val_accuracy: 0.6277 - val_loss: 1.0778 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7220 - loss: 0.7438\n",
      "Epoch 21: val_loss did not improve from 1.02950\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.7219 - loss: 0.7443 - val_accuracy: 0.6372 - val_loss: 1.0739 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7321 - loss: 0.7361\n",
      "Epoch 22: val_loss did not improve from 1.02950\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.7321 - loss: 0.7365 - val_accuracy: 0.6253 - val_loss: 1.1061 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7384 - loss: 0.7151\n",
      "Epoch 23: val_loss improved from 1.02950 to 1.02282, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7384 - loss: 0.7153 - val_accuracy: 0.6456 - val_loss: 1.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7567 - loss: 0.6916\n",
      "Epoch 24: val_loss did not improve from 1.02282\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7564 - loss: 0.6922 - val_accuracy: 0.6384 - val_loss: 1.0766 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7369 - loss: 0.7106\n",
      "Epoch 25: val_loss did not improve from 1.02282\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.7371 - loss: 0.7102 - val_accuracy: 0.6563 - val_loss: 1.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7532 - loss: 0.6872\n",
      "Epoch 26: val_loss did not improve from 1.02282\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.7532 - loss: 0.6869 - val_accuracy: 0.6599 - val_loss: 1.0325 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7465 - loss: 0.6937\n",
      "Epoch 27: val_loss did not improve from 1.02282\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.7466 - loss: 0.6932 - val_accuracy: 0.6432 - val_loss: 1.0820 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7607 - loss: 0.6786\n",
      "Epoch 28: val_loss improved from 1.02282 to 1.01139, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7606 - loss: 0.6783 - val_accuracy: 0.6659 - val_loss: 1.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7603 - loss: 0.6581\n",
      "Epoch 29: val_loss did not improve from 1.01139\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.7603 - loss: 0.6583 - val_accuracy: 0.6456 - val_loss: 1.0577 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7693 - loss: 0.6524\n",
      "Epoch 30: val_loss did not improve from 1.01139\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.7692 - loss: 0.6523 - val_accuracy: 0.6408 - val_loss: 1.0702 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7589 - loss: 0.6688\n",
      "Epoch 31: val_loss did not improve from 1.01139\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7590 - loss: 0.6687 - val_accuracy: 0.6408 - val_loss: 1.0831 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7720 - loss: 0.6354\n",
      "Epoch 32: val_loss did not improve from 1.01139\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.7720 - loss: 0.6356 - val_accuracy: 0.6408 - val_loss: 1.0755 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7709 - loss: 0.6225\n",
      "Epoch 33: val_loss did not improve from 1.01139\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.7711 - loss: 0.6226 - val_accuracy: 0.6504 - val_loss: 1.0744 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7730 - loss: 0.6297\n",
      "Epoch 34: val_loss did not improve from 1.01139\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.7730 - loss: 0.6297 - val_accuracy: 0.6396 - val_loss: 1.0508 - learning_rate: 2.5000e-04\n",
      "Fold 7 training completed in time: 0:04:12.246310\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\n",
      "Fold 7 Post-Training Train Accuracy: 0.7738\n",
      "Fold 7 Post-Training Test Accuracy: 0.6659\n",
      "[1.0113908052444458, 0.6658711433410645]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(7)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1152f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7926, 40, 174)\n",
      "(806, 40, 174)\n",
      "(7926, 10)\n",
      "(806, 10)\n",
      "x_train shape: (7926, 40, 174, 1)\n",
      "x_test shape: (806, 40, 174, 1)\n",
      "y_train shape: (7926, 10)\n",
      "y_test shape: (806, 10)\n",
      "\n",
      "Training Fold 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.1652 - loss: 2.2154\n",
      "Epoch 1: val_loss improved from inf to 1.95021, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 249ms/step - accuracy: 0.1668 - loss: 2.2128 - val_accuracy: 0.3970 - val_loss: 1.9502 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.3517 - loss: 1.8176\n",
      "Epoch 2: val_loss improved from 1.95021 to 1.68959, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.3530 - loss: 1.8149 - val_accuracy: 0.4888 - val_loss: 1.6896 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.4730 - loss: 1.5029\n",
      "Epoch 3: val_loss improved from 1.68959 to 1.49662, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.4733 - loss: 1.5017 - val_accuracy: 0.5831 - val_loss: 1.4966 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5346 - loss: 1.3126\n",
      "Epoch 4: val_loss did not improve from 1.49662\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.5345 - loss: 1.3121 - val_accuracy: 0.5161 - val_loss: 1.5218 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5542 - loss: 1.2201\n",
      "Epoch 5: val_loss improved from 1.49662 to 1.42371, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.5541 - loss: 1.2200 - val_accuracy: 0.6042 - val_loss: 1.4237 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.5749 - loss: 1.1480\n",
      "Epoch 6: val_loss improved from 1.42371 to 1.30955, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5748 - loss: 1.1480 - val_accuracy: 0.5670 - val_loss: 1.3095 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.5994 - loss: 1.0960\n",
      "Epoch 7: val_loss did not improve from 1.30955\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.5994 - loss: 1.0958 - val_accuracy: 0.5670 - val_loss: 1.3895 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6205 - loss: 1.0431\n",
      "Epoch 8: val_loss improved from 1.30955 to 1.30841, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.6201 - loss: 1.0434 - val_accuracy: 0.5112 - val_loss: 1.3084 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6199 - loss: 1.0337\n",
      "Epoch 9: val_loss did not improve from 1.30841\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6201 - loss: 1.0330 - val_accuracy: 0.5707 - val_loss: 1.3872 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6456 - loss: 0.9719\n",
      "Epoch 10: val_loss did not improve from 1.30841\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.6454 - loss: 0.9724 - val_accuracy: 0.5223 - val_loss: 1.3785 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6487 - loss: 0.9598\n",
      "Epoch 11: val_loss did not improve from 1.30841\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6490 - loss: 0.9593 - val_accuracy: 0.5397 - val_loss: 1.3255 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6584 - loss: 0.9227\n",
      "Epoch 12: val_loss did not improve from 1.30841\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6585 - loss: 0.9225 - val_accuracy: 0.5236 - val_loss: 1.3764 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6692 - loss: 0.9152\n",
      "Epoch 13: val_loss did not improve from 1.30841\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.6694 - loss: 0.9150 - val_accuracy: 0.5521 - val_loss: 1.3479 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6887 - loss: 0.8645\n",
      "Epoch 14: val_loss did not improve from 1.30841\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.6889 - loss: 0.8644 - val_accuracy: 0.5186 - val_loss: 1.3963 - learning_rate: 5.0000e-04\n",
      "Fold 8 training completed in time: 0:01:45.121746\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "Fold 8 Post-Training Train Accuracy: 0.6939\n",
      "Fold 8 Post-Training Test Accuracy: 0.5112\n",
      "[1.3084056377410889, 0.5111662745475769]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(8)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cccb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7916, 40, 174)\n",
      "(816, 40, 174)\n",
      "(7916, 10)\n",
      "(816, 10)\n",
      "x_train shape: (7916, 40, 174, 1)\n",
      "x_test shape: (816, 40, 174, 1)\n",
      "y_train shape: (7916, 10)\n",
      "y_test shape: (816, 10)\n",
      "\n",
      "Training Fold 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.1242 - loss: 2.2761\n",
      "Epoch 1: val_loss improved from inf to 2.03719, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.1257 - loss: 2.2737 - val_accuracy: 0.2733 - val_loss: 2.0372 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.3570 - loss: 1.9083\n",
      "Epoch 2: val_loss improved from 2.03719 to 1.71544, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.3580 - loss: 1.9048 - val_accuracy: 0.3493 - val_loss: 1.7154 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.4549 - loss: 1.5270\n",
      "Epoch 3: val_loss improved from 1.71544 to 1.47289, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.4555 - loss: 1.5248 - val_accuracy: 0.4350 - val_loss: 1.4729 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5073 - loss: 1.3252\n",
      "Epoch 4: val_loss improved from 1.47289 to 1.36559, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5077 - loss: 1.3241 - val_accuracy: 0.4681 - val_loss: 1.3656 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.5505 - loss: 1.2281\n",
      "Epoch 5: val_loss improved from 1.36559 to 1.28135, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.5506 - loss: 1.2273 - val_accuracy: 0.5208 - val_loss: 1.2814 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.5646 - loss: 1.1374\n",
      "Epoch 6: val_loss improved from 1.28135 to 1.25075, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.5649 - loss: 1.1371 - val_accuracy: 0.5355 - val_loss: 1.2508 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.5867 - loss: 1.0960\n",
      "Epoch 7: val_loss improved from 1.25075 to 1.18791, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.5870 - loss: 1.0952 - val_accuracy: 0.5539 - val_loss: 1.1879 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6065 - loss: 1.0518\n",
      "Epoch 8: val_loss did not improve from 1.18791\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6066 - loss: 1.0513 - val_accuracy: 0.5478 - val_loss: 1.2318 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6190 - loss: 1.0058\n",
      "Epoch 9: val_loss did not improve from 1.18791\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6193 - loss: 1.0055 - val_accuracy: 0.5441 - val_loss: 1.2477 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6316 - loss: 0.9672\n",
      "Epoch 10: val_loss did not improve from 1.18791\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6317 - loss: 0.9673 - val_accuracy: 0.5551 - val_loss: 1.2233 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6531 - loss: 0.9263\n",
      "Epoch 11: val_loss did not improve from 1.18791\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6531 - loss: 0.9266 - val_accuracy: 0.5662 - val_loss: 1.2196 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6660 - loss: 0.9015\n",
      "Epoch 12: val_loss did not improve from 1.18791\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.6658 - loss: 0.9018 - val_accuracy: 0.5527 - val_loss: 1.2669 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6824 - loss: 0.8769\n",
      "Epoch 13: val_loss did not improve from 1.18791\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6821 - loss: 0.8772 - val_accuracy: 0.5797 - val_loss: 1.1899 - learning_rate: 5.0000e-04\n",
      "Fold 9 training completed in time: 0:01:34.835390\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "Fold 9 Post-Training Train Accuracy: 0.6724\n",
      "Fold 9 Post-Training Test Accuracy: 0.5539\n",
      "[1.187907099723816, 0.5539215803146362]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(9)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16e48c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7895, 40, 174)\n",
      "(837, 40, 174)\n",
      "(7895, 10)\n",
      "(837, 10)\n",
      "x_train shape: (7895, 40, 174, 1)\n",
      "x_test shape: (837, 40, 174, 1)\n",
      "y_train shape: (7895, 10)\n",
      "y_test shape: (837, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 10...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.1490 - loss: 2.2309\n",
      "Epoch 1: val_loss improved from inf to 2.07343, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - accuracy: 0.1504 - loss: 2.2287 - val_accuracy: 0.3082 - val_loss: 2.0734 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.3347 - loss: 1.9264\n",
      "Epoch 2: val_loss improved from 2.07343 to 1.83637, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.3352 - loss: 1.9242 - val_accuracy: 0.3357 - val_loss: 1.8364 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.4128 - loss: 1.6695\n",
      "Epoch 3: val_loss improved from 1.83637 to 1.66558, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.4133 - loss: 1.6674 - val_accuracy: 0.4361 - val_loss: 1.6656 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.4812 - loss: 1.4242\n",
      "Epoch 4: val_loss improved from 1.66558 to 1.61626, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.4816 - loss: 1.4231 - val_accuracy: 0.4313 - val_loss: 1.6163 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5376 - loss: 1.2638\n",
      "Epoch 5: val_loss improved from 1.61626 to 1.44837, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.5376 - loss: 1.2636 - val_accuracy: 0.5149 - val_loss: 1.4484 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.5648 - loss: 1.1955\n",
      "Epoch 6: val_loss did not improve from 1.44837\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.5649 - loss: 1.1949 - val_accuracy: 0.4110 - val_loss: 1.6012 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5704 - loss: 1.1510\n",
      "Epoch 7: val_loss improved from 1.44837 to 1.44544, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.5709 - loss: 1.1503 - val_accuracy: 0.4958 - val_loss: 1.4454 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6051 - loss: 1.0870\n",
      "Epoch 8: val_loss improved from 1.44544 to 1.34668, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6051 - loss: 1.0866 - val_accuracy: 0.5448 - val_loss: 1.3467 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6204 - loss: 1.0576\n",
      "Epoch 9: val_loss did not improve from 1.34668\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6204 - loss: 1.0571 - val_accuracy: 0.4791 - val_loss: 1.5185 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6229 - loss: 1.0186\n",
      "Epoch 10: val_loss did not improve from 1.34668\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step - accuracy: 0.6231 - loss: 1.0183 - val_accuracy: 0.5173 - val_loss: 1.4181 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.6405 - loss: 0.9799\n",
      "Epoch 11: val_loss did not improve from 1.34668\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.6405 - loss: 0.9796 - val_accuracy: 0.5520 - val_loss: 1.3532 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6410 - loss: 0.9660\n",
      "Epoch 12: val_loss did not improve from 1.34668\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.6413 - loss: 0.9654 - val_accuracy: 0.5591 - val_loss: 1.3559 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6668 - loss: 0.9106\n",
      "Epoch 13: val_loss did not improve from 1.34668\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.6668 - loss: 0.9106 - val_accuracy: 0.5472 - val_loss: 1.4201 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.6748 - loss: 0.8818\n",
      "Epoch 14: val_loss did not improve from 1.34668\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 273ms/step - accuracy: 0.6747 - loss: 0.8822 - val_accuracy: 0.5603 - val_loss: 1.3735 - learning_rate: 5.0000e-04\n",
      "Fold 10 training completed in time: 0:01:49.336031\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\n",
      "Fold 10 Post-Training Train Accuracy: 0.6694\n",
      "Fold 10 Post-Training Test Accuracy: 0.5448\n",
      "[1.3466823101043701, 0.5448028445243835]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(10)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154286d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc0b8513",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72acccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracies: [0.7055605053901672, 0.7316420078277588, 0.7011656165122986, 0.7498062252998352, 0.7547460198402405, 0.7115944027900696, 0.7875601649284363, 0.7124652862548828, 0.7474734783172607, 0.7351488471031189]\n",
      "Test Accuracies: [0.5028636884306987, 0.5225225225225225, 0.4702702702702703, 0.5484848484848485, 0.563034188034188, 0.5467800729040098, 0.7159904534606205, 0.6066997518610422, 0.5980392156862745, 0.6009557945041816]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1, 11), train_accuracies, 'x-', label=\"Train Acc\")\n",
    "plt.plot(range(1, 11), fold_accuracies, 'o-', label=\"Test Acc\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"10-Fold Cross-Validation Accuracies\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train Accuracies:\", train_accuracies)\n",
    "print(\"Test Accuracies:\", fold_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff481d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Training Accuracy over 10 folds: 0.7337\n",
      "Average Test Accuracy over 10 folds: 0.5676\n",
      "Training Accuracies for each fold: [0.7055605053901672, 0.7316420078277588, 0.7011656165122986, 0.7498062252998352, 0.7547460198402405, 0.7115944027900696, 0.7875601649284363, 0.7124652862548828, 0.7474734783172607, 0.7351488471031189]\n",
      "Test Accuracies for each fold: [0.5028636884306987, 0.5225225225225225, 0.4702702702702703, 0.5484848484848485, 0.563034188034188, 0.5467800729040098, 0.7159904534606205, 0.6066997518610422, 0.5980392156862745, 0.6009557945041816]\n"
     ]
    }
   ],
   "source": [
    "# Final metrics\n",
    "print(f\"\\nAverage Training Accuracy over 10 folds: {np.mean(train_accuracies):.4f}\")\n",
    "print(f\"Average Test Accuracy over 10 folds: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Training Accuracies for each fold: {train_accuracies}\")\n",
    "print(f\"Test Accuracies for each fold: {fold_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1ca1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_path, model_path='saved_models/urban_sound_model_fold1.keras'):\n",
    "    model = load_model(model_path)\n",
    "    feature = extract_features(file_path)\n",
    "\n",
    "    if feature is None:\n",
    "        print(\"Error extracting features.\")\n",
    "        return\n",
    "\n",
    "    feature = feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    prediction = model.predict(feature)[0]  # shape: (num_classes,)\n",
    "\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_class = le.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class}\\n\")\n",
    "\n",
    "    print(\"Class probabilities:\")\n",
    "    class_labels = le.classes_\n",
    "    for i, prob in enumerate(prediction):\n",
    "        label = class_labels[i]\n",
    "        print(f\"{str(label):20s}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b76a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_across_folds(file_path, output_file=\"fold_predictions.txt\"):\n",
    "    feature = extract_features(file_path)\n",
    "    if feature is None:\n",
    "        print(\"Error extracting features.\")\n",
    "        return\n",
    "\n",
    "    feature = feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    all_predictions = []\n",
    "\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(f\"Predictions for audio file: {file_path}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "        for fold in range(1, 11):\n",
    "            model_path = f\"saved_models/urban_sound_model_fold{fold}.final.keras\"\n",
    "            try:\n",
    "                model = load_model(model_path)\n",
    "                prediction = model.predict(feature)[0]  # shape: (num_classes,)\n",
    "                all_predictions.append(prediction)\n",
    "\n",
    "                predicted_index = np.argmax(prediction)\n",
    "                predicted_class = le.inverse_transform([predicted_index])[0]\n",
    "\n",
    "                f.write(f\"Fold {fold} Prediction: {predicted_class} (class index: {predicted_index})\\n\")\n",
    "            except Exception as e:\n",
    "                f.write(f\"Fold {fold} Prediction Error: {str(e)}\\n\")\n",
    "\n",
    "        if all_predictions:\n",
    "            # Aggregate predictions\n",
    "            avg_prediction = np.mean(all_predictions, axis=0)\n",
    "            final_index = np.argmax(avg_prediction)\n",
    "            final_class = le.inverse_transform([final_index])[0]\n",
    "\n",
    "            f.write(\"\\nAverage Prediction Probabilities:\\n\")\n",
    "            for i, prob in enumerate(avg_prediction):\n",
    "                class_name = le.classes_[i]\n",
    "                f.write(f\"{class_name:20s}: {prob:.4f}\\n\")\n",
    "\n",
    "            f.write(f\"\\nFinal Predicted Class (Avg): {final_class} (class index: {final_index})\\n\")\n",
    "\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        print(f\"Predictions written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9569be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Predicted class: street_music\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 1.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./audio/fold5/100852-0-0-0.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9827a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "WARNING:tensorflow:5 out of the last 30 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D33F9253A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "WARNING:tensorflow:6 out of the last 31 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D32C0F0B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Predictions written to fold_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/dog_bark_1.wav\", output_file=\"fold_predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71503e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predicted class: car_horn\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.9935\n",
      "children_playing    : 0.0065\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fdf6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "Predicted class: car_horn\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.9935\n",
      "children_playing    : 0.0065\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b58c9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "Predicted class: car_horn\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.9935\n",
      "children_playing    : 0.0065\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/weights.fold1.best.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de5b576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Predicted class: siren\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 1.0000\n",
      "street_music        : 0.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Predicted class: siren\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 0.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 1.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/drilling_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/drilling_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57227ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 0.9998\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0002\n",
      "street_music        : 0.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 0.9998\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0002\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/gun_shot_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/gun_shot_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1886281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file: ./EvaluationAudio/siren_1.wav\n",
      "Error extracting features.\n",
      "Error encountered while parsing file: ./EvaluationAudio/siren_1.wav\n",
      "Error extracting features.\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/siren_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/siren_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cf50824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 1.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold6.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "366585cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 1.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold7.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efb25674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 1.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold8.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e3ac19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 1.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold9.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf49d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Predicted class: dog_bark\n",
      "\n",
      "Class probabilities:\n",
      "air_conditioner     : 0.0000\n",
      "car_horn            : 0.0000\n",
      "children_playing    : 0.0000\n",
      "dog_bark            : 1.0000\n",
      "drilling            : 0.0000\n",
      "engine_idling       : 0.0000\n",
      "gun_shot            : 0.0000\n",
      "jackhammer          : 0.0000\n",
      "siren               : 0.0000\n",
      "street_music        : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold10.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3dc7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Predictions written to fold_predictions_dog_bark.txt\n"
     ]
    }
   ],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/dog_bark_1.wav\", output_file=\"fold_predictions_dog_bark.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "372f9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Predictions written to fold_predictions_drilling.txt\n"
     ]
    }
   ],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/drilling_1.wav\", output_file=\"fold_predictions_drilling.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d77e929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file: ./EvaluationAudio/siren_1.wav\n",
      "Error extracting features.\n"
     ]
    }
   ],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/siren_1.wav\", output_file=\"fold_predictions_siren.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5eb4f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Predictions written to fold_predictions_gun_shot.txt\n"
     ]
    }
   ],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/gun_shot_1.wav\", output_file=\"fold_predictions_gun_shot.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08166599",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "A deep CNN architecture. It uses progressive convolutional blocks followed by dropout regularization and a global average pooling layer.\n",
    "\n",
    "**Layer-wise Architecture**:\n",
    "\n",
    "1. **Conv Layer 1**  \n",
    "   - Filters: 16  \n",
    "   - Kernel Size: 2×2  \n",
    "   - Activation: ReLU  \n",
    "   - MaxPooling: 2×2  \n",
    "   - Dropout: 0.2\n",
    "\n",
    "2. **Conv Layer 2**  \n",
    "   - Filters: 32  \n",
    "   - Kernel Size: 2×2  \n",
    "   - Activation: ReLU  \n",
    "   - MaxPooling: 2×2  \n",
    "   - Dropout: 0.2\n",
    "\n",
    "3. **Conv Layer 3**  \n",
    "   - Filters: 64  \n",
    "   - Kernel Size: 2×2  \n",
    "   - Activation: ReLU  \n",
    "   - MaxPooling: 2×2  \n",
    "   - Dropout: 0.2\n",
    "\n",
    "4. **Conv Layer 4**  \n",
    "   - Filters: 128  \n",
    "   - Kernel Size: 2×2  \n",
    "   - Activation: ReLU  \n",
    "   - MaxPooling: 2×2  \n",
    "   - Dropout: 0.2\n",
    "\n",
    "5. **Global Average Pooling**: Aggregates spatial features into a single vector\n",
    "\n",
    "6. **Dense Output Layer**  \n",
    "   - Units: `num_labels`  \n",
    "   - Activation: Softmax\n",
    "\n",
    "---\n",
    "\n",
    "- **Loss Function**: Categorical Crossentropy  \n",
    "- **Optimizer**: Adam  \n",
    "- **Evaluation Metric**: Accuracy  \n",
    "- **Regularization**: Dropout (0.2 after each conv block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01e7fb",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### Combined Dataset Performance\n",
    "\n",
    "| Metric                | Value       |\n",
    "|-----------------------|-------------|\n",
    "| Final Train Accuracy  | **0.8106**  |\n",
    "| Final Test Accuracy   | **0.7803**  |\n",
    "| Final Test Loss       | **0.6615**  |\n",
    "\n",
    "**Interpretation**:\n",
    "- The model generalizes well with a **78.03% test accuracy**.\n",
    "- The loss value (0.66) confirms smooth convergence with no major signs of overfitting.\n",
    "- A modest **train-test gap (~3%)** indicates a healthy learning curve.\n",
    "\n",
    "---\n",
    "\n",
    "### 10-Fold Cross-Validation Performance\n",
    "\n",
    "| Fold | Train Accuracy | Test Accuracy | Test Loss |\n",
    "|------|----------------|---------------|-----------|\n",
    "| 1    | 0.7696         | 0.5223        | 1.4413    |\n",
    "| 2    | 0.7560         | 0.5146        | 1.2743    |\n",
    "| 3    | 0.6711         | 0.4530        | 1.5442    |\n",
    "| 4    | 0.7643         | 0.5707        | 1.2806    |\n",
    "| 5    | 0.7646         | 0.6100        | 1.0914    |\n",
    "| 6    | 0.6987         | 0.4982        | 1.4201    |\n",
    "| 7    | 0.7738         | 0.6659        | 1.0114    |\n",
    "| 8    | 0.6939         | 0.5112        | 1.3084    |\n",
    "| 9    | 0.6724         | 0.5539        | 1.1879    |\n",
    "| 10   | 0.6694         | 0.5448        | 1.3467    |\n",
    "\n",
    "### Average Metrics (10-Fold)\n",
    "- **Average Train Accuracy**: `0.7234`\n",
    "- **Average Test Accuracy**: `0.5445`\n",
    "- **Average Test Loss**: `1.2900`\n",
    "\n",
    "---\n",
    "\n",
    "### Observations\n",
    "\n",
    "- **Combined training** outperforms the average of individual folds by nearly **23%**.\n",
    "- **Folds 3 and 6** show the weakest performance, likely due to unfavorable class distributions or data noise.\n",
    "- **Fold 7** performs best in terms of test accuracy (66.59%) and lowest test loss.\n",
    "- The model overall does not perform or generalize well for the 10-fold cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
