{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dd27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Activation, GlobalMaxPooling2D,GlobalAveragePooling2D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers, activations\n",
    "from keras.initializers import HeNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1865543",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "num_epochs = 100\n",
    "num_batch_size = 256\n",
    "dataset_path = './audio/'\n",
    "metadata = pd.read_csv('./metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f31c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=num_rows)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file:\", file_name)\n",
    "        return None\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f46854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode outside the loop for consistency\n",
    "le = LabelEncoder()\n",
    "le.fit(metadata[\"class\"])\n",
    "num_labels = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b51c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store accuracy of each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "# Save model and track training accuracy\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a9cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = metadata[metadata['fold'] == 1]\n",
    "data_2 = metadata[metadata['fold'] == 2]\n",
    "data_3 = metadata[metadata['fold'] == 3]\n",
    "data_4 = metadata[metadata['fold'] == 4]\n",
    "data_5 = metadata[metadata['fold'] == 5]\n",
    "data_6 = metadata[metadata['fold'] == 6]\n",
    "data_7 = metadata[metadata['fold'] == 7]\n",
    "data_8 = metadata[metadata['fold'] == 8]\n",
    "data_9 = metadata[metadata['fold'] == 9]\n",
    "data_10 = metadata[metadata['fold'] == 10]\n",
    "data_folds = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2c2274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>101415-3-0-2.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>101415-3-0-3.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>101415-3-0-8.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>102106-3-0-0.wav</td>\n",
       "      <td>102106</td>\n",
       "      <td>2.243852</td>\n",
       "      <td>3.884477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>102305-6-0-0.wav</td>\n",
       "      <td>102305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.611610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>gun_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>99180-9-0-2.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>99180-9-0-36.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>99180-9-0-48.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>99180-9-0-49.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>99180-9-0-7.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       slice_file_name    fsID      start        end  salience  fold  classID  \\\n",
       "64    101415-3-0-2.wav  101415   1.000000   5.000000         1     1        3   \n",
       "65    101415-3-0-3.wav  101415   1.500000   5.500000         1     1        3   \n",
       "66    101415-3-0-8.wav  101415   4.000000   8.000000         1     1        3   \n",
       "105   102106-3-0-0.wav  102106   2.243852   3.884477         2     1        3   \n",
       "106   102305-6-0-0.wav  102305   0.000000   2.611610         1     1        6   \n",
       "...                ...     ...        ...        ...       ...   ...      ...   \n",
       "8676   99180-9-0-2.wav   99180   1.000000   5.000000         1     1        9   \n",
       "8677  99180-9-0-36.wav   99180  18.000000  22.000000         1     1        9   \n",
       "8678  99180-9-0-48.wav   99180  24.000000  28.000000         1     1        9   \n",
       "8679  99180-9-0-49.wav   99180  24.500000  28.500000         1     1        9   \n",
       "8680   99180-9-0-7.wav   99180   3.500000   7.500000         1     1        9   \n",
       "\n",
       "             class  \n",
       "64        dog_bark  \n",
       "65        dog_bark  \n",
       "66        dog_bark  \n",
       "105       dog_bark  \n",
       "106       gun_shot  \n",
       "...            ...  \n",
       "8676  street_music  \n",
       "8677  street_music  \n",
       "8678  street_music  \n",
       "8679  street_music  \n",
       "8680  street_music  \n",
       "\n",
       "[873 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0c79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_set(dataframe):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=\"Extracting features\"):\n",
    "        file_path = os.path.join(dataset_path, f\"fold{row['fold']}\", row[\"slice_file_name\"])\n",
    "        class_label = row[\"class\"]\n",
    "        data = extract_features(file_path)\n",
    "        if data is not None:\n",
    "            features.append([data, class_label])\n",
    "            labels.append(row[\"class\"])\n",
    "    featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "    return features, featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee05e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 833/873 [01:21<00:02, 18.26it/s]C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "Extracting features:  96%|█████████▌| 835/873 [01:21<00:02, 17.57it/s]C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "Extracting features: 100%|██████████| 873/873 [01:23<00:00, 10.45it/s]\n",
      "Extracting features: 100%|██████████| 888/888 [01:10<00:00, 12.65it/s]\n",
      "Extracting features: 100%|██████████| 925/925 [01:03<00:00, 14.59it/s]\n",
      "Extracting features: 100%|██████████| 990/990 [01:18<00:00, 12.55it/s]\n",
      "Extracting features: 100%|██████████| 936/936 [01:11<00:00, 13.12it/s]\n",
      "Extracting features: 100%|██████████| 823/823 [00:54<00:00, 15.14it/s]\n",
      "Extracting features: 100%|██████████| 838/838 [01:00<00:00, 13.86it/s]\n",
      "Extracting features: 100%|██████████| 806/806 [01:02<00:00, 12.87it/s]\n",
      "Extracting features: 100%|██████████| 816/816 [01:03<00:00, 12.82it/s]\n",
      "Extracting features: 100%|██████████| 837/837 [01:03<00:00, 13.16it/s]\n"
     ]
    }
   ],
   "source": [
    "features_1, featuresdf_1 = extract_set(data_1)\n",
    "features_2, featuresdf_2 = extract_set(data_2)\n",
    "features_3, featuresdf_3 = extract_set(data_3)\n",
    "features_4, featuresdf_4 = extract_set(data_4)\n",
    "features_5, featuresdf_5 = extract_set(data_5)\n",
    "features_6, featuresdf_6 = extract_set(data_6)\n",
    "features_7, featuresdf_7 = extract_set(data_7)\n",
    "features_8, featuresdf_8 = extract_set(data_8)\n",
    "features_9, featuresdf_9 = extract_set(data_9)\n",
    "features_10, featuresdf_10 = extract_set(data_10)\n",
    "\n",
    "all_features = [features_1, features_2, features_3, features_4, features_5, features_6, features_7, features_8, features_9, features_10]\n",
    "\n",
    "all_features_df = [featuresdf_1, featuresdf_2, featuresdf_3, featuresdf_4, featuresdf_5, featuresdf_6, featuresdf_7, featuresdf_8, featuresdf_9, featuresdf_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b46606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-525.06586, -519.55695, -518.64276, -518.897...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-524.8159, -521.7542, -520.1264, -521.55524,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-133.84369, -161.87689, -246.68976, -244.979...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-268.53568, -244.676, -250.90111, -222.67284...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-145.07484, -90.33111, -93.73102, -105.46187...</td>\n",
       "      <td>gun_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>[[-156.50749, -163.36191, -215.15918, -218.828...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>[[-123.989105, -134.89343, -156.30284, -154.51...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>[[-162.53307, -154.248, -156.98843, -153.72377...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>[[-101.44252, -102.41235, -158.99976, -152.564...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>[[-114.2226, -120.25398, -177.69623, -183.1599...</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature   class_label\n",
       "0    [[-525.06586, -519.55695, -518.64276, -518.897...      dog_bark\n",
       "1    [[-524.8159, -521.7542, -520.1264, -521.55524,...      dog_bark\n",
       "2    [[-133.84369, -161.87689, -246.68976, -244.979...      dog_bark\n",
       "3    [[-268.53568, -244.676, -250.90111, -222.67284...      dog_bark\n",
       "4    [[-145.07484, -90.33111, -93.73102, -105.46187...      gun_shot\n",
       "..                                                 ...           ...\n",
       "868  [[-156.50749, -163.36191, -215.15918, -218.828...  street_music\n",
       "869  [[-123.989105, -134.89343, -156.30284, -154.51...  street_music\n",
       "870  [[-162.53307, -154.248, -156.98843, -153.72377...  street_music\n",
       "871  [[-101.44252, -102.41235, -158.99976, -152.564...  street_music\n",
       "872  [[-114.2226, -120.25398, -177.69623, -183.1599...  street_music\n",
       "\n",
       "[873 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27848e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data to get consistent label encoding\n",
    "all_labels = [label for df in all_features_df for label in df['class_label']]\n",
    "le = LabelEncoder()\n",
    "le.fit(all_labels)  # Fit once across all data\n",
    "\n",
    "X_folds = []\n",
    "y_folds = []\n",
    "\n",
    "for features_df in all_features_df:\n",
    "    X = np.array(features_df['feature'].tolist())\n",
    "    y = le.transform(features_df['class_label'])  # Encode\n",
    "    y = to_categorical(y)  # One-hot\n",
    "    X_folds.append(X)\n",
    "    y_folds.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c01c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_labels):\n",
    "    model1 = Sequential()\n",
    "\n",
    "    #layer-1\n",
    "    model1.add(Conv2D(filters=24, kernel_size=5, input_shape=(input_shape),\n",
    "                      kernel_regularizer=regularizers.l2(1e-3)))\n",
    "    model1.add(MaxPooling2D(pool_size=(3,3), strides=3))\n",
    "    model1.add(Activation(activations.relu))\n",
    "\n",
    "    #layer-2\n",
    "    model1.add(Conv2D(filters=36, kernel_size=4, padding='valid', kernel_regularizer=regularizers.l2(1e-3)))\n",
    "    model1.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "    model1.add(Activation(activations.relu))\n",
    "\n",
    "    #layer-3\n",
    "    model1.add(Conv2D(filters=48, kernel_size=3, padding='valid'))\n",
    "    model1.add(Activation(activations.relu))\n",
    "\n",
    "    model1.add(GlobalAveragePooling2D())\n",
    "\n",
    "    #layer-4 (1st dense layer)\n",
    "    model1.add(Dense(60, activation='relu'))\n",
    "    model1.add(Dropout(0.5))\n",
    "\n",
    "    #layer-5 (2nd dense layer)\n",
    "    model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # compile\n",
    "    model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7576162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fold(fold_number):\n",
    "    test_x = X_folds[fold_number - 1]\n",
    "    test_y = y_folds[fold_number - 1]\n",
    "\n",
    "    train_x = np.concatenate([X_folds[i] for i in range(10) if i != (fold_number - 1)], axis=0)\n",
    "    train_y = np.concatenate([y_folds[i] for i in range(10) if i != (fold_number - 1)], axis=0)\n",
    "\n",
    "    print(train_x.shape)\n",
    "    print(test_x.shape)\n",
    "    print(train_y.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    x_train = train_x.reshape(train_x.shape[0], num_rows, num_columns, num_channels)\n",
    "    x_test = test_x.reshape(test_x.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "    y_train_cat = train_y\n",
    "    y_test_cat = test_y\n",
    "\n",
    "    # Optional normalization (you may shift this to extract_features if better)\n",
    "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "    x_test = (x_test - np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    print('y_train shape:', train_y.shape)\n",
    "    print('y_test shape:', test_y.shape)\n",
    "\n",
    "    model = build_model((num_rows, num_columns, num_channels), num_labels)\n",
    "\n",
    "    # Compute class weights\n",
    "    y_train_labels = np.argmax(y_train_cat, axis=1)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_path = f\"saved_models/weights.fold{fold_number}.best.keras\"\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    print(f\"\\nTraining Fold {fold_number}...\")\n",
    "    start = datetime.now()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train_cat,\n",
    "        batch_size=num_batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_test, y_test_cat),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[checkpointer, earlystopper, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    duration = datetime.now() - start\n",
    "    print(f\"Fold {fold_number} training completed in time: {duration}\")\n",
    "\n",
    "    # Save final model\n",
    "    final_model_path = f\"saved_models/urban_sound_model_fold{fold_number}.final.keras\"\n",
    "    model.save(final_model_path)\n",
    "\n",
    "    # Post-training evaluation\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test_cat, axis=1)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nFold {fold_number} Post-Training Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold_number} Post-Training Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(model.evaluate(x_test, y_test_cat, verbose=0))\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82451667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combined():\n",
    "    # Combine all folds into one dataset\n",
    "    X = np.concatenate(X_folds, axis=0)\n",
    "    y = np.concatenate(y_folds, axis=0)  # Assume already one-hot encoded\n",
    "\n",
    "    num_labels = y.shape[1]\n",
    "\n",
    "    # Train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=np.argmax(y, axis=1))\n",
    "\n",
    "    # Reshape for CNN\n",
    "    x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "    # Optional normalization\n",
    "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "    x_test = (x_test - np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "    # Build model\n",
    "    model = build_model((num_rows, num_columns, num_channels), num_labels)\n",
    "\n",
    "    # Compute class weights\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_path = \"saved_models/weights.combined.best.keras\"\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nTraining Combined dataset...\")\n",
    "    start = datetime.now()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=num_batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[checkpointer, earlystopper, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    duration = datetime.now() - start\n",
    "    print(f\"Training completed in time: {duration}\")\n",
    "\n",
    "    # Save final model\n",
    "    final_model_path = \"saved_models/urban_sound_model_combined.final.keras\"\n",
    "    model.save(final_model_path)\n",
    "\n",
    "    # Post-training evaluation\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nPost-Training Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Post-Training Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"Evaluation:\", model.evaluate(x_test, y_test, verbose=0))\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1c54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7858, 40, 174, 1)\n",
      "x_test shape: (874, 40, 174, 1)\n",
      "y_train shape: (7858, 10)\n",
      "y_test shape: (874, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Combined dataset...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1194 - loss: 2.3178\n",
      "Epoch 1: val_loss improved from inf to 2.11675, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 956ms/step - accuracy: 0.1203 - loss: 2.3160 - val_accuracy: 0.2712 - val_loss: 2.1168 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2656 - loss: 2.0790\n",
      "Epoch 2: val_loss improved from 2.11675 to 1.77375, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.2660 - loss: 2.0763 - val_accuracy: 0.3627 - val_loss: 1.7737 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.3438 - loss: 1.7806\n",
      "Epoch 3: val_loss improved from 1.77375 to 1.59129, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.3445 - loss: 1.7788 - val_accuracy: 0.4794 - val_loss: 1.5913 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.4233 - loss: 1.5925\n",
      "Epoch 4: val_loss improved from 1.59129 to 1.47708, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.4237 - loss: 1.5916 - val_accuracy: 0.5092 - val_loss: 1.4771 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.4678 - loss: 1.4643\n",
      "Epoch 5: val_loss improved from 1.47708 to 1.39922, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.4679 - loss: 1.4641 - val_accuracy: 0.5057 - val_loss: 1.3992 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.4839 - loss: 1.4077\n",
      "Epoch 6: val_loss improved from 1.39922 to 1.31137, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.4841 - loss: 1.4070 - val_accuracy: 0.5355 - val_loss: 1.3114 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5149 - loss: 1.3289\n",
      "Epoch 7: val_loss improved from 1.31137 to 1.28441, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.5151 - loss: 1.3284 - val_accuracy: 0.5526 - val_loss: 1.2844 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.5183 - loss: 1.3118\n",
      "Epoch 8: val_loss improved from 1.28441 to 1.17252, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.5187 - loss: 1.3108 - val_accuracy: 0.5732 - val_loss: 1.1725 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.5347 - loss: 1.2650\n",
      "Epoch 9: val_loss improved from 1.17252 to 1.15740, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.5352 - loss: 1.2639 - val_accuracy: 0.5950 - val_loss: 1.1574 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.5604 - loss: 1.1951\n",
      "Epoch 10: val_loss improved from 1.15740 to 1.11341, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 277ms/step - accuracy: 0.5608 - loss: 1.1948 - val_accuracy: 0.6030 - val_loss: 1.1134 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5739 - loss: 1.1772\n",
      "Epoch 11: val_loss improved from 1.11341 to 1.09702, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.5739 - loss: 1.1771 - val_accuracy: 0.6362 - val_loss: 1.0970 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.5900 - loss: 1.1427\n",
      "Epoch 12: val_loss improved from 1.09702 to 1.04324, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 333ms/step - accuracy: 0.5900 - loss: 1.1424 - val_accuracy: 0.6487 - val_loss: 1.0432 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.6011 - loss: 1.1187\n",
      "Epoch 13: val_loss improved from 1.04324 to 1.01181, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.6013 - loss: 1.1183 - val_accuracy: 0.6682 - val_loss: 1.0118 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6196 - loss: 1.0714\n",
      "Epoch 14: val_loss improved from 1.01181 to 0.98599, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 988ms/step - accuracy: 0.6196 - loss: 1.0714 - val_accuracy: 0.6739 - val_loss: 0.9860 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6211 - loss: 1.0552\n",
      "Epoch 15: val_loss improved from 0.98599 to 0.96830, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 990ms/step - accuracy: 0.6211 - loss: 1.0552 - val_accuracy: 0.6705 - val_loss: 0.9683 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6337 - loss: 1.0433\n",
      "Epoch 16: val_loss improved from 0.96830 to 0.95579, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 999ms/step - accuracy: 0.6338 - loss: 1.0424 - val_accuracy: 0.6796 - val_loss: 0.9558 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6304 - loss: 1.0073\n",
      "Epoch 17: val_loss improved from 0.95579 to 0.91162, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 364ms/step - accuracy: 0.6307 - loss: 1.0071 - val_accuracy: 0.7071 - val_loss: 0.9116 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6635 - loss: 0.9626\n",
      "Epoch 18: val_loss improved from 0.91162 to 0.88774, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6634 - loss: 0.9625 - val_accuracy: 0.7128 - val_loss: 0.8877 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6646 - loss: 0.9509\n",
      "Epoch 19: val_loss improved from 0.88774 to 0.87483, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 725ms/step - accuracy: 0.6645 - loss: 0.9512 - val_accuracy: 0.7105 - val_loss: 0.8748 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6774 - loss: 0.9171\n",
      "Epoch 20: val_loss improved from 0.87483 to 0.84730, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 544ms/step - accuracy: 0.6773 - loss: 0.9175 - val_accuracy: 0.7243 - val_loss: 0.8473 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6759 - loss: 0.9318\n",
      "Epoch 21: val_loss improved from 0.84730 to 0.84716, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6760 - loss: 0.9314 - val_accuracy: 0.7254 - val_loss: 0.8472 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6838 - loss: 0.9040\n",
      "Epoch 22: val_loss improved from 0.84716 to 0.81463, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.6838 - loss: 0.9041 - val_accuracy: 0.7403 - val_loss: 0.8146 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6850 - loss: 0.8855\n",
      "Epoch 23: val_loss did not improve from 0.81463\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 455ms/step - accuracy: 0.6851 - loss: 0.8855 - val_accuracy: 0.7311 - val_loss: 0.8245 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7058 - loss: 0.8596\n",
      "Epoch 24: val_loss improved from 0.81463 to 0.79467, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 638ms/step - accuracy: 0.7057 - loss: 0.8596 - val_accuracy: 0.7426 - val_loss: 0.7947 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7052 - loss: 0.8560\n",
      "Epoch 25: val_loss improved from 0.79467 to 0.76589, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7052 - loss: 0.8557 - val_accuracy: 0.7609 - val_loss: 0.7659 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7133 - loss: 0.8361\n",
      "Epoch 26: val_loss improved from 0.76589 to 0.75453, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.7133 - loss: 0.8360 - val_accuracy: 0.7586 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7211 - loss: 0.8044\n",
      "Epoch 27: val_loss did not improve from 0.75453\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7211 - loss: 0.8047 - val_accuracy: 0.7597 - val_loss: 0.7653 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7313 - loss: 0.7886\n",
      "Epoch 28: val_loss improved from 0.75453 to 0.73992, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7311 - loss: 0.7889 - val_accuracy: 0.7643 - val_loss: 0.7399 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7325 - loss: 0.7836\n",
      "Epoch 29: val_loss improved from 0.73992 to 0.71750, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.7326 - loss: 0.7834 - val_accuracy: 0.7792 - val_loss: 0.7175 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7312 - loss: 0.7877\n",
      "Epoch 30: val_loss improved from 0.71750 to 0.71606, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.7312 - loss: 0.7877 - val_accuracy: 0.7746 - val_loss: 0.7161 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7295 - loss: 0.7740\n",
      "Epoch 31: val_loss did not improve from 0.71606\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 463ms/step - accuracy: 0.7297 - loss: 0.7739 - val_accuracy: 0.7620 - val_loss: 0.7350 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7531 - loss: 0.7477\n",
      "Epoch 32: val_loss did not improve from 0.71606\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 436ms/step - accuracy: 0.7530 - loss: 0.7478 - val_accuracy: 0.7574 - val_loss: 0.7646 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7509 - loss: 0.7379\n",
      "Epoch 33: val_loss improved from 0.71606 to 0.71143, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.7510 - loss: 0.7380 - val_accuracy: 0.7689 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7534 - loss: 0.7175\n",
      "Epoch 34: val_loss improved from 0.71143 to 0.69213, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.7532 - loss: 0.7179 - val_accuracy: 0.7643 - val_loss: 0.6921 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7425 - loss: 0.7408\n",
      "Epoch 35: val_loss improved from 0.69213 to 0.67528, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.7427 - loss: 0.7405 - val_accuracy: 0.7941 - val_loss: 0.6753 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7546 - loss: 0.7172\n",
      "Epoch 36: val_loss did not improve from 0.67528\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 449ms/step - accuracy: 0.7544 - loss: 0.7176 - val_accuracy: 0.7906 - val_loss: 0.6774 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7529 - loss: 0.7165\n",
      "Epoch 37: val_loss improved from 0.67528 to 0.63539, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7531 - loss: 0.7163 - val_accuracy: 0.8089 - val_loss: 0.6354 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7576 - loss: 0.7167\n",
      "Epoch 38: val_loss did not improve from 0.63539\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 458ms/step - accuracy: 0.7576 - loss: 0.7167 - val_accuracy: 0.7860 - val_loss: 0.7000 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7733 - loss: 0.6896\n",
      "Epoch 39: val_loss did not improve from 0.63539\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 456ms/step - accuracy: 0.7732 - loss: 0.6896 - val_accuracy: 0.7929 - val_loss: 0.6666 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7685 - loss: 0.6733\n",
      "Epoch 40: val_loss did not improve from 0.63539\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 458ms/step - accuracy: 0.7684 - loss: 0.6740 - val_accuracy: 0.8055 - val_loss: 0.6683 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7754 - loss: 0.6730\n",
      "Epoch 41: val_loss improved from 0.63539 to 0.61949, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.7754 - loss: 0.6729 - val_accuracy: 0.8124 - val_loss: 0.6195 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7849 - loss: 0.6442\n",
      "Epoch 42: val_loss improved from 0.61949 to 0.61610, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 306ms/step - accuracy: 0.7849 - loss: 0.6444 - val_accuracy: 0.8112 - val_loss: 0.6161 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7786 - loss: 0.6528\n",
      "Epoch 43: val_loss improved from 0.61610 to 0.59945, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.7788 - loss: 0.6524 - val_accuracy: 0.8169 - val_loss: 0.5994 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7940 - loss: 0.6310\n",
      "Epoch 44: val_loss did not improve from 0.59945\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.7941 - loss: 0.6312 - val_accuracy: 0.8192 - val_loss: 0.6242 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8061 - loss: 0.6014\n",
      "Epoch 45: val_loss improved from 0.59945 to 0.59258, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.8058 - loss: 0.6022 - val_accuracy: 0.8215 - val_loss: 0.5926 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7967 - loss: 0.6186\n",
      "Epoch 46: val_loss did not improve from 0.59258\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step - accuracy: 0.7967 - loss: 0.6187 - val_accuracy: 0.8146 - val_loss: 0.6009 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7988 - loss: 0.6117\n",
      "Epoch 47: val_loss did not improve from 0.59258\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7988 - loss: 0.6120 - val_accuracy: 0.8101 - val_loss: 0.5964 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7971 - loss: 0.6067\n",
      "Epoch 48: val_loss did not improve from 0.59258\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.7971 - loss: 0.6071 - val_accuracy: 0.8249 - val_loss: 0.5962 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8006 - loss: 0.6132\n",
      "Epoch 49: val_loss did not improve from 0.59258\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 461ms/step - accuracy: 0.8008 - loss: 0.6130 - val_accuracy: 0.8238 - val_loss: 0.6244 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8157 - loss: 0.5978\n",
      "Epoch 50: val_loss did not improve from 0.59258\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 462ms/step - accuracy: 0.8154 - loss: 0.5980 - val_accuracy: 0.8112 - val_loss: 0.6388 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8001 - loss: 0.5986\n",
      "Epoch 51: val_loss improved from 0.59258 to 0.58904, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.8001 - loss: 0.5989 - val_accuracy: 0.8192 - val_loss: 0.5890 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8103 - loss: 0.5987\n",
      "Epoch 52: val_loss improved from 0.58904 to 0.58028, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.8102 - loss: 0.5986 - val_accuracy: 0.8215 - val_loss: 0.5803 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8061 - loss: 0.6009\n",
      "Epoch 53: val_loss did not improve from 0.58028\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 464ms/step - accuracy: 0.8061 - loss: 0.6007 - val_accuracy: 0.8192 - val_loss: 0.5890 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.8075 - loss: 0.5913\n",
      "Epoch 54: val_loss did not improve from 0.58028\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 479ms/step - accuracy: 0.8074 - loss: 0.5916 - val_accuracy: 0.8295 - val_loss: 0.5892 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.8013 - loss: 0.5953\n",
      "Epoch 55: val_loss improved from 0.58028 to 0.57639, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.8015 - loss: 0.5951 - val_accuracy: 0.8192 - val_loss: 0.5764 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - accuracy: 0.8021 - loss: 0.5934\n",
      "Epoch 56: val_loss did not improve from 0.57639\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 820ms/step - accuracy: 0.8023 - loss: 0.5931 - val_accuracy: 0.8295 - val_loss: 0.5815 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.8034 - loss: 0.5974\n",
      "Epoch 57: val_loss improved from 0.57639 to 0.57267, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.8034 - loss: 0.5973 - val_accuracy: 0.8249 - val_loss: 0.5727 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8125 - loss: 0.5946\n",
      "Epoch 58: val_loss did not improve from 0.57267\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 629ms/step - accuracy: 0.8126 - loss: 0.5944 - val_accuracy: 0.8272 - val_loss: 0.5803 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8041 - loss: 0.6031\n",
      "Epoch 59: val_loss improved from 0.57267 to 0.56944, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.8043 - loss: 0.6025 - val_accuracy: 0.8352 - val_loss: 0.5694 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8071 - loss: 0.5915\n",
      "Epoch 60: val_loss improved from 0.56944 to 0.56532, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.8071 - loss: 0.5911 - val_accuracy: 0.8272 - val_loss: 0.5653 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8124 - loss: 0.5699\n",
      "Epoch 61: val_loss improved from 0.56532 to 0.56462, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.8124 - loss: 0.5701 - val_accuracy: 0.8410 - val_loss: 0.5646 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8154 - loss: 0.5767\n",
      "Epoch 62: val_loss did not improve from 0.56462\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.8153 - loss: 0.5770 - val_accuracy: 0.8295 - val_loss: 0.5648 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8152 - loss: 0.5773\n",
      "Epoch 63: val_loss did not improve from 0.56462\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8152 - loss: 0.5773 - val_accuracy: 0.8330 - val_loss: 0.5687 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8145 - loss: 0.5877\n",
      "Epoch 64: val_loss did not improve from 0.56462\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.8145 - loss: 0.5876 - val_accuracy: 0.8364 - val_loss: 0.5749 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.8118 - loss: 0.5694\n",
      "Epoch 65: val_loss improved from 0.56462 to 0.55162, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.8119 - loss: 0.5694 - val_accuracy: 0.8387 - val_loss: 0.5516 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8190 - loss: 0.5737\n",
      "Epoch 66: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.8190 - loss: 0.5737 - val_accuracy: 0.8410 - val_loss: 0.5549 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8185 - loss: 0.5674\n",
      "Epoch 67: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8185 - loss: 0.5673 - val_accuracy: 0.8284 - val_loss: 0.5610 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8151 - loss: 0.5664\n",
      "Epoch 68: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.8150 - loss: 0.5665 - val_accuracy: 0.8364 - val_loss: 0.5555 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8168 - loss: 0.5588\n",
      "Epoch 69: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8169 - loss: 0.5589 - val_accuracy: 0.8421 - val_loss: 0.5533 - learning_rate: 6.2500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8236 - loss: 0.5668\n",
      "Epoch 70: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - accuracy: 0.8236 - loss: 0.5666 - val_accuracy: 0.8330 - val_loss: 0.5555 - learning_rate: 6.2500e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8293 - loss: 0.5409\n",
      "Epoch 71: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.8290 - loss: 0.5416 - val_accuracy: 0.8364 - val_loss: 0.5673 - learning_rate: 6.2500e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8146 - loss: 0.5765\n",
      "Epoch 72: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.8147 - loss: 0.5764 - val_accuracy: 0.8387 - val_loss: 0.5548 - learning_rate: 3.1250e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8186 - loss: 0.5740\n",
      "Epoch 73: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8186 - loss: 0.5738 - val_accuracy: 0.8398 - val_loss: 0.5574 - learning_rate: 3.1250e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8207 - loss: 0.5656\n",
      "Epoch 74: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8207 - loss: 0.5655 - val_accuracy: 0.8375 - val_loss: 0.5539 - learning_rate: 3.1250e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8274 - loss: 0.5589\n",
      "Epoch 75: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.8273 - loss: 0.5588 - val_accuracy: 0.8375 - val_loss: 0.5535 - learning_rate: 1.5625e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8201 - loss: 0.5607\n",
      "Epoch 76: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.8202 - loss: 0.5606 - val_accuracy: 0.8398 - val_loss: 0.5533 - learning_rate: 1.5625e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8263 - loss: 0.5570\n",
      "Epoch 77: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8262 - loss: 0.5571 - val_accuracy: 0.8387 - val_loss: 0.5533 - learning_rate: 1.5625e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8239 - loss: 0.5636\n",
      "Epoch 78: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.8238 - loss: 0.5634 - val_accuracy: 0.8398 - val_loss: 0.5525 - learning_rate: 7.8125e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8238 - loss: 0.5567\n",
      "Epoch 79: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.8238 - loss: 0.5567 - val_accuracy: 0.8410 - val_loss: 0.5537 - learning_rate: 7.8125e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8211 - loss: 0.5614\n",
      "Epoch 80: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.8211 - loss: 0.5613 - val_accuracy: 0.8398 - val_loss: 0.5525 - learning_rate: 7.8125e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8278 - loss: 0.5473\n",
      "Epoch 81: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.8276 - loss: 0.5476 - val_accuracy: 0.8398 - val_loss: 0.5527 - learning_rate: 3.9063e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8285 - loss: 0.5554\n",
      "Epoch 82: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.8283 - loss: 0.5553 - val_accuracy: 0.8387 - val_loss: 0.5526 - learning_rate: 3.9063e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8192 - loss: 0.5527\n",
      "Epoch 83: val_loss did not improve from 0.55162\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.8193 - loss: 0.5528 - val_accuracy: 0.8398 - val_loss: 0.5528 - learning_rate: 3.9063e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8181 - loss: 0.5820\n",
      "Epoch 84: val_loss did not improve from 0.55162\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8182 - loss: 0.5813 - val_accuracy: 0.8398 - val_loss: 0.5522 - learning_rate: 1.9531e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8213 - loss: 0.5497\n",
      "Epoch 85: val_loss improved from 0.55162 to 0.55154, saving model to saved_models/weights.combined.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.8213 - loss: 0.5497 - val_accuracy: 0.8387 - val_loss: 0.5515 - learning_rate: 1.9531e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8223 - loss: 0.5557\n",
      "Epoch 86: val_loss did not improve from 0.55154\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.8221 - loss: 0.5559 - val_accuracy: 0.8387 - val_loss: 0.5523 - learning_rate: 1.9531e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8220 - loss: 0.5644\n",
      "Epoch 87: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.8219 - loss: 0.5642 - val_accuracy: 0.8387 - val_loss: 0.5518 - learning_rate: 1.0000e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8229 - loss: 0.5430\n",
      "Epoch 88: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.8229 - loss: 0.5431 - val_accuracy: 0.8398 - val_loss: 0.5520 - learning_rate: 1.0000e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8230 - loss: 0.5462\n",
      "Epoch 89: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.8229 - loss: 0.5464 - val_accuracy: 0.8387 - val_loss: 0.5522 - learning_rate: 1.0000e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8219 - loss: 0.5697\n",
      "Epoch 90: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.8220 - loss: 0.5694 - val_accuracy: 0.8398 - val_loss: 0.5523 - learning_rate: 1.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8111 - loss: 0.5801\n",
      "Epoch 91: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.8112 - loss: 0.5795 - val_accuracy: 0.8398 - val_loss: 0.5520 - learning_rate: 1.0000e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8132 - loss: 0.5628\n",
      "Epoch 92: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.8132 - loss: 0.5629 - val_accuracy: 0.8398 - val_loss: 0.5519 - learning_rate: 1.0000e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8234 - loss: 0.5590\n",
      "Epoch 93: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.8235 - loss: 0.5588 - val_accuracy: 0.8398 - val_loss: 0.5523 - learning_rate: 1.0000e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8266 - loss: 0.5473\n",
      "Epoch 94: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8266 - loss: 0.5472 - val_accuracy: 0.8398 - val_loss: 0.5519 - learning_rate: 1.0000e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8242 - loss: 0.5521\n",
      "Epoch 95: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8241 - loss: 0.5522 - val_accuracy: 0.8398 - val_loss: 0.5520 - learning_rate: 1.0000e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.8169 - loss: 0.5694\n",
      "Epoch 96: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.8170 - loss: 0.5691 - val_accuracy: 0.8398 - val_loss: 0.5521 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8217 - loss: 0.5651\n",
      "Epoch 97: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8218 - loss: 0.5648 - val_accuracy: 0.8398 - val_loss: 0.5522 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8357 - loss: 0.5427\n",
      "Epoch 98: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8354 - loss: 0.5433 - val_accuracy: 0.8398 - val_loss: 0.5526 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8178 - loss: 0.5576\n",
      "Epoch 99: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8179 - loss: 0.5575 - val_accuracy: 0.8398 - val_loss: 0.5521 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8240 - loss: 0.5476\n",
      "Epoch 100: val_loss did not improve from 0.55154\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8240 - loss: 0.5479 - val_accuracy: 0.8398 - val_loss: 0.5519 - learning_rate: 1.0000e-06\n",
      "Training completed in time: 0:23:27.774726\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Post-Training Train Accuracy: 0.8217\n",
      "Post-Training Test Accuracy: 0.8387\n",
      "Evaluation: [0.5515395998954773, 0.8386727571487427]\n",
      "0.8217103481292725\n",
      "0.8386727688787186\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_combined()\n",
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740c05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7859, 40, 174)\n",
      "(873, 40, 174)\n",
      "(7859, 10)\n",
      "(873, 10)\n",
      "x_train shape: (7859, 40, 174, 1)\n",
      "x_test shape: (873, 40, 174, 1)\n",
      "y_train shape: (7859, 10)\n",
      "y_test shape: (873, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1...\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1271 - loss: 2.2897\n",
      "Epoch 1: val_loss improved from inf to 2.16821, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.1277 - loss: 2.2883 - val_accuracy: 0.2749 - val_loss: 2.1682 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2706 - loss: 2.0472\n",
      "Epoch 2: val_loss improved from 2.16821 to 1.90423, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.2715 - loss: 2.0451 - val_accuracy: 0.3677 - val_loss: 1.9042 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3592 - loss: 1.8080\n",
      "Epoch 3: val_loss improved from 1.90423 to 1.78894, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.3601 - loss: 1.8058 - val_accuracy: 0.4926 - val_loss: 1.7889 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4474 - loss: 1.5880\n",
      "Epoch 4: val_loss improved from 1.78894 to 1.67993, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 645ms/step - accuracy: 0.4477 - loss: 1.5865 - val_accuracy: 0.5200 - val_loss: 1.6799 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.4837 - loss: 1.4202\n",
      "Epoch 5: val_loss improved from 1.67993 to 1.60833, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4842 - loss: 1.4194 - val_accuracy: 0.5304 - val_loss: 1.6083 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5230 - loss: 1.3231\n",
      "Epoch 6: val_loss did not improve from 1.60833\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.5233 - loss: 1.3223 - val_accuracy: 0.5601 - val_loss: 1.6157 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5451 - loss: 1.2708\n",
      "Epoch 7: val_loss improved from 1.60833 to 1.60194, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 876ms/step - accuracy: 0.5454 - loss: 1.2697 - val_accuracy: 0.5430 - val_loss: 1.6019 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5737 - loss: 1.1914\n",
      "Epoch 8: val_loss improved from 1.60194 to 1.59651, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.5738 - loss: 1.1907 - val_accuracy: 0.5544 - val_loss: 1.5965 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5984 - loss: 1.1098\n",
      "Epoch 9: val_loss improved from 1.59651 to 1.51095, saving model to saved_models/weights.fold1.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5983 - loss: 1.1103 - val_accuracy: 0.5487 - val_loss: 1.5110 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6034 - loss: 1.0888\n",
      "Epoch 10: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6037 - loss: 1.0885 - val_accuracy: 0.5659 - val_loss: 1.5314 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6251 - loss: 1.0479\n",
      "Epoch 11: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.6251 - loss: 1.0479 - val_accuracy: 0.5407 - val_loss: 1.5939 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6332 - loss: 1.0307\n",
      "Epoch 12: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.6332 - loss: 1.0305 - val_accuracy: 0.5613 - val_loss: 1.6020 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.6511 - loss: 0.9901\n",
      "Epoch 13: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.6512 - loss: 0.9898 - val_accuracy: 0.5716 - val_loss: 1.5350 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6616 - loss: 0.9787\n",
      "Epoch 14: val_loss did not improve from 1.51095\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - accuracy: 0.6616 - loss: 0.9782 - val_accuracy: 0.5773 - val_loss: 1.5138 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6747 - loss: 0.9359\n",
      "Epoch 15: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.6748 - loss: 0.9356 - val_accuracy: 0.5578 - val_loss: 1.5947 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6710 - loss: 0.9289\n",
      "Epoch 16: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.6712 - loss: 0.9285 - val_accuracy: 0.5785 - val_loss: 1.5394 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.6801 - loss: 0.8988\n",
      "Epoch 17: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.6801 - loss: 0.8987 - val_accuracy: 0.5670 - val_loss: 1.5701 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6921 - loss: 0.8958\n",
      "Epoch 18: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 491ms/step - accuracy: 0.6922 - loss: 0.8955 - val_accuracy: 0.5521 - val_loss: 1.5586 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6839 - loss: 0.9048\n",
      "Epoch 19: val_loss did not improve from 1.51095\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 620ms/step - accuracy: 0.6840 - loss: 0.9044 - val_accuracy: 0.5785 - val_loss: 1.5539 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6907 - loss: 0.8939\n",
      "Epoch 20: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.6910 - loss: 0.8932 - val_accuracy: 0.5785 - val_loss: 1.5583 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7015 - loss: 0.8732\n",
      "Epoch 21: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - accuracy: 0.7015 - loss: 0.8729 - val_accuracy: 0.5785 - val_loss: 1.5487 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7095 - loss: 0.8545\n",
      "Epoch 22: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 723ms/step - accuracy: 0.7094 - loss: 0.8546 - val_accuracy: 0.5796 - val_loss: 1.5747 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6991 - loss: 0.8624\n",
      "Epoch 23: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 548ms/step - accuracy: 0.6993 - loss: 0.8623 - val_accuracy: 0.5796 - val_loss: 1.5482 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7076 - loss: 0.8490\n",
      "Epoch 24: val_loss did not improve from 1.51095\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.7078 - loss: 0.8485 - val_accuracy: 0.5739 - val_loss: 1.5727 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7050 - loss: 0.8444\n",
      "Epoch 25: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 450ms/step - accuracy: 0.7052 - loss: 0.8439 - val_accuracy: 0.5762 - val_loss: 1.5687 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7130 - loss: 0.8360\n",
      "Epoch 26: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 631ms/step - accuracy: 0.7131 - loss: 0.8360 - val_accuracy: 0.5842 - val_loss: 1.5650 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7113 - loss: 0.8363\n",
      "Epoch 27: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 636ms/step - accuracy: 0.7114 - loss: 0.8361 - val_accuracy: 0.5785 - val_loss: 1.5796 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7188 - loss: 0.8193\n",
      "Epoch 28: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step - accuracy: 0.7187 - loss: 0.8196 - val_accuracy: 0.5693 - val_loss: 1.5693 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7170 - loss: 0.8155\n",
      "Epoch 29: val_loss did not improve from 1.51095\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 452ms/step - accuracy: 0.7169 - loss: 0.8157 - val_accuracy: 0.5704 - val_loss: 1.5713 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.7188 - loss: 0.8193\n",
      "Epoch 30: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 453ms/step - accuracy: 0.7187 - loss: 0.8193 - val_accuracy: 0.5830 - val_loss: 1.5567 - learning_rate: 6.2500e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7274 - loss: 0.8188\n",
      "Epoch 31: val_loss did not improve from 1.51095\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 444ms/step - accuracy: 0.7273 - loss: 0.8188 - val_accuracy: 0.5830 - val_loss: 1.5664 - learning_rate: 6.2500e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 0.7196 - loss: 0.8424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n\u001b[0;32m      3\u001b[0m fold_accuracies\u001b[38;5;241m.\u001b[39mappend(test_accuracy)\n",
      "Cell \u001b[1;32mIn[13], line 44\u001b[0m, in \u001b[0;36mrun_fold\u001b[1;34m(fold_number)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m---> 44\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlystopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training completed in time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\TB Pal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(1)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7844, 40, 174)\n",
      "(888, 40, 174)\n",
      "(7844, 10)\n",
      "(888, 10)\n",
      "x_train shape: (7844, 40, 174, 1)\n",
      "x_test shape: (888, 40, 174, 1)\n",
      "y_train shape: (7844, 10)\n",
      "y_test shape: (888, 10)\n",
      "\n",
      "Training Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1330 - loss: 2.3031\n",
      "Epoch 1: val_loss improved from inf to 2.06832, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 252ms/step - accuracy: 0.1336 - loss: 2.3018 - val_accuracy: 0.3266 - val_loss: 2.0683 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2481 - loss: 2.0841\n",
      "Epoch 2: val_loss improved from 2.06832 to 1.78356, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 358ms/step - accuracy: 0.2488 - loss: 2.0823 - val_accuracy: 0.3649 - val_loss: 1.7836 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3447 - loss: 1.8035\n",
      "Epoch 3: val_loss improved from 1.78356 to 1.53594, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 451ms/step - accuracy: 0.3454 - loss: 1.8018 - val_accuracy: 0.4809 - val_loss: 1.5359 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.4203 - loss: 1.5923\n",
      "Epoch 4: val_loss improved from 1.53594 to 1.45011, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.4206 - loss: 1.5919 - val_accuracy: 0.5248 - val_loss: 1.4501 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.4567 - loss: 1.5023\n",
      "Epoch 5: val_loss improved from 1.45011 to 1.38393, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.4567 - loss: 1.5015 - val_accuracy: 0.5631 - val_loss: 1.3839 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4813 - loss: 1.3936\n",
      "Epoch 6: val_loss improved from 1.38393 to 1.37182, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 448ms/step - accuracy: 0.4815 - loss: 1.3936 - val_accuracy: 0.5484 - val_loss: 1.3718 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5075 - loss: 1.3372\n",
      "Epoch 7: val_loss improved from 1.37182 to 1.31368, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.5077 - loss: 1.3370 - val_accuracy: 0.5552 - val_loss: 1.3137 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5333 - loss: 1.2790\n",
      "Epoch 8: val_loss improved from 1.31368 to 1.25034, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.5336 - loss: 1.2788 - val_accuracy: 0.5800 - val_loss: 1.2503 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5399 - loss: 1.2365\n",
      "Epoch 9: val_loss improved from 1.25034 to 1.22335, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 358ms/step - accuracy: 0.5403 - loss: 1.2358 - val_accuracy: 0.5946 - val_loss: 1.2233 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5688 - loss: 1.1770\n",
      "Epoch 10: val_loss improved from 1.22335 to 1.20601, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.5689 - loss: 1.1769 - val_accuracy: 0.5856 - val_loss: 1.2060 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5794 - loss: 1.1417\n",
      "Epoch 11: val_loss improved from 1.20601 to 1.15652, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.5796 - loss: 1.1415 - val_accuracy: 0.6047 - val_loss: 1.1565 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5943 - loss: 1.1186\n",
      "Epoch 12: val_loss did not improve from 1.15652\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.5945 - loss: 1.1182 - val_accuracy: 0.5991 - val_loss: 1.1607 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6138 - loss: 1.0689\n",
      "Epoch 13: val_loss improved from 1.15652 to 1.12353, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.6138 - loss: 1.0689 - val_accuracy: 0.6216 - val_loss: 1.1235 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6210 - loss: 1.0388\n",
      "Epoch 14: val_loss did not improve from 1.12353\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.6211 - loss: 1.0392 - val_accuracy: 0.5980 - val_loss: 1.1464 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6278 - loss: 1.0493\n",
      "Epoch 15: val_loss did not improve from 1.12353\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.6279 - loss: 1.0489 - val_accuracy: 0.5991 - val_loss: 1.1278 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6471 - loss: 1.0063\n",
      "Epoch 16: val_loss did not improve from 1.12353\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.6470 - loss: 1.0066 - val_accuracy: 0.6273 - val_loss: 1.1456 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6459 - loss: 0.9900\n",
      "Epoch 17: val_loss improved from 1.12353 to 1.09041, saving model to saved_models/weights.fold2.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.6461 - loss: 0.9898 - val_accuracy: 0.6453 - val_loss: 1.0904 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6708 - loss: 0.9404\n",
      "Epoch 18: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.6709 - loss: 0.9406 - val_accuracy: 0.6318 - val_loss: 1.0966 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6743 - loss: 0.9357\n",
      "Epoch 19: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.6745 - loss: 0.9353 - val_accuracy: 0.6486 - val_loss: 1.0936 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6726 - loss: 0.9140\n",
      "Epoch 20: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.6729 - loss: 0.9139 - val_accuracy: 0.5766 - val_loss: 1.1145 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7032 - loss: 0.8718\n",
      "Epoch 21: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7030 - loss: 0.8722 - val_accuracy: 0.5664 - val_loss: 1.1093 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6961 - loss: 0.8976\n",
      "Epoch 22: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.6962 - loss: 0.8970 - val_accuracy: 0.5833 - val_loss: 1.1018 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7145 - loss: 0.8373\n",
      "Epoch 23: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.7144 - loss: 0.8375 - val_accuracy: 0.5890 - val_loss: 1.0969 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7196 - loss: 0.8154\n",
      "Epoch 24: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7193 - loss: 0.8159 - val_accuracy: 0.5901 - val_loss: 1.1466 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7083 - loss: 0.8480\n",
      "Epoch 25: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7086 - loss: 0.8475 - val_accuracy: 0.5777 - val_loss: 1.1316 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7312 - loss: 0.8161\n",
      "Epoch 26: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.7310 - loss: 0.8163 - val_accuracy: 0.6059 - val_loss: 1.1167 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7150 - loss: 0.8117\n",
      "Epoch 27: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7152 - loss: 0.8117 - val_accuracy: 0.5991 - val_loss: 1.1314 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7208 - loss: 0.8064\n",
      "Epoch 28: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7210 - loss: 0.8059 - val_accuracy: 0.6171 - val_loss: 1.1177 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7391 - loss: 0.7745\n",
      "Epoch 29: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7391 - loss: 0.7747 - val_accuracy: 0.6036 - val_loss: 1.1209 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7291 - loss: 0.7779\n",
      "Epoch 30: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7292 - loss: 0.7782 - val_accuracy: 0.5957 - val_loss: 1.1213 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7363 - loss: 0.7822\n",
      "Epoch 31: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7363 - loss: 0.7823 - val_accuracy: 0.6194 - val_loss: 1.0952 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7317 - loss: 0.7954\n",
      "Epoch 32: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7318 - loss: 0.7950 - val_accuracy: 0.6205 - val_loss: 1.1131 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7431 - loss: 0.7661\n",
      "Epoch 33: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7429 - loss: 0.7661 - val_accuracy: 0.6036 - val_loss: 1.1271 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7409 - loss: 0.7609\n",
      "Epoch 34: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7409 - loss: 0.7611 - val_accuracy: 0.6036 - val_loss: 1.1248 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7444 - loss: 0.7663\n",
      "Epoch 35: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7442 - loss: 0.7666 - val_accuracy: 0.6137 - val_loss: 1.1190 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7435 - loss: 0.7558\n",
      "Epoch 36: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7435 - loss: 0.7558 - val_accuracy: 0.6081 - val_loss: 1.1195 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7381 - loss: 0.7691\n",
      "Epoch 37: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7380 - loss: 0.7692 - val_accuracy: 0.6047 - val_loss: 1.1259 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7480 - loss: 0.7411\n",
      "Epoch 38: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7477 - loss: 0.7417 - val_accuracy: 0.6047 - val_loss: 1.1266 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7452 - loss: 0.7574\n",
      "Epoch 39: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7453 - loss: 0.7574 - val_accuracy: 0.6047 - val_loss: 1.1349 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7470 - loss: 0.7642\n",
      "Epoch 40: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7471 - loss: 0.7639 - val_accuracy: 0.6047 - val_loss: 1.1286 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7503 - loss: 0.7448\n",
      "Epoch 41: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7500 - loss: 0.7452 - val_accuracy: 0.6047 - val_loss: 1.1264 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7367 - loss: 0.7638\n",
      "Epoch 42: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.7368 - loss: 0.7637 - val_accuracy: 0.6014 - val_loss: 1.1222 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7499 - loss: 0.7447\n",
      "Epoch 43: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.7499 - loss: 0.7444 - val_accuracy: 0.6036 - val_loss: 1.1208 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7511 - loss: 0.7365\n",
      "Epoch 44: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.7511 - loss: 0.7369 - val_accuracy: 0.6059 - val_loss: 1.1288 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7451 - loss: 0.7495\n",
      "Epoch 45: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.7449 - loss: 0.7495 - val_accuracy: 0.6014 - val_loss: 1.1245 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7388 - loss: 0.7704\n",
      "Epoch 46: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.7390 - loss: 0.7697 - val_accuracy: 0.6014 - val_loss: 1.1439 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.7523 - loss: 0.7416\n",
      "Epoch 47: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.7522 - loss: 0.7417 - val_accuracy: 0.6059 - val_loss: 1.1304 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.7535 - loss: 0.7355\n",
      "Epoch 48: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.7533 - loss: 0.7359 - val_accuracy: 0.6047 - val_loss: 1.1234 - learning_rate: 1.5625e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.7410 - loss: 0.7551\n",
      "Epoch 49: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.7411 - loss: 0.7546 - val_accuracy: 0.6070 - val_loss: 1.1239 - learning_rate: 1.5625e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7475 - loss: 0.7303\n",
      "Epoch 50: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7474 - loss: 0.7307 - val_accuracy: 0.6047 - val_loss: 1.1232 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7523 - loss: 0.7386\n",
      "Epoch 51: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.7522 - loss: 0.7389 - val_accuracy: 0.6070 - val_loss: 1.1220 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7416 - loss: 0.7554\n",
      "Epoch 52: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.7419 - loss: 0.7553 - val_accuracy: 0.6059 - val_loss: 1.1282 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.7462 - loss: 0.7512\n",
      "Epoch 53: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.7462 - loss: 0.7513 - val_accuracy: 0.6014 - val_loss: 1.1249 - learning_rate: 7.8125e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7449 - loss: 0.7413\n",
      "Epoch 54: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.7451 - loss: 0.7411 - val_accuracy: 0.6070 - val_loss: 1.1281 - learning_rate: 7.8125e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7426 - loss: 0.7568\n",
      "Epoch 55: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.7428 - loss: 0.7566 - val_accuracy: 0.6036 - val_loss: 1.1247 - learning_rate: 7.8125e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7494 - loss: 0.7481\n",
      "Epoch 56: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.7495 - loss: 0.7480 - val_accuracy: 0.6036 - val_loss: 1.1234 - learning_rate: 7.8125e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7475 - loss: 0.7453\n",
      "Epoch 57: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.7476 - loss: 0.7452 - val_accuracy: 0.6059 - val_loss: 1.1252 - learning_rate: 7.8125e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7539 - loss: 0.7385\n",
      "Epoch 58: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7538 - loss: 0.7387 - val_accuracy: 0.6059 - val_loss: 1.1252 - learning_rate: 3.9063e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7427 - loss: 0.7333\n",
      "Epoch 59: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.7428 - loss: 0.7337 - val_accuracy: 0.6036 - val_loss: 1.1267 - learning_rate: 3.9063e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7547 - loss: 0.7488\n",
      "Epoch 60: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.7547 - loss: 0.7488 - val_accuracy: 0.6047 - val_loss: 1.1258 - learning_rate: 3.9063e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7466 - loss: 0.7567\n",
      "Epoch 61: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7465 - loss: 0.7563 - val_accuracy: 0.6047 - val_loss: 1.1264 - learning_rate: 3.9063e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7431 - loss: 0.7551\n",
      "Epoch 62: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7431 - loss: 0.7551 - val_accuracy: 0.6059 - val_loss: 1.1263 - learning_rate: 3.9063e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7519 - loss: 0.7447\n",
      "Epoch 63: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7517 - loss: 0.7449 - val_accuracy: 0.6059 - val_loss: 1.1261 - learning_rate: 1.9531e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7515 - loss: 0.7370\n",
      "Epoch 64: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7514 - loss: 0.7372 - val_accuracy: 0.6047 - val_loss: 1.1253 - learning_rate: 1.9531e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7524 - loss: 0.7571\n",
      "Epoch 65: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7525 - loss: 0.7568 - val_accuracy: 0.6047 - val_loss: 1.1255 - learning_rate: 1.9531e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7392 - loss: 0.7598\n",
      "Epoch 66: val_loss did not improve from 1.09041\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7396 - loss: 0.7592 - val_accuracy: 0.6047 - val_loss: 1.1250 - learning_rate: 1.9531e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7490 - loss: 0.7400\n",
      "Epoch 67: val_loss did not improve from 1.09041\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7491 - loss: 0.7401 - val_accuracy: 0.6059 - val_loss: 1.1261 - learning_rate: 1.9531e-06\n",
      "Fold 2 training completed in time: 0:06:42.571733\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\n",
      "Fold 2 Post-Training Train Accuracy: 0.7501\n",
      "Fold 2 Post-Training Test Accuracy: 0.6453\n",
      "[1.0904115438461304, 0.6452702879905701]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(2)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7807, 40, 174)\n",
      "(925, 40, 174)\n",
      "(7807, 10)\n",
      "(925, 10)\n",
      "x_train shape: (7807, 40, 174, 1)\n",
      "x_test shape: (925, 40, 174, 1)\n",
      "y_train shape: (7807, 10)\n",
      "y_test shape: (925, 10)\n",
      "\n",
      "Training Fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.1133 - loss: 2.2923\n",
      "Epoch 1: val_loss improved from inf to 2.14178, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 244ms/step - accuracy: 0.1139 - loss: 2.2914 - val_accuracy: 0.1730 - val_loss: 2.1418 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2591 - loss: 2.0970\n",
      "Epoch 2: val_loss improved from 2.14178 to 1.83074, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 356ms/step - accuracy: 0.2599 - loss: 2.0947 - val_accuracy: 0.3686 - val_loss: 1.8307 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.3619 - loss: 1.8212\n",
      "Epoch 3: val_loss improved from 1.83074 to 1.67026, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 538ms/step - accuracy: 0.3623 - loss: 1.8201 - val_accuracy: 0.4011 - val_loss: 1.6703 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4090 - loss: 1.6546\n",
      "Epoch 4: val_loss improved from 1.67026 to 1.58183, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.4092 - loss: 1.6539 - val_accuracy: 0.4497 - val_loss: 1.5818 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4417 - loss: 1.5491\n",
      "Epoch 5: val_loss did not improve from 1.58183\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.4420 - loss: 1.5482 - val_accuracy: 0.4184 - val_loss: 1.5986 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.4883 - loss: 1.4169\n",
      "Epoch 6: val_loss did not improve from 1.58183\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.4882 - loss: 1.4169 - val_accuracy: 0.4411 - val_loss: 1.6532 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4847 - loss: 1.4045\n",
      "Epoch 7: val_loss improved from 1.58183 to 1.52298, saving model to saved_models/weights.fold3.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.4852 - loss: 1.4039 - val_accuracy: 0.5135 - val_loss: 1.5230 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5226 - loss: 1.3182\n",
      "Epoch 8: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.5228 - loss: 1.3178 - val_accuracy: 0.4519 - val_loss: 1.5713 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5382 - loss: 1.2625\n",
      "Epoch 9: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.5385 - loss: 1.2625 - val_accuracy: 0.4454 - val_loss: 1.7477 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5600 - loss: 1.2314\n",
      "Epoch 10: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.5602 - loss: 1.2312 - val_accuracy: 0.5481 - val_loss: 1.5502 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5711 - loss: 1.2065\n",
      "Epoch 11: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.5713 - loss: 1.2057 - val_accuracy: 0.4876 - val_loss: 1.6137 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5913 - loss: 1.1718\n",
      "Epoch 12: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.5913 - loss: 1.1717 - val_accuracy: 0.4832 - val_loss: 1.6721 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6134 - loss: 1.0887\n",
      "Epoch 13: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.6131 - loss: 1.0894 - val_accuracy: 0.4854 - val_loss: 1.5980 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6239 - loss: 1.0755\n",
      "Epoch 14: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.6236 - loss: 1.0760 - val_accuracy: 0.4800 - val_loss: 1.5909 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6236 - loss: 1.0858\n",
      "Epoch 15: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.6235 - loss: 1.0861 - val_accuracy: 0.4897 - val_loss: 1.6196 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6261 - loss: 1.0701\n",
      "Epoch 16: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.6261 - loss: 1.0700 - val_accuracy: 0.4778 - val_loss: 1.7009 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6336 - loss: 1.0617\n",
      "Epoch 17: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.6337 - loss: 1.0615 - val_accuracy: 0.4984 - val_loss: 1.6271 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6346 - loss: 1.0441\n",
      "Epoch 18: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.6346 - loss: 1.0441 - val_accuracy: 0.5027 - val_loss: 1.6222 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6385 - loss: 1.0347\n",
      "Epoch 19: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.6385 - loss: 1.0349 - val_accuracy: 0.4908 - val_loss: 1.6264 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6416 - loss: 1.0457\n",
      "Epoch 20: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.6415 - loss: 1.0455 - val_accuracy: 0.5005 - val_loss: 1.6799 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6419 - loss: 1.0425\n",
      "Epoch 21: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.6420 - loss: 1.0420 - val_accuracy: 0.4832 - val_loss: 1.6764 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6481 - loss: 1.0214\n",
      "Epoch 22: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.6480 - loss: 1.0215 - val_accuracy: 0.4984 - val_loss: 1.6118 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6515 - loss: 1.0109\n",
      "Epoch 23: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.6517 - loss: 1.0108 - val_accuracy: 0.4962 - val_loss: 1.7095 - learning_rate: 1.2500e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6529 - loss: 0.9955\n",
      "Epoch 24: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.6529 - loss: 0.9956 - val_accuracy: 0.4941 - val_loss: 1.6789 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6517 - loss: 1.0146\n",
      "Epoch 25: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.6517 - loss: 1.0146 - val_accuracy: 0.4951 - val_loss: 1.6897 - learning_rate: 1.2500e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6615 - loss: 0.9824\n",
      "Epoch 26: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.6616 - loss: 0.9825 - val_accuracy: 0.5016 - val_loss: 1.6883 - learning_rate: 1.2500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.6587 - loss: 0.9855\n",
      "Epoch 27: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.6586 - loss: 0.9857 - val_accuracy: 0.4822 - val_loss: 1.7075 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6551 - loss: 0.9866\n",
      "Epoch 28: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - accuracy: 0.6551 - loss: 0.9866 - val_accuracy: 0.4865 - val_loss: 1.7395 - learning_rate: 6.2500e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6625 - loss: 0.9878\n",
      "Epoch 29: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.6624 - loss: 0.9880 - val_accuracy: 0.4930 - val_loss: 1.7141 - learning_rate: 6.2500e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6613 - loss: 1.0007\n",
      "Epoch 30: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - accuracy: 0.6611 - loss: 1.0005 - val_accuracy: 0.4951 - val_loss: 1.7211 - learning_rate: 6.2500e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6592 - loss: 0.9986\n",
      "Epoch 31: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.6593 - loss: 0.9979 - val_accuracy: 0.4995 - val_loss: 1.7149 - learning_rate: 6.2500e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6581 - loss: 0.9742\n",
      "Epoch 32: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - accuracy: 0.6581 - loss: 0.9744 - val_accuracy: 0.4930 - val_loss: 1.7274 - learning_rate: 6.2500e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6596 - loss: 0.9658\n",
      "Epoch 33: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.6596 - loss: 0.9661 - val_accuracy: 0.4962 - val_loss: 1.7210 - learning_rate: 3.1250e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6619 - loss: 0.9783\n",
      "Epoch 34: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.6618 - loss: 0.9782 - val_accuracy: 0.4951 - val_loss: 1.7382 - learning_rate: 3.1250e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6592 - loss: 0.9732\n",
      "Epoch 35: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.6593 - loss: 0.9735 - val_accuracy: 0.5005 - val_loss: 1.7099 - learning_rate: 3.1250e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6602 - loss: 0.9814\n",
      "Epoch 36: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.6603 - loss: 0.9811 - val_accuracy: 0.4973 - val_loss: 1.7115 - learning_rate: 3.1250e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6663 - loss: 0.9605\n",
      "Epoch 37: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.6663 - loss: 0.9608 - val_accuracy: 0.5038 - val_loss: 1.7128 - learning_rate: 3.1250e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6697 - loss: 0.9662\n",
      "Epoch 38: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.6694 - loss: 0.9668 - val_accuracy: 0.5005 - val_loss: 1.7083 - learning_rate: 1.5625e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6661 - loss: 0.9672\n",
      "Epoch 39: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.6659 - loss: 0.9676 - val_accuracy: 0.5005 - val_loss: 1.7126 - learning_rate: 1.5625e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6562 - loss: 0.9828\n",
      "Epoch 40: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.6564 - loss: 0.9828 - val_accuracy: 0.5016 - val_loss: 1.7213 - learning_rate: 1.5625e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6676 - loss: 0.9867\n",
      "Epoch 41: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.6677 - loss: 0.9864 - val_accuracy: 0.4995 - val_loss: 1.7079 - learning_rate: 1.5625e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6699 - loss: 0.9573\n",
      "Epoch 42: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.6701 - loss: 0.9574 - val_accuracy: 0.5027 - val_loss: 1.7100 - learning_rate: 1.5625e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6645 - loss: 0.9763\n",
      "Epoch 43: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.6645 - loss: 0.9760 - val_accuracy: 0.4995 - val_loss: 1.7204 - learning_rate: 7.8125e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6705 - loss: 0.9639\n",
      "Epoch 44: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.6704 - loss: 0.9645 - val_accuracy: 0.5005 - val_loss: 1.7115 - learning_rate: 7.8125e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6691 - loss: 0.9718\n",
      "Epoch 45: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.6689 - loss: 0.9721 - val_accuracy: 0.4984 - val_loss: 1.7217 - learning_rate: 7.8125e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6678 - loss: 0.9681\n",
      "Epoch 46: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.6677 - loss: 0.9681 - val_accuracy: 0.4984 - val_loss: 1.7143 - learning_rate: 7.8125e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6573 - loss: 0.9719\n",
      "Epoch 47: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.6574 - loss: 0.9719 - val_accuracy: 0.4995 - val_loss: 1.7199 - learning_rate: 7.8125e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6702 - loss: 0.9632\n",
      "Epoch 48: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.6702 - loss: 0.9632 - val_accuracy: 0.4984 - val_loss: 1.7179 - learning_rate: 3.9063e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6714 - loss: 0.9565\n",
      "Epoch 49: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.6714 - loss: 0.9569 - val_accuracy: 0.4995 - val_loss: 1.7161 - learning_rate: 3.9063e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6634 - loss: 0.9711\n",
      "Epoch 50: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.6635 - loss: 0.9709 - val_accuracy: 0.5005 - val_loss: 1.7155 - learning_rate: 3.9063e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6597 - loss: 0.9762\n",
      "Epoch 51: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.6598 - loss: 0.9760 - val_accuracy: 0.4995 - val_loss: 1.7177 - learning_rate: 3.9063e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6571 - loss: 0.9856\n",
      "Epoch 52: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.6573 - loss: 0.9852 - val_accuracy: 0.4995 - val_loss: 1.7155 - learning_rate: 3.9063e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6581 - loss: 0.9784\n",
      "Epoch 53: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.6585 - loss: 0.9780 - val_accuracy: 0.4995 - val_loss: 1.7168 - learning_rate: 1.9531e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.6781 - loss: 0.9502\n",
      "Epoch 54: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.6776 - loss: 0.9509 - val_accuracy: 0.4995 - val_loss: 1.7160 - learning_rate: 1.9531e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6675 - loss: 0.9765\n",
      "Epoch 55: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.6675 - loss: 0.9761 - val_accuracy: 0.4995 - val_loss: 1.7166 - learning_rate: 1.9531e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6637 - loss: 0.9788\n",
      "Epoch 56: val_loss did not improve from 1.52298\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.6637 - loss: 0.9788 - val_accuracy: 0.4995 - val_loss: 1.7187 - learning_rate: 1.9531e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6566 - loss: 0.9745\n",
      "Epoch 57: val_loss did not improve from 1.52298\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.6566 - loss: 0.9744 - val_accuracy: 0.4995 - val_loss: 1.7167 - learning_rate: 1.9531e-06\n",
      "Fold 3 training completed in time: 0:05:20.865955\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      "Fold 3 Post-Training Train Accuracy: 0.6576\n",
      "Fold 3 Post-Training Test Accuracy: 0.5135\n",
      "[1.5229825973510742, 0.5135135054588318]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(3)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7742, 40, 174)\n",
      "(990, 40, 174)\n",
      "(7742, 10)\n",
      "(990, 10)\n",
      "x_train shape: (7742, 40, 174, 1)\n",
      "x_test shape: (990, 40, 174, 1)\n",
      "y_train shape: (7742, 10)\n",
      "y_test shape: (990, 10)\n",
      "\n",
      "Training Fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1136 - loss: 2.2926\n",
      "Epoch 1: val_loss improved from inf to 2.11236, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 246ms/step - accuracy: 0.1143 - loss: 2.2919 - val_accuracy: 0.2242 - val_loss: 2.1124 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.2659 - loss: 2.0635\n",
      "Epoch 2: val_loss improved from 2.11236 to 1.72687, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 449ms/step - accuracy: 0.2674 - loss: 2.0582 - val_accuracy: 0.4111 - val_loss: 1.7269 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.3588 - loss: 1.7636\n",
      "Epoch 3: val_loss improved from 1.72687 to 1.56103, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 371ms/step - accuracy: 0.3592 - loss: 1.7626 - val_accuracy: 0.4505 - val_loss: 1.5610 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.4159 - loss: 1.5956\n",
      "Epoch 4: val_loss improved from 1.56103 to 1.46061, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 342ms/step - accuracy: 0.4162 - loss: 1.5946 - val_accuracy: 0.5030 - val_loss: 1.4606 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.4517 - loss: 1.4996\n",
      "Epoch 5: val_loss improved from 1.46061 to 1.44246, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 282ms/step - accuracy: 0.4518 - loss: 1.4990 - val_accuracy: 0.5051 - val_loss: 1.4425 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4759 - loss: 1.4336\n",
      "Epoch 6: val_loss improved from 1.44246 to 1.37448, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 299ms/step - accuracy: 0.4761 - loss: 1.4329 - val_accuracy: 0.5192 - val_loss: 1.3745 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.5112 - loss: 1.3464\n",
      "Epoch 7: val_loss improved from 1.37448 to 1.34980, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 310ms/step - accuracy: 0.5114 - loss: 1.3459 - val_accuracy: 0.4960 - val_loss: 1.3498 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5321 - loss: 1.2770\n",
      "Epoch 8: val_loss improved from 1.34980 to 1.34710, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.5320 - loss: 1.2771 - val_accuracy: 0.5202 - val_loss: 1.3471 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5394 - loss: 1.2594\n",
      "Epoch 9: val_loss did not improve from 1.34710\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.5396 - loss: 1.2589 - val_accuracy: 0.5131 - val_loss: 1.3521 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.5639 - loss: 1.2226\n",
      "Epoch 10: val_loss improved from 1.34710 to 1.34164, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 333ms/step - accuracy: 0.5639 - loss: 1.2220 - val_accuracy: 0.5081 - val_loss: 1.3416 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.5694 - loss: 1.1809\n",
      "Epoch 11: val_loss improved from 1.34164 to 1.32549, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 342ms/step - accuracy: 0.5698 - loss: 1.1803 - val_accuracy: 0.5081 - val_loss: 1.3255 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5818 - loss: 1.1466\n",
      "Epoch 12: val_loss improved from 1.32549 to 1.31622, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.5819 - loss: 1.1462 - val_accuracy: 0.5111 - val_loss: 1.3162 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5974 - loss: 1.1127\n",
      "Epoch 13: val_loss improved from 1.31622 to 1.28204, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5975 - loss: 1.1126 - val_accuracy: 0.5495 - val_loss: 1.2820 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6127 - loss: 1.0863\n",
      "Epoch 14: val_loss did not improve from 1.28204\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.6127 - loss: 1.0866 - val_accuracy: 0.5475 - val_loss: 1.2970 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.6223 - loss: 1.0499\n",
      "Epoch 15: val_loss improved from 1.28204 to 1.26105, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.6222 - loss: 1.0501 - val_accuracy: 0.5667 - val_loss: 1.2611 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6305 - loss: 1.0424\n",
      "Epoch 16: val_loss did not improve from 1.26105\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.6307 - loss: 1.0418 - val_accuracy: 0.5616 - val_loss: 1.2901 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.6311 - loss: 1.0282\n",
      "Epoch 17: val_loss improved from 1.26105 to 1.25625, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 318ms/step - accuracy: 0.6311 - loss: 1.0281 - val_accuracy: 0.5687 - val_loss: 1.2562 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6390 - loss: 1.0124\n",
      "Epoch 18: val_loss did not improve from 1.25625\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.6391 - loss: 1.0124 - val_accuracy: 0.5798 - val_loss: 1.2740 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6496 - loss: 0.9842\n",
      "Epoch 19: val_loss improved from 1.25625 to 1.24579, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - accuracy: 0.6497 - loss: 0.9841 - val_accuracy: 0.5475 - val_loss: 1.2458 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6561 - loss: 0.9554\n",
      "Epoch 20: val_loss did not improve from 1.24579\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.6562 - loss: 0.9555 - val_accuracy: 0.5778 - val_loss: 1.2998 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6742 - loss: 0.9243\n",
      "Epoch 21: val_loss did not improve from 1.24579\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.6742 - loss: 0.9246 - val_accuracy: 0.5333 - val_loss: 1.2801 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6974 - loss: 0.9036\n",
      "Epoch 22: val_loss did not improve from 1.24579\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 179ms/step - accuracy: 0.6970 - loss: 0.9037 - val_accuracy: 0.5758 - val_loss: 1.2706 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6840 - loss: 0.9301\n",
      "Epoch 23: val_loss did not improve from 1.24579\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - accuracy: 0.6842 - loss: 0.9291 - val_accuracy: 0.5505 - val_loss: 1.3040 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6938 - loss: 0.8757\n",
      "Epoch 24: val_loss did not improve from 1.24579\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.6937 - loss: 0.8757 - val_accuracy: 0.5879 - val_loss: 1.2818 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7044 - loss: 0.8426\n",
      "Epoch 25: val_loss improved from 1.24579 to 1.24436, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 481ms/step - accuracy: 0.7042 - loss: 0.8429 - val_accuracy: 0.5990 - val_loss: 1.2444 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7056 - loss: 0.8466\n",
      "Epoch 26: val_loss did not improve from 1.24436\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.7052 - loss: 0.8470 - val_accuracy: 0.5818 - val_loss: 1.2504 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7144 - loss: 0.8278\n",
      "Epoch 27: val_loss did not improve from 1.24436\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.7144 - loss: 0.8282 - val_accuracy: 0.6121 - val_loss: 1.2479 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7179 - loss: 0.8310\n",
      "Epoch 28: val_loss improved from 1.24436 to 1.22181, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - accuracy: 0.7179 - loss: 0.8307 - val_accuracy: 0.5778 - val_loss: 1.2218 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7256 - loss: 0.8148\n",
      "Epoch 29: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7255 - loss: 0.8148 - val_accuracy: 0.5657 - val_loss: 1.2598 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7177 - loss: 0.8348\n",
      "Epoch 30: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.7178 - loss: 0.8345 - val_accuracy: 0.5869 - val_loss: 1.2426 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.7133 - loss: 0.8054\n",
      "Epoch 31: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.7134 - loss: 0.8053 - val_accuracy: 0.5828 - val_loss: 1.2414 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7194 - loss: 0.8071\n",
      "Epoch 32: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.7194 - loss: 0.8068 - val_accuracy: 0.6081 - val_loss: 1.2656 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7265 - loss: 0.7951\n",
      "Epoch 33: val_loss did not improve from 1.22181\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.7266 - loss: 0.7949 - val_accuracy: 0.5919 - val_loss: 1.2404 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7345 - loss: 0.7914\n",
      "Epoch 34: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.7345 - loss: 0.7912 - val_accuracy: 0.5929 - val_loss: 1.2269 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.7407 - loss: 0.7673\n",
      "Epoch 35: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step - accuracy: 0.7407 - loss: 0.7674 - val_accuracy: 0.6000 - val_loss: 1.2374 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7279 - loss: 0.7815\n",
      "Epoch 36: val_loss did not improve from 1.22181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.7281 - loss: 0.7812 - val_accuracy: 0.5970 - val_loss: 1.2359 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7341 - loss: 0.7762\n",
      "Epoch 37: val_loss improved from 1.22181 to 1.21680, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 319ms/step - accuracy: 0.7341 - loss: 0.7759 - val_accuracy: 0.5990 - val_loss: 1.2168 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7318 - loss: 0.7586\n",
      "Epoch 38: val_loss did not improve from 1.21680\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7320 - loss: 0.7587 - val_accuracy: 0.5929 - val_loss: 1.2206 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7531 - loss: 0.7517\n",
      "Epoch 39: val_loss did not improve from 1.21680\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.7529 - loss: 0.7518 - val_accuracy: 0.5970 - val_loss: 1.2329 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7364 - loss: 0.7699\n",
      "Epoch 40: val_loss did not improve from 1.21680\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.7365 - loss: 0.7697 - val_accuracy: 0.5909 - val_loss: 1.2399 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7401 - loss: 0.7572\n",
      "Epoch 41: val_loss improved from 1.21680 to 1.21016, saving model to saved_models/weights.fold4.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.7403 - loss: 0.7566 - val_accuracy: 0.5929 - val_loss: 1.2102 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7546 - loss: 0.7350\n",
      "Epoch 42: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.7545 - loss: 0.7355 - val_accuracy: 0.5939 - val_loss: 1.2423 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7421 - loss: 0.7467\n",
      "Epoch 43: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.7421 - loss: 0.7467 - val_accuracy: 0.5929 - val_loss: 1.2142 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.7494 - loss: 0.7404\n",
      "Epoch 44: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.7494 - loss: 0.7402 - val_accuracy: 0.6040 - val_loss: 1.2443 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7516 - loss: 0.7278\n",
      "Epoch 45: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.7516 - loss: 0.7280 - val_accuracy: 0.6010 - val_loss: 1.2164 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7416 - loss: 0.7275\n",
      "Epoch 46: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - accuracy: 0.7419 - loss: 0.7277 - val_accuracy: 0.5960 - val_loss: 1.2343 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7498 - loss: 0.7250\n",
      "Epoch 47: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7498 - loss: 0.7252 - val_accuracy: 0.5990 - val_loss: 1.2244 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7530 - loss: 0.7364\n",
      "Epoch 48: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7531 - loss: 0.7356 - val_accuracy: 0.5990 - val_loss: 1.2241 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7632 - loss: 0.7221\n",
      "Epoch 49: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7630 - loss: 0.7217 - val_accuracy: 0.6081 - val_loss: 1.2305 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7618 - loss: 0.7086\n",
      "Epoch 50: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7615 - loss: 0.7090 - val_accuracy: 0.6030 - val_loss: 1.2256 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7558 - loss: 0.7139\n",
      "Epoch 51: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7558 - loss: 0.7139 - val_accuracy: 0.6051 - val_loss: 1.2129 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7555 - loss: 0.7153\n",
      "Epoch 52: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7555 - loss: 0.7148 - val_accuracy: 0.6051 - val_loss: 1.2210 - learning_rate: 6.2500e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7570 - loss: 0.7079\n",
      "Epoch 53: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7569 - loss: 0.7086 - val_accuracy: 0.6051 - val_loss: 1.2144 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7574 - loss: 0.7071\n",
      "Epoch 54: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7577 - loss: 0.7072 - val_accuracy: 0.6081 - val_loss: 1.2325 - learning_rate: 6.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7602 - loss: 0.7021\n",
      "Epoch 55: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7602 - loss: 0.7024 - val_accuracy: 0.6051 - val_loss: 1.2270 - learning_rate: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7582 - loss: 0.7009\n",
      "Epoch 56: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7580 - loss: 0.7017 - val_accuracy: 0.6030 - val_loss: 1.2121 - learning_rate: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7622 - loss: 0.7003\n",
      "Epoch 57: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7622 - loss: 0.7005 - val_accuracy: 0.6051 - val_loss: 1.2172 - learning_rate: 3.1250e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7625 - loss: 0.6947\n",
      "Epoch 58: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7623 - loss: 0.6958 - val_accuracy: 0.6040 - val_loss: 1.2176 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7622 - loss: 0.6996\n",
      "Epoch 59: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7622 - loss: 0.7000 - val_accuracy: 0.5990 - val_loss: 1.2203 - learning_rate: 3.1250e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7642 - loss: 0.7061\n",
      "Epoch 60: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7639 - loss: 0.7056 - val_accuracy: 0.5980 - val_loss: 1.2184 - learning_rate: 3.1250e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7585 - loss: 0.7145\n",
      "Epoch 61: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7585 - loss: 0.7142 - val_accuracy: 0.6010 - val_loss: 1.2172 - learning_rate: 3.1250e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7568 - loss: 0.7044\n",
      "Epoch 62: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7574 - loss: 0.7041 - val_accuracy: 0.6061 - val_loss: 1.2181 - learning_rate: 1.5625e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7653 - loss: 0.7117\n",
      "Epoch 63: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7652 - loss: 0.7114 - val_accuracy: 0.6030 - val_loss: 1.2153 - learning_rate: 1.5625e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7670 - loss: 0.6972\n",
      "Epoch 64: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7665 - loss: 0.6980 - val_accuracy: 0.6030 - val_loss: 1.2169 - learning_rate: 1.5625e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7622 - loss: 0.7167\n",
      "Epoch 65: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7621 - loss: 0.7163 - val_accuracy: 0.6071 - val_loss: 1.2166 - learning_rate: 1.5625e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7653 - loss: 0.7044\n",
      "Epoch 66: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7653 - loss: 0.7041 - val_accuracy: 0.6111 - val_loss: 1.2169 - learning_rate: 1.5625e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7605 - loss: 0.6914\n",
      "Epoch 67: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7607 - loss: 0.6918 - val_accuracy: 0.6111 - val_loss: 1.2161 - learning_rate: 7.8125e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7524 - loss: 0.7179\n",
      "Epoch 68: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7528 - loss: 0.7170 - val_accuracy: 0.6061 - val_loss: 1.2133 - learning_rate: 7.8125e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7730 - loss: 0.6943\n",
      "Epoch 69: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7729 - loss: 0.6945 - val_accuracy: 0.6040 - val_loss: 1.2154 - learning_rate: 7.8125e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7586 - loss: 0.7029\n",
      "Epoch 70: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7585 - loss: 0.7029 - val_accuracy: 0.6081 - val_loss: 1.2195 - learning_rate: 7.8125e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7556 - loss: 0.7078\n",
      "Epoch 71: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7559 - loss: 0.7074 - val_accuracy: 0.6081 - val_loss: 1.2202 - learning_rate: 7.8125e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7630 - loss: 0.7014\n",
      "Epoch 72: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7630 - loss: 0.7014 - val_accuracy: 0.6051 - val_loss: 1.2186 - learning_rate: 3.9063e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7548 - loss: 0.7167\n",
      "Epoch 73: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7554 - loss: 0.7156 - val_accuracy: 0.6030 - val_loss: 1.2179 - learning_rate: 3.9063e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7635 - loss: 0.7003\n",
      "Epoch 74: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7635 - loss: 0.7003 - val_accuracy: 0.6040 - val_loss: 1.2175 - learning_rate: 3.9063e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7699 - loss: 0.6896\n",
      "Epoch 75: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7694 - loss: 0.6902 - val_accuracy: 0.6040 - val_loss: 1.2187 - learning_rate: 3.9063e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7636 - loss: 0.6970\n",
      "Epoch 76: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7635 - loss: 0.6973 - val_accuracy: 0.6040 - val_loss: 1.2162 - learning_rate: 3.9063e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7587 - loss: 0.7182\n",
      "Epoch 77: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7588 - loss: 0.7178 - val_accuracy: 0.6040 - val_loss: 1.2163 - learning_rate: 1.9531e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7613 - loss: 0.7102\n",
      "Epoch 78: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7614 - loss: 0.7099 - val_accuracy: 0.6040 - val_loss: 1.2171 - learning_rate: 1.9531e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7627 - loss: 0.7181\n",
      "Epoch 79: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7624 - loss: 0.7175 - val_accuracy: 0.6051 - val_loss: 1.2172 - learning_rate: 1.9531e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7705 - loss: 0.7021\n",
      "Epoch 80: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7701 - loss: 0.7025 - val_accuracy: 0.6051 - val_loss: 1.2169 - learning_rate: 1.9531e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7644 - loss: 0.6993\n",
      "Epoch 81: val_loss did not improve from 1.21016\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7643 - loss: 0.6990 - val_accuracy: 0.6061 - val_loss: 1.2173 - learning_rate: 1.9531e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7508 - loss: 0.7157\n",
      "Epoch 82: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7511 - loss: 0.7153 - val_accuracy: 0.6040 - val_loss: 1.2172 - learning_rate: 1.0000e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7682 - loss: 0.7073\n",
      "Epoch 83: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7681 - loss: 0.7072 - val_accuracy: 0.6040 - val_loss: 1.2170 - learning_rate: 1.0000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7541 - loss: 0.7295\n",
      "Epoch 84: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7548 - loss: 0.7281 - val_accuracy: 0.6030 - val_loss: 1.2170 - learning_rate: 1.0000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7650 - loss: 0.6964\n",
      "Epoch 85: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7644 - loss: 0.6968 - val_accuracy: 0.6051 - val_loss: 1.2172 - learning_rate: 1.0000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7578 - loss: 0.7249\n",
      "Epoch 86: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7585 - loss: 0.7230 - val_accuracy: 0.6061 - val_loss: 1.2173 - learning_rate: 1.0000e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7578 - loss: 0.7223\n",
      "Epoch 87: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7581 - loss: 0.7210 - val_accuracy: 0.6061 - val_loss: 1.2174 - learning_rate: 1.0000e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7689 - loss: 0.6843\n",
      "Epoch 88: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7685 - loss: 0.6856 - val_accuracy: 0.6051 - val_loss: 1.2173 - learning_rate: 1.0000e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7755 - loss: 0.6948\n",
      "Epoch 89: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7753 - loss: 0.6948 - val_accuracy: 0.6061 - val_loss: 1.2175 - learning_rate: 1.0000e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7621 - loss: 0.7019\n",
      "Epoch 90: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7620 - loss: 0.7019 - val_accuracy: 0.6051 - val_loss: 1.2174 - learning_rate: 1.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7682 - loss: 0.6841\n",
      "Epoch 91: val_loss did not improve from 1.21016\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7678 - loss: 0.6851 - val_accuracy: 0.6040 - val_loss: 1.2174 - learning_rate: 1.0000e-06\n",
      "Fold 4 training completed in time: 0:09:29.769045\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\n",
      "Fold 4 Post-Training Train Accuracy: 0.7626\n",
      "Fold 4 Post-Training Test Accuracy: 0.5929\n",
      "[1.2101587057113647, 0.5929293036460876]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(4)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7796, 40, 174)\n",
      "(936, 40, 174)\n",
      "(7796, 10)\n",
      "(936, 10)\n",
      "x_train shape: (7796, 40, 174, 1)\n",
      "x_test shape: (936, 40, 174, 1)\n",
      "y_train shape: (7796, 10)\n",
      "y_test shape: (936, 10)\n",
      "\n",
      "Training Fold 5...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1191 - loss: 2.2926\n",
      "Epoch 1: val_loss improved from inf to 2.04859, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 242ms/step - accuracy: 0.1201 - loss: 2.2911 - val_accuracy: 0.2468 - val_loss: 2.0486 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.2791 - loss: 2.0249\n",
      "Epoch 2: val_loss improved from 2.04859 to 1.71224, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 538ms/step - accuracy: 0.2802 - loss: 2.0226 - val_accuracy: 0.4156 - val_loss: 1.7122 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3874 - loss: 1.6869\n",
      "Epoch 3: val_loss improved from 1.71224 to 1.59507, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.3878 - loss: 1.6859 - val_accuracy: 0.4220 - val_loss: 1.5951 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.4428 - loss: 1.5326\n",
      "Epoch 4: val_loss improved from 1.59507 to 1.46054, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 357ms/step - accuracy: 0.4432 - loss: 1.5320 - val_accuracy: 0.4487 - val_loss: 1.4605 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4878 - loss: 1.4301\n",
      "Epoch 5: val_loss improved from 1.46054 to 1.42997, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 445ms/step - accuracy: 0.4878 - loss: 1.4300 - val_accuracy: 0.4466 - val_loss: 1.4300 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5055 - loss: 1.3461\n",
      "Epoch 6: val_loss improved from 1.42997 to 1.39036, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.5056 - loss: 1.3462 - val_accuracy: 0.4637 - val_loss: 1.3904 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5289 - loss: 1.3077\n",
      "Epoch 7: val_loss did not improve from 1.39036\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.5292 - loss: 1.3070 - val_accuracy: 0.4519 - val_loss: 1.3953 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5343 - loss: 1.2594\n",
      "Epoch 8: val_loss improved from 1.39036 to 1.35566, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 253ms/step - accuracy: 0.5349 - loss: 1.2586 - val_accuracy: 0.4808 - val_loss: 1.3557 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5640 - loss: 1.2191\n",
      "Epoch 9: val_loss improved from 1.35566 to 1.32289, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.5640 - loss: 1.2186 - val_accuracy: 0.4733 - val_loss: 1.3229 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5830 - loss: 1.1696\n",
      "Epoch 10: val_loss improved from 1.32289 to 1.31967, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.5830 - loss: 1.1695 - val_accuracy: 0.5021 - val_loss: 1.3197 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5848 - loss: 1.1360\n",
      "Epoch 11: val_loss improved from 1.31967 to 1.29714, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.5850 - loss: 1.1361 - val_accuracy: 0.5299 - val_loss: 1.2971 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5992 - loss: 1.1330\n",
      "Epoch 12: val_loss did not improve from 1.29714\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.5993 - loss: 1.1325 - val_accuracy: 0.4744 - val_loss: 1.3187 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6117 - loss: 1.0927\n",
      "Epoch 13: val_loss did not improve from 1.29714\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.6119 - loss: 1.0923 - val_accuracy: 0.4957 - val_loss: 1.3066 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6231 - loss: 1.0740\n",
      "Epoch 14: val_loss did not improve from 1.29714\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.6231 - loss: 1.0737 - val_accuracy: 0.5139 - val_loss: 1.3043 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6354 - loss: 1.0305\n",
      "Epoch 15: val_loss improved from 1.29714 to 1.25978, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.6354 - loss: 1.0302 - val_accuracy: 0.5310 - val_loss: 1.2598 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6232 - loss: 1.0389\n",
      "Epoch 16: val_loss did not improve from 1.25978\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.6236 - loss: 1.0382 - val_accuracy: 0.5502 - val_loss: 1.2776 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6548 - loss: 0.9912\n",
      "Epoch 17: val_loss did not improve from 1.25978\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.6547 - loss: 0.9912 - val_accuracy: 0.5256 - val_loss: 1.2877 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6632 - loss: 0.9547\n",
      "Epoch 18: val_loss did not improve from 1.25978\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.6631 - loss: 0.9551 - val_accuracy: 0.5246 - val_loss: 1.3184 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6687 - loss: 0.9489\n",
      "Epoch 19: val_loss improved from 1.25978 to 1.21647, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.6688 - loss: 0.9488 - val_accuracy: 0.5652 - val_loss: 1.2165 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6637 - loss: 0.9403\n",
      "Epoch 20: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - accuracy: 0.6639 - loss: 0.9405 - val_accuracy: 0.5491 - val_loss: 1.2365 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6934 - loss: 0.9101\n",
      "Epoch 21: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.6933 - loss: 0.9100 - val_accuracy: 0.5759 - val_loss: 1.2889 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6951 - loss: 0.8798\n",
      "Epoch 22: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.6951 - loss: 0.8800 - val_accuracy: 0.5609 - val_loss: 1.2456 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7063 - loss: 0.8507\n",
      "Epoch 23: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7063 - loss: 0.8507 - val_accuracy: 0.5726 - val_loss: 1.2533 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7090 - loss: 0.8586\n",
      "Epoch 24: val_loss did not improve from 1.21647\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7090 - loss: 0.8582 - val_accuracy: 0.5598 - val_loss: 1.3498 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7183 - loss: 0.8372\n",
      "Epoch 25: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.7184 - loss: 0.8370 - val_accuracy: 0.5769 - val_loss: 1.2499 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7264 - loss: 0.8260\n",
      "Epoch 26: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.7265 - loss: 0.8255 - val_accuracy: 0.5673 - val_loss: 1.2845 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7351 - loss: 0.7948\n",
      "Epoch 27: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7350 - loss: 0.7950 - val_accuracy: 0.5962 - val_loss: 1.2358 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7330 - loss: 0.8021\n",
      "Epoch 28: val_loss did not improve from 1.21647\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7331 - loss: 0.8019 - val_accuracy: 0.5908 - val_loss: 1.2241 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7453 - loss: 0.7560\n",
      "Epoch 29: val_loss improved from 1.21647 to 1.21539, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.7451 - loss: 0.7566 - val_accuracy: 0.5983 - val_loss: 1.2154 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7426 - loss: 0.7685\n",
      "Epoch 30: val_loss improved from 1.21539 to 1.19043, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.7426 - loss: 0.7687 - val_accuracy: 0.6100 - val_loss: 1.1904 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7515 - loss: 0.7569\n",
      "Epoch 31: val_loss did not improve from 1.19043\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.7514 - loss: 0.7570 - val_accuracy: 0.5972 - val_loss: 1.2718 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7567 - loss: 0.7487\n",
      "Epoch 32: val_loss did not improve from 1.19043\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.7565 - loss: 0.7486 - val_accuracy: 0.6090 - val_loss: 1.2106 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7627 - loss: 0.7323\n",
      "Epoch 33: val_loss improved from 1.19043 to 1.16477, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.7626 - loss: 0.7324 - val_accuracy: 0.6325 - val_loss: 1.1648 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7649 - loss: 0.7267\n",
      "Epoch 34: val_loss did not improve from 1.16477\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7647 - loss: 0.7269 - val_accuracy: 0.6004 - val_loss: 1.2120 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7619 - loss: 0.7417\n",
      "Epoch 35: val_loss did not improve from 1.16477\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.7619 - loss: 0.7417 - val_accuracy: 0.6207 - val_loss: 1.1662 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7616 - loss: 0.7203\n",
      "Epoch 36: val_loss did not improve from 1.16477\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7614 - loss: 0.7206 - val_accuracy: 0.6058 - val_loss: 1.1896 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7624 - loss: 0.7205\n",
      "Epoch 37: val_loss improved from 1.16477 to 1.13963, saving model to saved_models/weights.fold5.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 243ms/step - accuracy: 0.7624 - loss: 0.7207 - val_accuracy: 0.6378 - val_loss: 1.1396 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7699 - loss: 0.7073\n",
      "Epoch 38: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7698 - loss: 0.7074 - val_accuracy: 0.6410 - val_loss: 1.1633 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7783 - loss: 0.6810\n",
      "Epoch 39: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.7781 - loss: 0.6815 - val_accuracy: 0.5865 - val_loss: 1.3064 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7699 - loss: 0.7194\n",
      "Epoch 40: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7700 - loss: 0.7190 - val_accuracy: 0.6175 - val_loss: 1.1992 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7705 - loss: 0.7067\n",
      "Epoch 41: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7705 - loss: 0.7065 - val_accuracy: 0.6165 - val_loss: 1.1947 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7730 - loss: 0.7024\n",
      "Epoch 42: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7731 - loss: 0.7020 - val_accuracy: 0.6143 - val_loss: 1.2125 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7891 - loss: 0.6610\n",
      "Epoch 43: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7891 - loss: 0.6609 - val_accuracy: 0.6464 - val_loss: 1.1616 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7837 - loss: 0.6550\n",
      "Epoch 44: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7837 - loss: 0.6553 - val_accuracy: 0.6538 - val_loss: 1.1738 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7899 - loss: 0.6569\n",
      "Epoch 45: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.7898 - loss: 0.6570 - val_accuracy: 0.6389 - val_loss: 1.1814 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7882 - loss: 0.6496\n",
      "Epoch 46: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7883 - loss: 0.6498 - val_accuracy: 0.6378 - val_loss: 1.1815 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7938 - loss: 0.6417\n",
      "Epoch 47: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7938 - loss: 0.6417 - val_accuracy: 0.6517 - val_loss: 1.1572 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7988 - loss: 0.6450\n",
      "Epoch 48: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7988 - loss: 0.6448 - val_accuracy: 0.6581 - val_loss: 1.1693 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.8006 - loss: 0.6217\n",
      "Epoch 49: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.8005 - loss: 0.6220 - val_accuracy: 0.6474 - val_loss: 1.1622 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7950 - loss: 0.6373\n",
      "Epoch 50: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7951 - loss: 0.6371 - val_accuracy: 0.6314 - val_loss: 1.2041 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8039 - loss: 0.6251\n",
      "Epoch 51: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8038 - loss: 0.6254 - val_accuracy: 0.6506 - val_loss: 1.1662 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7937 - loss: 0.6282\n",
      "Epoch 52: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7937 - loss: 0.6283 - val_accuracy: 0.6453 - val_loss: 1.2048 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7895 - loss: 0.6389\n",
      "Epoch 53: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.7896 - loss: 0.6387 - val_accuracy: 0.6389 - val_loss: 1.1819 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7921 - loss: 0.6433\n",
      "Epoch 54: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7922 - loss: 0.6430 - val_accuracy: 0.6453 - val_loss: 1.1715 - learning_rate: 6.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8013 - loss: 0.6172\n",
      "Epoch 55: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.8012 - loss: 0.6174 - val_accuracy: 0.6368 - val_loss: 1.1986 - learning_rate: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7983 - loss: 0.6280\n",
      "Epoch 56: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7983 - loss: 0.6281 - val_accuracy: 0.6410 - val_loss: 1.1861 - learning_rate: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7903 - loss: 0.6334\n",
      "Epoch 57: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7905 - loss: 0.6332 - val_accuracy: 0.6464 - val_loss: 1.1798 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.8076 - loss: 0.6125\n",
      "Epoch 58: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.8074 - loss: 0.6127 - val_accuracy: 0.6346 - val_loss: 1.1925 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7953 - loss: 0.6193\n",
      "Epoch 59: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7954 - loss: 0.6193 - val_accuracy: 0.6442 - val_loss: 1.1732 - learning_rate: 3.1250e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.8022 - loss: 0.6225\n",
      "Epoch 60: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.8023 - loss: 0.6223 - val_accuracy: 0.6453 - val_loss: 1.1878 - learning_rate: 3.1250e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7972 - loss: 0.6342\n",
      "Epoch 61: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7973 - loss: 0.6338 - val_accuracy: 0.6496 - val_loss: 1.1803 - learning_rate: 3.1250e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7854 - loss: 0.6500\n",
      "Epoch 62: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7858 - loss: 0.6495 - val_accuracy: 0.6410 - val_loss: 1.1915 - learning_rate: 3.1250e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7963 - loss: 0.6243\n",
      "Epoch 63: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7963 - loss: 0.6244 - val_accuracy: 0.6485 - val_loss: 1.1711 - learning_rate: 1.5625e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8036 - loss: 0.6120\n",
      "Epoch 64: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.8035 - loss: 0.6121 - val_accuracy: 0.6485 - val_loss: 1.1749 - learning_rate: 1.5625e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7964 - loss: 0.6315\n",
      "Epoch 65: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7965 - loss: 0.6311 - val_accuracy: 0.6453 - val_loss: 1.1766 - learning_rate: 1.5625e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8037 - loss: 0.6279\n",
      "Epoch 66: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8036 - loss: 0.6277 - val_accuracy: 0.6485 - val_loss: 1.1770 - learning_rate: 1.5625e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7983 - loss: 0.6216\n",
      "Epoch 67: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7984 - loss: 0.6213 - val_accuracy: 0.6506 - val_loss: 1.1784 - learning_rate: 1.5625e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8082 - loss: 0.5951\n",
      "Epoch 68: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.8079 - loss: 0.5957 - val_accuracy: 0.6474 - val_loss: 1.1808 - learning_rate: 7.8125e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7993 - loss: 0.6220\n",
      "Epoch 69: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7993 - loss: 0.6220 - val_accuracy: 0.6474 - val_loss: 1.1768 - learning_rate: 7.8125e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7993 - loss: 0.6250\n",
      "Epoch 70: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7993 - loss: 0.6249 - val_accuracy: 0.6474 - val_loss: 1.1778 - learning_rate: 7.8125e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7942 - loss: 0.6150\n",
      "Epoch 71: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.7943 - loss: 0.6151 - val_accuracy: 0.6485 - val_loss: 1.1768 - learning_rate: 7.8125e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7946 - loss: 0.6303\n",
      "Epoch 72: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7948 - loss: 0.6300 - val_accuracy: 0.6496 - val_loss: 1.1747 - learning_rate: 7.8125e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8003 - loss: 0.6185\n",
      "Epoch 73: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.8004 - loss: 0.6185 - val_accuracy: 0.6528 - val_loss: 1.1770 - learning_rate: 3.9063e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7924 - loss: 0.6273\n",
      "Epoch 74: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.7927 - loss: 0.6270 - val_accuracy: 0.6506 - val_loss: 1.1763 - learning_rate: 3.9063e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8014 - loss: 0.6150\n",
      "Epoch 75: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8014 - loss: 0.6153 - val_accuracy: 0.6474 - val_loss: 1.1771 - learning_rate: 3.9063e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8040 - loss: 0.6130\n",
      "Epoch 76: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.8040 - loss: 0.6131 - val_accuracy: 0.6496 - val_loss: 1.1757 - learning_rate: 3.9063e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7977 - loss: 0.6301\n",
      "Epoch 77: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7978 - loss: 0.6296 - val_accuracy: 0.6485 - val_loss: 1.1768 - learning_rate: 3.9063e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8053 - loss: 0.6200\n",
      "Epoch 78: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.8053 - loss: 0.6197 - val_accuracy: 0.6485 - val_loss: 1.1779 - learning_rate: 1.9531e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8026 - loss: 0.6115\n",
      "Epoch 79: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.8027 - loss: 0.6115 - val_accuracy: 0.6474 - val_loss: 1.1790 - learning_rate: 1.9531e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7982 - loss: 0.6148\n",
      "Epoch 80: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.7983 - loss: 0.6149 - val_accuracy: 0.6474 - val_loss: 1.1787 - learning_rate: 1.9531e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8021 - loss: 0.6073\n",
      "Epoch 81: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.8021 - loss: 0.6075 - val_accuracy: 0.6474 - val_loss: 1.1782 - learning_rate: 1.9531e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7942 - loss: 0.6301\n",
      "Epoch 82: val_loss did not improve from 1.13963\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7943 - loss: 0.6298 - val_accuracy: 0.6474 - val_loss: 1.1798 - learning_rate: 1.9531e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7988 - loss: 0.6312\n",
      "Epoch 83: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7989 - loss: 0.6307 - val_accuracy: 0.6474 - val_loss: 1.1788 - learning_rate: 1.0000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8009 - loss: 0.6202\n",
      "Epoch 84: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.8010 - loss: 0.6203 - val_accuracy: 0.6474 - val_loss: 1.1795 - learning_rate: 1.0000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7945 - loss: 0.6338\n",
      "Epoch 85: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.7947 - loss: 0.6335 - val_accuracy: 0.6474 - val_loss: 1.1793 - learning_rate: 1.0000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7987 - loss: 0.6300\n",
      "Epoch 86: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7988 - loss: 0.6296 - val_accuracy: 0.6474 - val_loss: 1.1789 - learning_rate: 1.0000e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7966 - loss: 0.6201\n",
      "Epoch 87: val_loss did not improve from 1.13963\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7966 - loss: 0.6200 - val_accuracy: 0.6485 - val_loss: 1.1780 - learning_rate: 1.0000e-06\n",
      "Fold 5 training completed in time: 0:07:59.094979\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Fold 5 Post-Training Train Accuracy: 0.7977\n",
      "Fold 5 Post-Training Test Accuracy: 0.6378\n",
      "[1.1396336555480957, 0.6378205418586731]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(5)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8137e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7909, 40, 174)\n",
      "(823, 40, 174)\n",
      "(7909, 10)\n",
      "(823, 10)\n",
      "x_train shape: (7909, 40, 174, 1)\n",
      "x_test shape: (823, 40, 174, 1)\n",
      "y_train shape: (7909, 10)\n",
      "y_test shape: (823, 10)\n",
      "\n",
      "Training Fold 6...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.1420 - loss: 2.2997\n",
      "Epoch 1: val_loss improved from inf to 2.10433, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 326ms/step - accuracy: 0.1429 - loss: 2.2988 - val_accuracy: 0.2467 - val_loss: 2.1043 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.2454 - loss: 2.0691\n",
      "Epoch 2: val_loss improved from 2.10433 to 1.89039, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 715ms/step - accuracy: 0.2464 - loss: 2.0669 - val_accuracy: 0.3123 - val_loss: 1.8904 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.3549 - loss: 1.7758\n",
      "Epoch 3: val_loss improved from 1.89039 to 1.78719, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.3553 - loss: 1.7745 - val_accuracy: 0.3463 - val_loss: 1.7872 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4256 - loss: 1.6271\n",
      "Epoch 4: val_loss improved from 1.78719 to 1.75786, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 624ms/step - accuracy: 0.4260 - loss: 1.6255 - val_accuracy: 0.3803 - val_loss: 1.7579 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4621 - loss: 1.4878\n",
      "Epoch 5: val_loss improved from 1.75786 to 1.72210, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4623 - loss: 1.4874 - val_accuracy: 0.4131 - val_loss: 1.7221 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.4802 - loss: 1.4246\n",
      "Epoch 6: val_loss improved from 1.72210 to 1.65309, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 713ms/step - accuracy: 0.4804 - loss: 1.4242 - val_accuracy: 0.4168 - val_loss: 1.6531 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.4931 - loss: 1.3668\n",
      "Epoch 7: val_loss improved from 1.65309 to 1.65268, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4935 - loss: 1.3661 - val_accuracy: 0.4253 - val_loss: 1.6527 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5239 - loss: 1.3111\n",
      "Epoch 8: val_loss improved from 1.65268 to 1.59525, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 890ms/step - accuracy: 0.5241 - loss: 1.3108 - val_accuracy: 0.4411 - val_loss: 1.5953 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5435 - loss: 1.2643\n",
      "Epoch 9: val_loss improved from 1.59525 to 1.52181, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.5436 - loss: 1.2639 - val_accuracy: 0.4557 - val_loss: 1.5218 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5590 - loss: 1.2147\n",
      "Epoch 10: val_loss did not improve from 1.52181\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.5591 - loss: 1.2145 - val_accuracy: 0.4629 - val_loss: 1.5330 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5651 - loss: 1.2168\n",
      "Epoch 11: val_loss improved from 1.52181 to 1.49451, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 752ms/step - accuracy: 0.5652 - loss: 1.2159 - val_accuracy: 0.4690 - val_loss: 1.4945 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5911 - loss: 1.1507\n",
      "Epoch 12: val_loss did not improve from 1.49451\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.5911 - loss: 1.1508 - val_accuracy: 0.4872 - val_loss: 1.5371 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6060 - loss: 1.1361\n",
      "Epoch 13: val_loss did not improve from 1.49451\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.6060 - loss: 1.1355 - val_accuracy: 0.4824 - val_loss: 1.5109 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6151 - loss: 1.1006\n",
      "Epoch 14: val_loss improved from 1.49451 to 1.45226, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.6150 - loss: 1.1004 - val_accuracy: 0.4812 - val_loss: 1.4523 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6221 - loss: 1.0790\n",
      "Epoch 15: val_loss did not improve from 1.45226\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - accuracy: 0.6221 - loss: 1.0787 - val_accuracy: 0.5006 - val_loss: 1.4727 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6380 - loss: 1.0366\n",
      "Epoch 16: val_loss improved from 1.45226 to 1.44711, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 775ms/step - accuracy: 0.6378 - loss: 1.0369 - val_accuracy: 0.5030 - val_loss: 1.4471 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6402 - loss: 1.0327\n",
      "Epoch 17: val_loss did not improve from 1.44711\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6401 - loss: 1.0327 - val_accuracy: 0.5018 - val_loss: 1.4790 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.6418 - loss: 1.0039\n",
      "Epoch 18: val_loss improved from 1.44711 to 1.44649, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.6418 - loss: 1.0045 - val_accuracy: 0.5164 - val_loss: 1.4465 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6669 - loss: 0.9715\n",
      "Epoch 19: val_loss did not improve from 1.44649\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - accuracy: 0.6667 - loss: 0.9716 - val_accuracy: 0.5164 - val_loss: 1.4708 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6703 - loss: 0.9706\n",
      "Epoch 20: val_loss improved from 1.44649 to 1.44069, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 767ms/step - accuracy: 0.6703 - loss: 0.9706 - val_accuracy: 0.5237 - val_loss: 1.4407 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6675 - loss: 0.9586\n",
      "Epoch 21: val_loss did not improve from 1.44069\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.6675 - loss: 0.9584 - val_accuracy: 0.5188 - val_loss: 1.4608 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6754 - loss: 0.9235\n",
      "Epoch 22: val_loss did not improve from 1.44069\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6753 - loss: 0.9239 - val_accuracy: 0.4824 - val_loss: 1.5258 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6674 - loss: 0.9444\n",
      "Epoch 23: val_loss improved from 1.44069 to 1.41874, saving model to saved_models/weights.fold6.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.6676 - loss: 0.9442 - val_accuracy: 0.5200 - val_loss: 1.4187 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6924 - loss: 0.9040\n",
      "Epoch 24: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.6923 - loss: 0.9039 - val_accuracy: 0.4909 - val_loss: 1.4836 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6879 - loss: 0.9145\n",
      "Epoch 25: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.6881 - loss: 0.9141 - val_accuracy: 0.5225 - val_loss: 1.4837 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7161 - loss: 0.8418\n",
      "Epoch 26: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.7157 - loss: 0.8424 - val_accuracy: 0.5249 - val_loss: 1.4528 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7073 - loss: 0.8655\n",
      "Epoch 27: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7074 - loss: 0.8654 - val_accuracy: 0.5079 - val_loss: 1.4542 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7221 - loss: 0.8404\n",
      "Epoch 28: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.7219 - loss: 0.8408 - val_accuracy: 0.5249 - val_loss: 1.4857 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7160 - loss: 0.8384\n",
      "Epoch 29: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7162 - loss: 0.8379 - val_accuracy: 0.5298 - val_loss: 1.4745 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7212 - loss: 0.8175\n",
      "Epoch 30: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7214 - loss: 0.8172 - val_accuracy: 0.5176 - val_loss: 1.4549 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7315 - loss: 0.8063\n",
      "Epoch 31: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7315 - loss: 0.8062 - val_accuracy: 0.5176 - val_loss: 1.4406 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7338 - loss: 0.8210\n",
      "Epoch 32: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7337 - loss: 0.8206 - val_accuracy: 0.5249 - val_loss: 1.4749 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.7407 - loss: 0.7913\n",
      "Epoch 33: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.7406 - loss: 0.7912 - val_accuracy: 0.5249 - val_loss: 1.4778 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7332 - loss: 0.8045\n",
      "Epoch 34: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7334 - loss: 0.8041 - val_accuracy: 0.5249 - val_loss: 1.4581 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7412 - loss: 0.7817\n",
      "Epoch 35: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7412 - loss: 0.7816 - val_accuracy: 0.5213 - val_loss: 1.4674 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7462 - loss: 0.7644\n",
      "Epoch 36: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7462 - loss: 0.7646 - val_accuracy: 0.5249 - val_loss: 1.4560 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7454 - loss: 0.7807\n",
      "Epoch 37: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7455 - loss: 0.7803 - val_accuracy: 0.5225 - val_loss: 1.4600 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7545 - loss: 0.7464\n",
      "Epoch 38: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7543 - loss: 0.7469 - val_accuracy: 0.5298 - val_loss: 1.4549 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7434 - loss: 0.7690\n",
      "Epoch 39: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7435 - loss: 0.7688 - val_accuracy: 0.5176 - val_loss: 1.4650 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7424 - loss: 0.7467\n",
      "Epoch 40: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7425 - loss: 0.7469 - val_accuracy: 0.5298 - val_loss: 1.4666 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7580 - loss: 0.7520\n",
      "Epoch 41: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7579 - loss: 0.7519 - val_accuracy: 0.5188 - val_loss: 1.4738 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7525 - loss: 0.7509\n",
      "Epoch 42: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7524 - loss: 0.7507 - val_accuracy: 0.5310 - val_loss: 1.4786 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7427 - loss: 0.7532\n",
      "Epoch 43: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.7428 - loss: 0.7531 - val_accuracy: 0.5298 - val_loss: 1.4772 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7453 - loss: 0.7589\n",
      "Epoch 44: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7456 - loss: 0.7587 - val_accuracy: 0.5249 - val_loss: 1.4700 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7567 - loss: 0.7275\n",
      "Epoch 45: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.7568 - loss: 0.7279 - val_accuracy: 0.5261 - val_loss: 1.4680 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7642 - loss: 0.7280\n",
      "Epoch 46: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 0.7639 - loss: 0.7284 - val_accuracy: 0.5346 - val_loss: 1.4752 - learning_rate: 6.2500e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7416 - loss: 0.7439\n",
      "Epoch 47: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7418 - loss: 0.7439 - val_accuracy: 0.5322 - val_loss: 1.4749 - learning_rate: 6.2500e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7552 - loss: 0.7446\n",
      "Epoch 48: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7552 - loss: 0.7446 - val_accuracy: 0.5298 - val_loss: 1.4754 - learning_rate: 6.2500e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7498 - loss: 0.7574\n",
      "Epoch 49: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7499 - loss: 0.7569 - val_accuracy: 0.5346 - val_loss: 1.4696 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7555 - loss: 0.7474\n",
      "Epoch 50: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7555 - loss: 0.7471 - val_accuracy: 0.5286 - val_loss: 1.4680 - learning_rate: 3.1250e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7604 - loss: 0.7335\n",
      "Epoch 51: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7603 - loss: 0.7336 - val_accuracy: 0.5346 - val_loss: 1.4732 - learning_rate: 3.1250e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7631 - loss: 0.7215\n",
      "Epoch 52: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7629 - loss: 0.7221 - val_accuracy: 0.5286 - val_loss: 1.4733 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7581 - loss: 0.7396\n",
      "Epoch 53: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7581 - loss: 0.7396 - val_accuracy: 0.5358 - val_loss: 1.4682 - learning_rate: 3.1250e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7561 - loss: 0.7409\n",
      "Epoch 54: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7561 - loss: 0.7407 - val_accuracy: 0.5346 - val_loss: 1.4685 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7595 - loss: 0.7422\n",
      "Epoch 55: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7595 - loss: 0.7420 - val_accuracy: 0.5286 - val_loss: 1.4663 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7650 - loss: 0.7179\n",
      "Epoch 56: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7648 - loss: 0.7182 - val_accuracy: 0.5249 - val_loss: 1.4659 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7612 - loss: 0.7299\n",
      "Epoch 57: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7610 - loss: 0.7300 - val_accuracy: 0.5322 - val_loss: 1.4630 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7536 - loss: 0.7459\n",
      "Epoch 58: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7538 - loss: 0.7454 - val_accuracy: 0.5310 - val_loss: 1.4673 - learning_rate: 1.5625e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7541 - loss: 0.7474\n",
      "Epoch 59: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7540 - loss: 0.7473 - val_accuracy: 0.5298 - val_loss: 1.4648 - learning_rate: 7.8125e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7545 - loss: 0.7429\n",
      "Epoch 60: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.7547 - loss: 0.7427 - val_accuracy: 0.5334 - val_loss: 1.4651 - learning_rate: 7.8125e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7587 - loss: 0.7240\n",
      "Epoch 61: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7587 - loss: 0.7242 - val_accuracy: 0.5298 - val_loss: 1.4634 - learning_rate: 7.8125e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7588 - loss: 0.7180\n",
      "Epoch 62: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7587 - loss: 0.7185 - val_accuracy: 0.5286 - val_loss: 1.4639 - learning_rate: 7.8125e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7511 - loss: 0.7421\n",
      "Epoch 63: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7511 - loss: 0.7423 - val_accuracy: 0.5310 - val_loss: 1.4639 - learning_rate: 7.8125e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7610 - loss: 0.7286\n",
      "Epoch 64: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7609 - loss: 0.7287 - val_accuracy: 0.5286 - val_loss: 1.4659 - learning_rate: 3.9063e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7626 - loss: 0.7227\n",
      "Epoch 65: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7626 - loss: 0.7229 - val_accuracy: 0.5286 - val_loss: 1.4663 - learning_rate: 3.9063e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7515 - loss: 0.7435\n",
      "Epoch 66: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7517 - loss: 0.7432 - val_accuracy: 0.5286 - val_loss: 1.4667 - learning_rate: 3.9063e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7501 - loss: 0.7407\n",
      "Epoch 67: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7503 - loss: 0.7405 - val_accuracy: 0.5298 - val_loss: 1.4674 - learning_rate: 3.9063e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7625 - loss: 0.7253\n",
      "Epoch 68: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7626 - loss: 0.7254 - val_accuracy: 0.5286 - val_loss: 1.4668 - learning_rate: 3.9063e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7616 - loss: 0.7281\n",
      "Epoch 69: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7615 - loss: 0.7281 - val_accuracy: 0.5286 - val_loss: 1.4670 - learning_rate: 1.9531e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7618 - loss: 0.7441\n",
      "Epoch 70: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7617 - loss: 0.7438 - val_accuracy: 0.5286 - val_loss: 1.4664 - learning_rate: 1.9531e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7538 - loss: 0.7301\n",
      "Epoch 71: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7539 - loss: 0.7300 - val_accuracy: 0.5286 - val_loss: 1.4668 - learning_rate: 1.9531e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7622 - loss: 0.7299\n",
      "Epoch 72: val_loss did not improve from 1.41874\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7622 - loss: 0.7300 - val_accuracy: 0.5286 - val_loss: 1.4664 - learning_rate: 1.9531e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7547 - loss: 0.7291\n",
      "Epoch 73: val_loss did not improve from 1.41874\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7549 - loss: 0.7291 - val_accuracy: 0.5286 - val_loss: 1.4669 - learning_rate: 1.9531e-06\n",
      "Fold 6 training completed in time: 0:08:54.391890\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Fold 6 Post-Training Train Accuracy: 0.7584\n",
      "Fold 6 Post-Training Test Accuracy: 0.5200\n",
      "[1.4187370538711548, 0.5200486183166504]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(6)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7894, 40, 174)\n",
      "(838, 40, 174)\n",
      "(7894, 10)\n",
      "(838, 10)\n",
      "x_train shape: (7894, 40, 174, 1)\n",
      "x_test shape: (838, 40, 174, 1)\n",
      "y_train shape: (7894, 10)\n",
      "y_test shape: (838, 10)\n",
      "\n",
      "Training Fold 7...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1378 - loss: 2.3220\n",
      "Epoch 1: val_loss improved from inf to 2.13481, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 268ms/step - accuracy: 0.1384 - loss: 2.3205 - val_accuracy: 0.2589 - val_loss: 2.1348 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2508 - loss: 2.0942\n",
      "Epoch 2: val_loss improved from 2.13481 to 1.76624, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.2516 - loss: 2.0920 - val_accuracy: 0.4081 - val_loss: 1.7662 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.3608 - loss: 1.7756\n",
      "Epoch 3: val_loss improved from 1.76624 to 1.56774, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.3613 - loss: 1.7745 - val_accuracy: 0.4809 - val_loss: 1.5677 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.4146 - loss: 1.5837\n",
      "Epoch 4: val_loss improved from 1.56774 to 1.43954, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.4153 - loss: 1.5831 - val_accuracy: 0.5251 - val_loss: 1.4395 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.4709 - loss: 1.4730\n",
      "Epoch 5: val_loss improved from 1.43954 to 1.40090, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 244ms/step - accuracy: 0.4711 - loss: 1.4725 - val_accuracy: 0.4773 - val_loss: 1.4009 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.4947 - loss: 1.3871\n",
      "Epoch 6: val_loss improved from 1.40090 to 1.33407, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.4947 - loss: 1.3868 - val_accuracy: 0.5394 - val_loss: 1.3341 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5193 - loss: 1.3170\n",
      "Epoch 7: val_loss improved from 1.33407 to 1.29553, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 282ms/step - accuracy: 0.5194 - loss: 1.3168 - val_accuracy: 0.5537 - val_loss: 1.2955 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.5354 - loss: 1.2874\n",
      "Epoch 8: val_loss improved from 1.29553 to 1.28052, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.5356 - loss: 1.2871 - val_accuracy: 0.5430 - val_loss: 1.2805 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5590 - loss: 1.2346\n",
      "Epoch 9: val_loss improved from 1.28052 to 1.27506, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 253ms/step - accuracy: 0.5589 - loss: 1.2344 - val_accuracy: 0.5382 - val_loss: 1.2751 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5708 - loss: 1.1977\n",
      "Epoch 10: val_loss improved from 1.27506 to 1.17801, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.5710 - loss: 1.1970 - val_accuracy: 0.5835 - val_loss: 1.1780 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5935 - loss: 1.1272\n",
      "Epoch 11: val_loss improved from 1.17801 to 1.15291, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - accuracy: 0.5935 - loss: 1.1274 - val_accuracy: 0.5811 - val_loss: 1.1529 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6117 - loss: 1.1079\n",
      "Epoch 12: val_loss did not improve from 1.15291\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.6116 - loss: 1.1079 - val_accuracy: 0.5585 - val_loss: 1.1721 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.6118 - loss: 1.0868\n",
      "Epoch 13: val_loss improved from 1.15291 to 1.08825, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 260ms/step - accuracy: 0.6118 - loss: 1.0870 - val_accuracy: 0.6325 - val_loss: 1.0882 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6288 - loss: 1.0560\n",
      "Epoch 14: val_loss improved from 1.08825 to 1.07585, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.6288 - loss: 1.0560 - val_accuracy: 0.6265 - val_loss: 1.0758 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6418 - loss: 1.0376\n",
      "Epoch 15: val_loss improved from 1.07585 to 1.05889, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.6417 - loss: 1.0376 - val_accuracy: 0.6229 - val_loss: 1.0589 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6380 - loss: 0.9991\n",
      "Epoch 16: val_loss did not improve from 1.05889\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.6382 - loss: 0.9990 - val_accuracy: 0.6480 - val_loss: 1.0884 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6436 - loss: 1.0153\n",
      "Epoch 17: val_loss did not improve from 1.05889\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.6439 - loss: 1.0148 - val_accuracy: 0.6480 - val_loss: 1.0594 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6538 - loss: 0.9768\n",
      "Epoch 18: val_loss improved from 1.05889 to 1.01375, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.6540 - loss: 0.9766 - val_accuracy: 0.6348 - val_loss: 1.0138 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6771 - loss: 0.9373\n",
      "Epoch 19: val_loss improved from 1.01375 to 1.00041, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.6770 - loss: 0.9374 - val_accuracy: 0.6635 - val_loss: 1.0004 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6700 - loss: 0.9464\n",
      "Epoch 20: val_loss improved from 1.00041 to 0.97745, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.6702 - loss: 0.9457 - val_accuracy: 0.6718 - val_loss: 0.9775 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6957 - loss: 0.9055\n",
      "Epoch 21: val_loss improved from 0.97745 to 0.96108, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 237ms/step - accuracy: 0.6955 - loss: 0.9054 - val_accuracy: 0.6444 - val_loss: 0.9611 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6985 - loss: 0.8801\n",
      "Epoch 22: val_loss did not improve from 0.96108\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.6982 - loss: 0.8805 - val_accuracy: 0.6647 - val_loss: 0.9765 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6915 - loss: 0.8899\n",
      "Epoch 23: val_loss improved from 0.96108 to 0.95726, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - accuracy: 0.6916 - loss: 0.8892 - val_accuracy: 0.6671 - val_loss: 0.9573 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7022 - loss: 0.8681\n",
      "Epoch 24: val_loss improved from 0.95726 to 0.94404, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.7022 - loss: 0.8678 - val_accuracy: 0.6659 - val_loss: 0.9440 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7183 - loss: 0.8312\n",
      "Epoch 25: val_loss improved from 0.94404 to 0.92056, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - accuracy: 0.7184 - loss: 0.8309 - val_accuracy: 0.6766 - val_loss: 0.9206 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7309 - loss: 0.8030\n",
      "Epoch 26: val_loss improved from 0.92056 to 0.90606, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.7308 - loss: 0.8029 - val_accuracy: 0.7076 - val_loss: 0.9061 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7214 - loss: 0.8110\n",
      "Epoch 27: val_loss improved from 0.90606 to 0.89494, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 246ms/step - accuracy: 0.7216 - loss: 0.8106 - val_accuracy: 0.6897 - val_loss: 0.8949 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7356 - loss: 0.7892\n",
      "Epoch 28: val_loss did not improve from 0.89494\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7355 - loss: 0.7895 - val_accuracy: 0.6993 - val_loss: 0.9424 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7308 - loss: 0.7811\n",
      "Epoch 29: val_loss improved from 0.89494 to 0.87536, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - accuracy: 0.7308 - loss: 0.7808 - val_accuracy: 0.6814 - val_loss: 0.8754 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7519 - loss: 0.7532\n",
      "Epoch 30: val_loss improved from 0.87536 to 0.86749, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - accuracy: 0.7516 - loss: 0.7538 - val_accuracy: 0.7160 - val_loss: 0.8675 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7468 - loss: 0.7641\n",
      "Epoch 31: val_loss did not improve from 0.86749\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7467 - loss: 0.7641 - val_accuracy: 0.6372 - val_loss: 0.9179 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7457 - loss: 0.7388\n",
      "Epoch 32: val_loss did not improve from 0.86749\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 179ms/step - accuracy: 0.7458 - loss: 0.7387 - val_accuracy: 0.6862 - val_loss: 0.8826 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7551 - loss: 0.7175\n",
      "Epoch 33: val_loss did not improve from 0.86749\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7550 - loss: 0.7176 - val_accuracy: 0.6790 - val_loss: 0.9365 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7636 - loss: 0.7105\n",
      "Epoch 34: val_loss improved from 0.86749 to 0.83289, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.7636 - loss: 0.7102 - val_accuracy: 0.7088 - val_loss: 0.8329 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7491 - loss: 0.7300\n",
      "Epoch 35: val_loss did not improve from 0.83289\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.7493 - loss: 0.7296 - val_accuracy: 0.7064 - val_loss: 0.8523 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7706 - loss: 0.6899\n",
      "Epoch 36: val_loss did not improve from 0.83289\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 179ms/step - accuracy: 0.7705 - loss: 0.6900 - val_accuracy: 0.7434 - val_loss: 0.8663 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7698 - loss: 0.6869\n",
      "Epoch 37: val_loss did not improve from 0.83289\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.7699 - loss: 0.6866 - val_accuracy: 0.7029 - val_loss: 0.8721 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7836 - loss: 0.6742\n",
      "Epoch 38: val_loss did not improve from 0.83289\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7834 - loss: 0.6744 - val_accuracy: 0.7029 - val_loss: 0.8742 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7815 - loss: 0.6493\n",
      "Epoch 39: val_loss improved from 0.83289 to 0.81795, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.7817 - loss: 0.6491 - val_accuracy: 0.7291 - val_loss: 0.8180 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7817 - loss: 0.6553\n",
      "Epoch 40: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7817 - loss: 0.6553 - val_accuracy: 0.6802 - val_loss: 0.9126 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7919 - loss: 0.6328\n",
      "Epoch 41: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.7919 - loss: 0.6330 - val_accuracy: 0.7136 - val_loss: 0.8688 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7969 - loss: 0.6297\n",
      "Epoch 42: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7967 - loss: 0.6300 - val_accuracy: 0.7363 - val_loss: 0.8226 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7954 - loss: 0.6216\n",
      "Epoch 43: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7955 - loss: 0.6215 - val_accuracy: 0.7029 - val_loss: 0.8534 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8004 - loss: 0.6057\n",
      "Epoch 44: val_loss did not improve from 0.81795\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8005 - loss: 0.6058 - val_accuracy: 0.7243 - val_loss: 0.8567 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8066 - loss: 0.6033\n",
      "Epoch 45: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.8068 - loss: 0.6026 - val_accuracy: 0.7232 - val_loss: 0.8478 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8163 - loss: 0.5651\n",
      "Epoch 46: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.8161 - loss: 0.5655 - val_accuracy: 0.7196 - val_loss: 0.8558 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8116 - loss: 0.5754\n",
      "Epoch 47: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.8116 - loss: 0.5754 - val_accuracy: 0.7291 - val_loss: 0.8303 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8087 - loss: 0.5914\n",
      "Epoch 48: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.8088 - loss: 0.5909 - val_accuracy: 0.7124 - val_loss: 0.8607 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8120 - loss: 0.5650\n",
      "Epoch 49: val_loss did not improve from 0.81795\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 179ms/step - accuracy: 0.8120 - loss: 0.5650 - val_accuracy: 0.7411 - val_loss: 0.8190 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8216 - loss: 0.5566\n",
      "Epoch 50: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8216 - loss: 0.5567 - val_accuracy: 0.7279 - val_loss: 0.8220 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8218 - loss: 0.5554\n",
      "Epoch 51: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8218 - loss: 0.5553 - val_accuracy: 0.7315 - val_loss: 0.8314 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8257 - loss: 0.5403\n",
      "Epoch 52: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8257 - loss: 0.5405 - val_accuracy: 0.7243 - val_loss: 0.8477 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8225 - loss: 0.5496\n",
      "Epoch 53: val_loss did not improve from 0.81795\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.8224 - loss: 0.5495 - val_accuracy: 0.7136 - val_loss: 0.8600 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8316 - loss: 0.5381\n",
      "Epoch 54: val_loss improved from 0.81795 to 0.81237, saving model to saved_models/weights.fold7.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.8314 - loss: 0.5383 - val_accuracy: 0.7339 - val_loss: 0.8124 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8217 - loss: 0.5386\n",
      "Epoch 55: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.8216 - loss: 0.5389 - val_accuracy: 0.6945 - val_loss: 0.8837 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8252 - loss: 0.5414\n",
      "Epoch 56: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8253 - loss: 0.5415 - val_accuracy: 0.7232 - val_loss: 0.8494 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8356 - loss: 0.5269\n",
      "Epoch 57: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.8355 - loss: 0.5271 - val_accuracy: 0.7399 - val_loss: 0.8389 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8218 - loss: 0.5522\n",
      "Epoch 58: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8219 - loss: 0.5518 - val_accuracy: 0.7100 - val_loss: 0.8750 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8357 - loss: 0.5261\n",
      "Epoch 59: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8357 - loss: 0.5264 - val_accuracy: 0.7446 - val_loss: 0.8169 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8280 - loss: 0.5341\n",
      "Epoch 60: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8280 - loss: 0.5341 - val_accuracy: 0.7291 - val_loss: 0.8312 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8334 - loss: 0.5397\n",
      "Epoch 61: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8334 - loss: 0.5394 - val_accuracy: 0.7327 - val_loss: 0.8231 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8221 - loss: 0.5355\n",
      "Epoch 62: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.8223 - loss: 0.5352 - val_accuracy: 0.7315 - val_loss: 0.8288 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8342 - loss: 0.5271\n",
      "Epoch 63: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8341 - loss: 0.5272 - val_accuracy: 0.7279 - val_loss: 0.8400 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8226 - loss: 0.5377\n",
      "Epoch 64: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8230 - loss: 0.5373 - val_accuracy: 0.7315 - val_loss: 0.8349 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8304 - loss: 0.5286\n",
      "Epoch 65: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.8306 - loss: 0.5284 - val_accuracy: 0.7387 - val_loss: 0.8267 - learning_rate: 6.2500e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8383 - loss: 0.5343\n",
      "Epoch 66: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8382 - loss: 0.5340 - val_accuracy: 0.7220 - val_loss: 0.8490 - learning_rate: 6.2500e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8274 - loss: 0.5345\n",
      "Epoch 67: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.8276 - loss: 0.5341 - val_accuracy: 0.7363 - val_loss: 0.8233 - learning_rate: 6.2500e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8341 - loss: 0.5249\n",
      "Epoch 68: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8343 - loss: 0.5246 - val_accuracy: 0.7363 - val_loss: 0.8262 - learning_rate: 6.2500e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8344 - loss: 0.5209\n",
      "Epoch 69: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8344 - loss: 0.5209 - val_accuracy: 0.7315 - val_loss: 0.8413 - learning_rate: 6.2500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8380 - loss: 0.5146\n",
      "Epoch 70: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8379 - loss: 0.5146 - val_accuracy: 0.7291 - val_loss: 0.8454 - learning_rate: 3.1250e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8394 - loss: 0.5133\n",
      "Epoch 71: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8394 - loss: 0.5134 - val_accuracy: 0.7303 - val_loss: 0.8382 - learning_rate: 3.1250e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8418 - loss: 0.5011\n",
      "Epoch 72: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.8418 - loss: 0.5014 - val_accuracy: 0.7339 - val_loss: 0.8372 - learning_rate: 3.1250e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8264 - loss: 0.5206\n",
      "Epoch 73: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8267 - loss: 0.5203 - val_accuracy: 0.7279 - val_loss: 0.8395 - learning_rate: 3.1250e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8358 - loss: 0.5136\n",
      "Epoch 74: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8359 - loss: 0.5136 - val_accuracy: 0.7315 - val_loss: 0.8314 - learning_rate: 3.1250e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8254 - loss: 0.5403\n",
      "Epoch 75: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8257 - loss: 0.5397 - val_accuracy: 0.7363 - val_loss: 0.8351 - learning_rate: 1.5625e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8388 - loss: 0.5154\n",
      "Epoch 76: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8387 - loss: 0.5154 - val_accuracy: 0.7291 - val_loss: 0.8343 - learning_rate: 1.5625e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8355 - loss: 0.5115\n",
      "Epoch 77: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8354 - loss: 0.5117 - val_accuracy: 0.7303 - val_loss: 0.8347 - learning_rate: 1.5625e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8325 - loss: 0.5145\n",
      "Epoch 78: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8326 - loss: 0.5147 - val_accuracy: 0.7339 - val_loss: 0.8359 - learning_rate: 1.5625e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8338 - loss: 0.5073\n",
      "Epoch 79: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8339 - loss: 0.5075 - val_accuracy: 0.7303 - val_loss: 0.8379 - learning_rate: 1.5625e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8313 - loss: 0.5202\n",
      "Epoch 80: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8314 - loss: 0.5203 - val_accuracy: 0.7291 - val_loss: 0.8360 - learning_rate: 7.8125e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8332 - loss: 0.5050\n",
      "Epoch 81: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.8332 - loss: 0.5050 - val_accuracy: 0.7303 - val_loss: 0.8347 - learning_rate: 7.8125e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8375 - loss: 0.5148\n",
      "Epoch 82: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8374 - loss: 0.5149 - val_accuracy: 0.7255 - val_loss: 0.8360 - learning_rate: 7.8125e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8376 - loss: 0.5260\n",
      "Epoch 83: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8376 - loss: 0.5256 - val_accuracy: 0.7315 - val_loss: 0.8330 - learning_rate: 7.8125e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8440 - loss: 0.5160\n",
      "Epoch 84: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.8438 - loss: 0.5162 - val_accuracy: 0.7303 - val_loss: 0.8325 - learning_rate: 7.8125e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8331 - loss: 0.5165\n",
      "Epoch 85: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8332 - loss: 0.5165 - val_accuracy: 0.7303 - val_loss: 0.8339 - learning_rate: 3.9063e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8398 - loss: 0.5170\n",
      "Epoch 86: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8397 - loss: 0.5170 - val_accuracy: 0.7267 - val_loss: 0.8358 - learning_rate: 3.9063e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8395 - loss: 0.5050\n",
      "Epoch 87: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8394 - loss: 0.5051 - val_accuracy: 0.7291 - val_loss: 0.8344 - learning_rate: 3.9063e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8323 - loss: 0.5265\n",
      "Epoch 88: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.8324 - loss: 0.5262 - val_accuracy: 0.7279 - val_loss: 0.8373 - learning_rate: 3.9063e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8321 - loss: 0.5237\n",
      "Epoch 89: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8322 - loss: 0.5235 - val_accuracy: 0.7315 - val_loss: 0.8355 - learning_rate: 3.9063e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8328 - loss: 0.5220\n",
      "Epoch 90: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8329 - loss: 0.5218 - val_accuracy: 0.7267 - val_loss: 0.8366 - learning_rate: 1.9531e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8377 - loss: 0.5029\n",
      "Epoch 91: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8377 - loss: 0.5031 - val_accuracy: 0.7267 - val_loss: 0.8363 - learning_rate: 1.9531e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8396 - loss: 0.5021\n",
      "Epoch 92: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8394 - loss: 0.5026 - val_accuracy: 0.7267 - val_loss: 0.8364 - learning_rate: 1.9531e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8353 - loss: 0.5077\n",
      "Epoch 93: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.8353 - loss: 0.5079 - val_accuracy: 0.7267 - val_loss: 0.8367 - learning_rate: 1.9531e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8377 - loss: 0.5117\n",
      "Epoch 94: val_loss did not improve from 0.81237\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8377 - loss: 0.5117 - val_accuracy: 0.7279 - val_loss: 0.8357 - learning_rate: 1.9531e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8345 - loss: 0.5020\n",
      "Epoch 95: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8345 - loss: 0.5023 - val_accuracy: 0.7279 - val_loss: 0.8355 - learning_rate: 1.0000e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8415 - loss: 0.5099\n",
      "Epoch 96: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8414 - loss: 0.5099 - val_accuracy: 0.7279 - val_loss: 0.8349 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8435 - loss: 0.5048\n",
      "Epoch 97: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.8434 - loss: 0.5049 - val_accuracy: 0.7279 - val_loss: 0.8351 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8274 - loss: 0.5311\n",
      "Epoch 98: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8276 - loss: 0.5307 - val_accuracy: 0.7279 - val_loss: 0.8349 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8355 - loss: 0.5119\n",
      "Epoch 99: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8354 - loss: 0.5119 - val_accuracy: 0.7267 - val_loss: 0.8358 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8339 - loss: 0.5218\n",
      "Epoch 100: val_loss did not improve from 0.81237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8339 - loss: 0.5218 - val_accuracy: 0.7279 - val_loss: 0.8350 - learning_rate: 1.0000e-06\n",
      "Fold 7 training completed in time: 0:09:38.681553\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Fold 7 Post-Training Train Accuracy: 0.8351\n",
      "Fold 7 Post-Training Test Accuracy: 0.7339\n",
      "[0.8123674988746643, 0.7338902354240417]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(7)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1152f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7926, 40, 174)\n",
      "(806, 40, 174)\n",
      "(7926, 10)\n",
      "(806, 10)\n",
      "x_train shape: (7926, 40, 174, 1)\n",
      "x_test shape: (806, 40, 174, 1)\n",
      "y_train shape: (7926, 10)\n",
      "y_test shape: (806, 10)\n",
      "\n",
      "Training Fold 8...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.1243 - loss: 2.2994\n",
      "Epoch 1: val_loss improved from inf to 2.12860, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 878ms/step - accuracy: 0.1250 - loss: 2.2984 - val_accuracy: 0.2035 - val_loss: 2.1286 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2391 - loss: 2.0841\n",
      "Epoch 2: val_loss improved from 2.12860 to 1.81333, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.2400 - loss: 2.0824 - val_accuracy: 0.4318 - val_loss: 1.8133 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3666 - loss: 1.8158\n",
      "Epoch 3: val_loss improved from 1.81333 to 1.63351, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 801ms/step - accuracy: 0.3671 - loss: 1.8143 - val_accuracy: 0.5087 - val_loss: 1.6335 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.4330 - loss: 1.6055\n",
      "Epoch 4: val_loss improved from 1.63351 to 1.54562, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.4333 - loss: 1.6047 - val_accuracy: 0.5509 - val_loss: 1.5456 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.4669 - loss: 1.4775\n",
      "Epoch 5: val_loss improved from 1.54562 to 1.49255, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 887ms/step - accuracy: 0.4671 - loss: 1.4768 - val_accuracy: 0.5955 - val_loss: 1.4926 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4964 - loss: 1.4143\n",
      "Epoch 6: val_loss improved from 1.49255 to 1.44936, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.4966 - loss: 1.4134 - val_accuracy: 0.5558 - val_loss: 1.4494 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5255 - loss: 1.3271\n",
      "Epoch 7: val_loss did not improve from 1.44936\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.5258 - loss: 1.3263 - val_accuracy: 0.5893 - val_loss: 1.4962 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5507 - loss: 1.2308\n",
      "Epoch 8: val_loss did not improve from 1.44936\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.5507 - loss: 1.2312 - val_accuracy: 0.5161 - val_loss: 1.5218 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5545 - loss: 1.2212\n",
      "Epoch 9: val_loss did not improve from 1.44936\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.5549 - loss: 1.2204 - val_accuracy: 0.6266 - val_loss: 1.4694 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5717 - loss: 1.1939\n",
      "Epoch 10: val_loss did not improve from 1.44936\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.5720 - loss: 1.1935 - val_accuracy: 0.5968 - val_loss: 1.4524 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5994 - loss: 1.1199\n",
      "Epoch 11: val_loss improved from 1.44936 to 1.40386, saving model to saved_models/weights.fold8.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 819ms/step - accuracy: 0.5993 - loss: 1.1200 - val_accuracy: 0.5906 - val_loss: 1.4039 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5969 - loss: 1.1072\n",
      "Epoch 12: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.5971 - loss: 1.1071 - val_accuracy: 0.5906 - val_loss: 1.4430 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6098 - loss: 1.0848\n",
      "Epoch 13: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - accuracy: 0.6100 - loss: 1.0844 - val_accuracy: 0.6203 - val_loss: 1.4103 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.6193 - loss: 1.0596\n",
      "Epoch 14: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.6194 - loss: 1.0593 - val_accuracy: 0.6203 - val_loss: 1.4855 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6412 - loss: 1.0251\n",
      "Epoch 15: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.6412 - loss: 1.0247 - val_accuracy: 0.6166 - val_loss: 1.4255 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6466 - loss: 0.9944\n",
      "Epoch 16: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - accuracy: 0.6465 - loss: 0.9946 - val_accuracy: 0.6166 - val_loss: 1.4264 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6637 - loss: 0.9592\n",
      "Epoch 17: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.6636 - loss: 0.9594 - val_accuracy: 0.6154 - val_loss: 1.4198 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6769 - loss: 0.9187\n",
      "Epoch 18: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.6767 - loss: 0.9193 - val_accuracy: 0.5732 - val_loss: 1.4409 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6655 - loss: 0.9405\n",
      "Epoch 19: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.6656 - loss: 0.9403 - val_accuracy: 0.5868 - val_loss: 1.4381 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6767 - loss: 0.9331\n",
      "Epoch 20: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.6767 - loss: 0.9329 - val_accuracy: 0.6414 - val_loss: 1.4177 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6912 - loss: 0.9095\n",
      "Epoch 21: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.6912 - loss: 0.9092 - val_accuracy: 0.6427 - val_loss: 1.4523 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6911 - loss: 0.8892\n",
      "Epoch 22: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.6912 - loss: 0.8892 - val_accuracy: 0.6117 - val_loss: 1.4471 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6903 - loss: 0.8782\n",
      "Epoch 23: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.6903 - loss: 0.8785 - val_accuracy: 0.6489 - val_loss: 1.4088 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7037 - loss: 0.8676\n",
      "Epoch 24: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7036 - loss: 0.8677 - val_accuracy: 0.6439 - val_loss: 1.4408 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7091 - loss: 0.8650\n",
      "Epoch 25: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.7090 - loss: 0.8647 - val_accuracy: 0.6464 - val_loss: 1.4542 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7091 - loss: 0.8447\n",
      "Epoch 26: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7089 - loss: 0.8451 - val_accuracy: 0.5658 - val_loss: 1.5040 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6974 - loss: 0.8669\n",
      "Epoch 27: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.6977 - loss: 0.8664 - val_accuracy: 0.6501 - val_loss: 1.4322 - learning_rate: 1.2500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6984 - loss: 0.8532\n",
      "Epoch 28: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.6986 - loss: 0.8530 - val_accuracy: 0.6414 - val_loss: 1.4577 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7195 - loss: 0.8368\n",
      "Epoch 29: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7193 - loss: 0.8369 - val_accuracy: 0.6340 - val_loss: 1.4872 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7144 - loss: 0.8414\n",
      "Epoch 30: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7144 - loss: 0.8412 - val_accuracy: 0.6253 - val_loss: 1.4557 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7167 - loss: 0.8287\n",
      "Epoch 31: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7166 - loss: 0.8289 - val_accuracy: 0.6315 - val_loss: 1.4681 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7155 - loss: 0.8304\n",
      "Epoch 32: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7155 - loss: 0.8300 - val_accuracy: 0.6439 - val_loss: 1.4504 - learning_rate: 6.2500e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7142 - loss: 0.8336\n",
      "Epoch 33: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7142 - loss: 0.8333 - val_accuracy: 0.6439 - val_loss: 1.4579 - learning_rate: 6.2500e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7151 - loss: 0.8317\n",
      "Epoch 34: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7151 - loss: 0.8317 - val_accuracy: 0.6427 - val_loss: 1.4549 - learning_rate: 6.2500e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7143 - loss: 0.8118\n",
      "Epoch 35: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7144 - loss: 0.8120 - val_accuracy: 0.6253 - val_loss: 1.4841 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7067 - loss: 0.8479\n",
      "Epoch 36: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7070 - loss: 0.8472 - val_accuracy: 0.5906 - val_loss: 1.4840 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7165 - loss: 0.8227\n",
      "Epoch 37: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.7166 - loss: 0.8226 - val_accuracy: 0.6390 - val_loss: 1.4742 - learning_rate: 3.1250e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7124 - loss: 0.8267\n",
      "Epoch 38: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7124 - loss: 0.8267 - val_accuracy: 0.6377 - val_loss: 1.4688 - learning_rate: 3.1250e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7210 - loss: 0.8258\n",
      "Epoch 39: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7210 - loss: 0.8256 - val_accuracy: 0.6179 - val_loss: 1.4901 - learning_rate: 3.1250e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7131 - loss: 0.8199\n",
      "Epoch 40: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7132 - loss: 0.8199 - val_accuracy: 0.6414 - val_loss: 1.4679 - learning_rate: 3.1250e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7270 - loss: 0.8264\n",
      "Epoch 41: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.7270 - loss: 0.8262 - val_accuracy: 0.6377 - val_loss: 1.4736 - learning_rate: 3.1250e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7208 - loss: 0.8189\n",
      "Epoch 42: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7208 - loss: 0.8187 - val_accuracy: 0.6340 - val_loss: 1.4789 - learning_rate: 1.5625e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7185 - loss: 0.8179\n",
      "Epoch 43: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.7185 - loss: 0.8179 - val_accuracy: 0.6365 - val_loss: 1.4689 - learning_rate: 1.5625e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7116 - loss: 0.8219\n",
      "Epoch 44: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.7117 - loss: 0.8219 - val_accuracy: 0.6352 - val_loss: 1.4765 - learning_rate: 1.5625e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7265 - loss: 0.8125\n",
      "Epoch 45: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7264 - loss: 0.8126 - val_accuracy: 0.6340 - val_loss: 1.4761 - learning_rate: 1.5625e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7261 - loss: 0.7994\n",
      "Epoch 46: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7261 - loss: 0.7999 - val_accuracy: 0.6352 - val_loss: 1.4717 - learning_rate: 1.5625e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7292 - loss: 0.7950\n",
      "Epoch 47: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7290 - loss: 0.7954 - val_accuracy: 0.6365 - val_loss: 1.4713 - learning_rate: 7.8125e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7308 - loss: 0.7910\n",
      "Epoch 48: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - accuracy: 0.7304 - loss: 0.7918 - val_accuracy: 0.6365 - val_loss: 1.4716 - learning_rate: 7.8125e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7206 - loss: 0.8116\n",
      "Epoch 49: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.7206 - loss: 0.8116 - val_accuracy: 0.6390 - val_loss: 1.4721 - learning_rate: 7.8125e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7149 - loss: 0.8009\n",
      "Epoch 50: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.7150 - loss: 0.8011 - val_accuracy: 0.6402 - val_loss: 1.4718 - learning_rate: 7.8125e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7173 - loss: 0.8206\n",
      "Epoch 51: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.7172 - loss: 0.8206 - val_accuracy: 0.6365 - val_loss: 1.4764 - learning_rate: 7.8125e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7146 - loss: 0.8329\n",
      "Epoch 52: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.7149 - loss: 0.8324 - val_accuracy: 0.6352 - val_loss: 1.4778 - learning_rate: 3.9063e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7220 - loss: 0.8065\n",
      "Epoch 53: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.7219 - loss: 0.8066 - val_accuracy: 0.6340 - val_loss: 1.4759 - learning_rate: 3.9063e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7146 - loss: 0.8103\n",
      "Epoch 54: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7147 - loss: 0.8103 - val_accuracy: 0.6365 - val_loss: 1.4724 - learning_rate: 3.9063e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7315 - loss: 0.8003\n",
      "Epoch 55: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.7313 - loss: 0.8005 - val_accuracy: 0.6352 - val_loss: 1.4713 - learning_rate: 3.9063e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7263 - loss: 0.8020\n",
      "Epoch 56: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - accuracy: 0.7262 - loss: 0.8020 - val_accuracy: 0.6352 - val_loss: 1.4746 - learning_rate: 3.9063e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7223 - loss: 0.8208\n",
      "Epoch 57: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7224 - loss: 0.8205 - val_accuracy: 0.6365 - val_loss: 1.4750 - learning_rate: 1.9531e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7282 - loss: 0.8006\n",
      "Epoch 58: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7280 - loss: 0.8008 - val_accuracy: 0.6352 - val_loss: 1.4737 - learning_rate: 1.9531e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7231 - loss: 0.8121\n",
      "Epoch 59: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.7232 - loss: 0.8121 - val_accuracy: 0.6365 - val_loss: 1.4734 - learning_rate: 1.9531e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7246 - loss: 0.7983\n",
      "Epoch 60: val_loss did not improve from 1.40386\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7247 - loss: 0.7984 - val_accuracy: 0.6365 - val_loss: 1.4742 - learning_rate: 1.9531e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7245 - loss: 0.8124\n",
      "Epoch 61: val_loss did not improve from 1.40386\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.7245 - loss: 0.8124 - val_accuracy: 0.6365 - val_loss: 1.4751 - learning_rate: 1.9531e-06\n",
      "Fold 8 training completed in time: 0:06:54.284195\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "Fold 8 Post-Training Train Accuracy: 0.7234\n",
      "Fold 8 Post-Training Test Accuracy: 0.5906\n",
      "[1.4038597345352173, 0.5905707478523254]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(8)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7916, 40, 174)\n",
      "(816, 40, 174)\n",
      "(7916, 10)\n",
      "(816, 10)\n",
      "x_train shape: (7916, 40, 174, 1)\n",
      "x_test shape: (816, 40, 174, 1)\n",
      "y_train shape: (7916, 10)\n",
      "y_test shape: (816, 10)\n",
      "\n",
      "Training Fold 9...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1396 - loss: 2.2964\n",
      "Epoch 1: val_loss improved from inf to 2.04258, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 624ms/step - accuracy: 0.1405 - loss: 2.2948 - val_accuracy: 0.3064 - val_loss: 2.0426 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2664 - loss: 2.0189\n",
      "Epoch 2: val_loss improved from 2.04258 to 1.74656, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.2673 - loss: 2.0169 - val_accuracy: 0.3627 - val_loss: 1.7466 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.3830 - loss: 1.7394\n",
      "Epoch 3: val_loss improved from 1.74656 to 1.65205, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 623ms/step - accuracy: 0.3835 - loss: 1.7379 - val_accuracy: 0.3738 - val_loss: 1.6520 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.4455 - loss: 1.5644\n",
      "Epoch 4: val_loss improved from 1.65205 to 1.48098, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.4457 - loss: 1.5634 - val_accuracy: 0.4436 - val_loss: 1.4810 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.4717 - loss: 1.4410\n",
      "Epoch 5: val_loss improved from 1.48098 to 1.40426, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 623ms/step - accuracy: 0.4721 - loss: 1.4405 - val_accuracy: 0.4755 - val_loss: 1.4043 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5059 - loss: 1.3638\n",
      "Epoch 6: val_loss improved from 1.40426 to 1.34547, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.5061 - loss: 1.3630 - val_accuracy: 0.4963 - val_loss: 1.3455 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5254 - loss: 1.2898\n",
      "Epoch 7: val_loss did not improve from 1.34547\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.5255 - loss: 1.2897 - val_accuracy: 0.4767 - val_loss: 1.3503 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5460 - loss: 1.2489\n",
      "Epoch 8: val_loss improved from 1.34547 to 1.24108, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 571ms/step - accuracy: 0.5461 - loss: 1.2488 - val_accuracy: 0.5551 - val_loss: 1.2411 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5574 - loss: 1.2357\n",
      "Epoch 9: val_loss did not improve from 1.24108\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.5575 - loss: 1.2347 - val_accuracy: 0.5135 - val_loss: 1.3298 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5664 - loss: 1.1978\n",
      "Epoch 10: val_loss did not improve from 1.24108\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.5666 - loss: 1.1972 - val_accuracy: 0.5564 - val_loss: 1.2701 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5866 - loss: 1.1398\n",
      "Epoch 11: val_loss improved from 1.24108 to 1.19465, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 249ms/step - accuracy: 0.5867 - loss: 1.1398 - val_accuracy: 0.5882 - val_loss: 1.1946 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5976 - loss: 1.1238\n",
      "Epoch 12: val_loss improved from 1.19465 to 1.18825, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 620ms/step - accuracy: 0.5977 - loss: 1.1234 - val_accuracy: 0.6397 - val_loss: 1.1882 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6180 - loss: 1.0797\n",
      "Epoch 13: val_loss did not improve from 1.18825\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.6181 - loss: 1.0796 - val_accuracy: 0.6311 - val_loss: 1.1953 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6305 - loss: 1.0581\n",
      "Epoch 14: val_loss did not improve from 1.18825\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.6305 - loss: 1.0578 - val_accuracy: 0.6164 - val_loss: 1.2400 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6353 - loss: 1.0239\n",
      "Epoch 15: val_loss did not improve from 1.18825\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.6353 - loss: 1.0242 - val_accuracy: 0.6311 - val_loss: 1.2332 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6348 - loss: 1.0129\n",
      "Epoch 16: val_loss improved from 1.18825 to 1.18542, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.6352 - loss: 1.0125 - val_accuracy: 0.6066 - val_loss: 1.1854 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6518 - loss: 1.0077\n",
      "Epoch 17: val_loss did not improve from 1.18542\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.6521 - loss: 1.0069 - val_accuracy: 0.6348 - val_loss: 1.2477 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6660 - loss: 0.9483\n",
      "Epoch 18: val_loss improved from 1.18542 to 1.17832, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 594ms/step - accuracy: 0.6662 - loss: 0.9480 - val_accuracy: 0.6777 - val_loss: 1.1783 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6830 - loss: 0.9280\n",
      "Epoch 19: val_loss did not improve from 1.17832\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.6828 - loss: 0.9282 - val_accuracy: 0.6520 - val_loss: 1.2148 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6837 - loss: 0.9090\n",
      "Epoch 20: val_loss did not improve from 1.17832\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.6836 - loss: 0.9094 - val_accuracy: 0.6544 - val_loss: 1.1808 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6926 - loss: 0.8898\n",
      "Epoch 21: val_loss did not improve from 1.17832\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.6927 - loss: 0.8899 - val_accuracy: 0.6446 - val_loss: 1.2042 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7059 - loss: 0.8546\n",
      "Epoch 22: val_loss improved from 1.17832 to 1.16068, saving model to saved_models/weights.fold9.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - accuracy: 0.7059 - loss: 0.8546 - val_accuracy: 0.6507 - val_loss: 1.1607 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7029 - loss: 0.8502\n",
      "Epoch 23: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.7028 - loss: 0.8506 - val_accuracy: 0.6507 - val_loss: 1.2351 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7162 - loss: 0.8442\n",
      "Epoch 24: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.7163 - loss: 0.8439 - val_accuracy: 0.6299 - val_loss: 1.2725 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7330 - loss: 0.8062\n",
      "Epoch 25: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7329 - loss: 0.8066 - val_accuracy: 0.6446 - val_loss: 1.2191 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7388 - loss: 0.7950\n",
      "Epoch 26: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7387 - loss: 0.7951 - val_accuracy: 0.6569 - val_loss: 1.2103 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7423 - loss: 0.7808\n",
      "Epoch 27: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7422 - loss: 0.7808 - val_accuracy: 0.6544 - val_loss: 1.2225 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7543 - loss: 0.7490\n",
      "Epoch 28: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7543 - loss: 0.7489 - val_accuracy: 0.6691 - val_loss: 1.3376 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7638 - loss: 0.7264\n",
      "Epoch 29: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7636 - loss: 0.7270 - val_accuracy: 0.6642 - val_loss: 1.2635 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7628 - loss: 0.7192\n",
      "Epoch 30: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7628 - loss: 0.7192 - val_accuracy: 0.6679 - val_loss: 1.3742 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7615 - loss: 0.7102\n",
      "Epoch 31: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7614 - loss: 0.7106 - val_accuracy: 0.6691 - val_loss: 1.3007 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7624 - loss: 0.7328\n",
      "Epoch 32: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7625 - loss: 0.7325 - val_accuracy: 0.6581 - val_loss: 1.3455 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7782 - loss: 0.6989\n",
      "Epoch 33: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7780 - loss: 0.6988 - val_accuracy: 0.6740 - val_loss: 1.3398 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7765 - loss: 0.6902\n",
      "Epoch 34: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7764 - loss: 0.6903 - val_accuracy: 0.6679 - val_loss: 1.3547 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7769 - loss: 0.6934\n",
      "Epoch 35: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7769 - loss: 0.6934 - val_accuracy: 0.6471 - val_loss: 1.2959 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7759 - loss: 0.6989\n",
      "Epoch 36: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7759 - loss: 0.6987 - val_accuracy: 0.6728 - val_loss: 1.3371 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7735 - loss: 0.7026\n",
      "Epoch 37: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - accuracy: 0.7736 - loss: 0.7022 - val_accuracy: 0.6593 - val_loss: 1.3190 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7732 - loss: 0.6834\n",
      "Epoch 38: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7734 - loss: 0.6831 - val_accuracy: 0.6716 - val_loss: 1.3430 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7853 - loss: 0.6668\n",
      "Epoch 39: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7853 - loss: 0.6669 - val_accuracy: 0.6703 - val_loss: 1.3387 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7737 - loss: 0.6949\n",
      "Epoch 40: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.7739 - loss: 0.6943 - val_accuracy: 0.6703 - val_loss: 1.3358 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7826 - loss: 0.6740\n",
      "Epoch 41: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7825 - loss: 0.6740 - val_accuracy: 0.6740 - val_loss: 1.3355 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7891 - loss: 0.6744\n",
      "Epoch 42: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7891 - loss: 0.6741 - val_accuracy: 0.6789 - val_loss: 1.3559 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7843 - loss: 0.6724\n",
      "Epoch 43: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7844 - loss: 0.6721 - val_accuracy: 0.6716 - val_loss: 1.3231 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7998 - loss: 0.6240\n",
      "Epoch 44: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7994 - loss: 0.6250 - val_accuracy: 0.6654 - val_loss: 1.3331 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7929 - loss: 0.6400\n",
      "Epoch 45: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7928 - loss: 0.6404 - val_accuracy: 0.6679 - val_loss: 1.3430 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7763 - loss: 0.6812\n",
      "Epoch 46: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7766 - loss: 0.6805 - val_accuracy: 0.6765 - val_loss: 1.3485 - learning_rate: 6.2500e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7824 - loss: 0.6630\n",
      "Epoch 47: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7826 - loss: 0.6628 - val_accuracy: 0.6765 - val_loss: 1.3564 - learning_rate: 6.2500e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7850 - loss: 0.6668\n",
      "Epoch 48: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7851 - loss: 0.6664 - val_accuracy: 0.6740 - val_loss: 1.3486 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7929 - loss: 0.6482\n",
      "Epoch 49: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.7929 - loss: 0.6484 - val_accuracy: 0.6740 - val_loss: 1.3579 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7906 - loss: 0.6515\n",
      "Epoch 50: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7906 - loss: 0.6515 - val_accuracy: 0.6716 - val_loss: 1.3580 - learning_rate: 3.1250e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7889 - loss: 0.6406\n",
      "Epoch 51: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7889 - loss: 0.6409 - val_accuracy: 0.6728 - val_loss: 1.3650 - learning_rate: 3.1250e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7887 - loss: 0.6546\n",
      "Epoch 52: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7888 - loss: 0.6545 - val_accuracy: 0.6740 - val_loss: 1.3470 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7840 - loss: 0.6649\n",
      "Epoch 53: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7841 - loss: 0.6646 - val_accuracy: 0.6740 - val_loss: 1.3478 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7930 - loss: 0.6478\n",
      "Epoch 54: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7929 - loss: 0.6481 - val_accuracy: 0.6728 - val_loss: 1.3561 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7967 - loss: 0.6483\n",
      "Epoch 55: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 0.7966 - loss: 0.6484 - val_accuracy: 0.6740 - val_loss: 1.3483 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8060 - loss: 0.6275\n",
      "Epoch 56: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.8057 - loss: 0.6279 - val_accuracy: 0.6752 - val_loss: 1.3544 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7990 - loss: 0.6379\n",
      "Epoch 57: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7987 - loss: 0.6384 - val_accuracy: 0.6703 - val_loss: 1.3489 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7894 - loss: 0.6636\n",
      "Epoch 58: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7893 - loss: 0.6636 - val_accuracy: 0.6728 - val_loss: 1.3539 - learning_rate: 7.8125e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7897 - loss: 0.6578\n",
      "Epoch 59: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7898 - loss: 0.6577 - val_accuracy: 0.6728 - val_loss: 1.3488 - learning_rate: 7.8125e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7876 - loss: 0.6691\n",
      "Epoch 60: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7877 - loss: 0.6685 - val_accuracy: 0.6728 - val_loss: 1.3511 - learning_rate: 7.8125e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7841 - loss: 0.6600\n",
      "Epoch 61: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.7843 - loss: 0.6598 - val_accuracy: 0.6716 - val_loss: 1.3507 - learning_rate: 7.8125e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7953 - loss: 0.6379\n",
      "Epoch 62: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7951 - loss: 0.6384 - val_accuracy: 0.6752 - val_loss: 1.3559 - learning_rate: 7.8125e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7879 - loss: 0.6479\n",
      "Epoch 63: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7877 - loss: 0.6482 - val_accuracy: 0.6740 - val_loss: 1.3537 - learning_rate: 3.9063e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7929 - loss: 0.6470\n",
      "Epoch 64: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7929 - loss: 0.6471 - val_accuracy: 0.6740 - val_loss: 1.3487 - learning_rate: 3.9063e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7949 - loss: 0.6565\n",
      "Epoch 65: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7949 - loss: 0.6562 - val_accuracy: 0.6728 - val_loss: 1.3495 - learning_rate: 3.9063e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7897 - loss: 0.6511\n",
      "Epoch 66: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7899 - loss: 0.6509 - val_accuracy: 0.6716 - val_loss: 1.3505 - learning_rate: 3.9063e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7925 - loss: 0.6591\n",
      "Epoch 67: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.7924 - loss: 0.6588 - val_accuracy: 0.6728 - val_loss: 1.3522 - learning_rate: 3.9063e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7911 - loss: 0.6488\n",
      "Epoch 68: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7912 - loss: 0.6488 - val_accuracy: 0.6728 - val_loss: 1.3514 - learning_rate: 1.9531e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7872 - loss: 0.6469\n",
      "Epoch 69: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.7873 - loss: 0.6471 - val_accuracy: 0.6728 - val_loss: 1.3517 - learning_rate: 1.9531e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7918 - loss: 0.6365\n",
      "Epoch 70: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7918 - loss: 0.6369 - val_accuracy: 0.6740 - val_loss: 1.3539 - learning_rate: 1.9531e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7963 - loss: 0.6596\n",
      "Epoch 71: val_loss did not improve from 1.16068\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7962 - loss: 0.6595 - val_accuracy: 0.6740 - val_loss: 1.3515 - learning_rate: 1.9531e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7896 - loss: 0.6531\n",
      "Epoch 72: val_loss did not improve from 1.16068\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.7897 - loss: 0.6530 - val_accuracy: 0.6728 - val_loss: 1.3518 - learning_rate: 1.9531e-06\n",
      "Fold 9 training completed in time: 0:07:27.727384\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "Fold 9 Post-Training Train Accuracy: 0.7932\n",
      "Fold 9 Post-Training Test Accuracy: 0.6507\n",
      "[1.1606833934783936, 0.6507353186607361]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(9)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e48c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7895, 40, 174)\n",
      "(837, 40, 174)\n",
      "(7895, 10)\n",
      "(837, 10)\n",
      "x_train shape: (7895, 40, 174, 1)\n",
      "x_test shape: (837, 40, 174, 1)\n",
      "y_train shape: (7895, 10)\n",
      "y_test shape: (837, 10)\n",
      "\n",
      "Training Fold 10...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TB Pal\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1328 - loss: 2.3114\n",
      "Epoch 1: val_loss improved from inf to 2.11379, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 702ms/step - accuracy: 0.1336 - loss: 2.3097 - val_accuracy: 0.2091 - val_loss: 2.1138 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2473 - loss: 2.0868\n",
      "Epoch 2: val_loss improved from 2.11379 to 1.74427, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.2484 - loss: 2.0836 - val_accuracy: 0.3787 - val_loss: 1.7443 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.3708 - loss: 1.7373\n",
      "Epoch 3: val_loss improved from 1.74427 to 1.53705, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 622ms/step - accuracy: 0.3712 - loss: 1.7359 - val_accuracy: 0.5233 - val_loss: 1.5371 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4272 - loss: 1.5671\n",
      "Epoch 4: val_loss improved from 1.53705 to 1.45456, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 689ms/step - accuracy: 0.4276 - loss: 1.5665 - val_accuracy: 0.5293 - val_loss: 1.4546 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4718 - loss: 1.4855\n",
      "Epoch 5: val_loss improved from 1.45456 to 1.37379, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.4720 - loss: 1.4845 - val_accuracy: 0.5412 - val_loss: 1.3738 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5118 - loss: 1.3714\n",
      "Epoch 6: val_loss improved from 1.37379 to 1.32108, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 642ms/step - accuracy: 0.5119 - loss: 1.3709 - val_accuracy: 0.5388 - val_loss: 1.3211 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5428 - loss: 1.3074\n",
      "Epoch 7: val_loss improved from 1.32108 to 1.31138, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.5430 - loss: 1.3070 - val_accuracy: 0.5795 - val_loss: 1.3114 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5486 - loss: 1.2718\n",
      "Epoch 8: val_loss improved from 1.31138 to 1.25602, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 660ms/step - accuracy: 0.5488 - loss: 1.2711 - val_accuracy: 0.5699 - val_loss: 1.2560 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5662 - loss: 1.2300\n",
      "Epoch 9: val_loss did not improve from 1.25602\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.5663 - loss: 1.2294 - val_accuracy: 0.5950 - val_loss: 1.2842 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5859 - loss: 1.1786\n",
      "Epoch 10: val_loss did not improve from 1.25602\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.5860 - loss: 1.1783 - val_accuracy: 0.5747 - val_loss: 1.2777 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6046 - loss: 1.1436\n",
      "Epoch 11: val_loss improved from 1.25602 to 1.19835, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 0.6045 - loss: 1.1432 - val_accuracy: 0.6153 - val_loss: 1.1983 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6251 - loss: 1.0874\n",
      "Epoch 12: val_loss did not improve from 1.19835\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.6249 - loss: 1.0873 - val_accuracy: 0.5818 - val_loss: 1.2387 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6229 - loss: 1.0780\n",
      "Epoch 13: val_loss improved from 1.19835 to 1.17640, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 642ms/step - accuracy: 0.6229 - loss: 1.0781 - val_accuracy: 0.6213 - val_loss: 1.1764 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6201 - loss: 1.0587\n",
      "Epoch 14: val_loss improved from 1.17640 to 1.14859, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.6203 - loss: 1.0586 - val_accuracy: 0.6308 - val_loss: 1.1486 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6539 - loss: 1.0167\n",
      "Epoch 15: val_loss improved from 1.14859 to 1.13217, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 620ms/step - accuracy: 0.6536 - loss: 1.0170 - val_accuracy: 0.6284 - val_loss: 1.1322 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6538 - loss: 0.9916\n",
      "Epoch 16: val_loss did not improve from 1.13217\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.6537 - loss: 0.9916 - val_accuracy: 0.6141 - val_loss: 1.1755 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6504 - loss: 0.9942\n",
      "Epoch 17: val_loss did not improve from 1.13217\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6506 - loss: 0.9938 - val_accuracy: 0.6452 - val_loss: 1.1597 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6717 - loss: 0.9581\n",
      "Epoch 18: val_loss improved from 1.13217 to 1.10391, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.6716 - loss: 0.9578 - val_accuracy: 0.6452 - val_loss: 1.1039 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6743 - loss: 0.9418\n",
      "Epoch 19: val_loss improved from 1.10391 to 1.09827, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.6744 - loss: 0.9415 - val_accuracy: 0.6511 - val_loss: 1.0983 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6966 - loss: 0.8734\n",
      "Epoch 20: val_loss improved from 1.09827 to 1.08844, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.6963 - loss: 0.8740 - val_accuracy: 0.6308 - val_loss: 1.0884 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.6937 - loss: 0.8919\n",
      "Epoch 21: val_loss improved from 1.08844 to 1.08473, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.6935 - loss: 0.8921 - val_accuracy: 0.6368 - val_loss: 1.0847 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6970 - loss: 0.8736\n",
      "Epoch 22: val_loss improved from 1.08473 to 1.07344, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.6972 - loss: 0.8732 - val_accuracy: 0.6571 - val_loss: 1.0734 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7050 - loss: 0.8419\n",
      "Epoch 23: val_loss did not improve from 1.07344\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.7050 - loss: 0.8421 - val_accuracy: 0.6296 - val_loss: 1.1696 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7048 - loss: 0.8577\n",
      "Epoch 24: val_loss did not improve from 1.07344\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7049 - loss: 0.8572 - val_accuracy: 0.6631 - val_loss: 1.0923 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7204 - loss: 0.8221\n",
      "Epoch 25: val_loss improved from 1.07344 to 1.04288, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.7204 - loss: 0.8220 - val_accuracy: 0.6810 - val_loss: 1.0429 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7281 - loss: 0.8135\n",
      "Epoch 26: val_loss did not improve from 1.04288\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.7280 - loss: 0.8132 - val_accuracy: 0.6643 - val_loss: 1.1115 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7128 - loss: 0.8284\n",
      "Epoch 27: val_loss did not improve from 1.04288\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.7134 - loss: 0.8274 - val_accuracy: 0.6535 - val_loss: 1.0684 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7249 - loss: 0.8068\n",
      "Epoch 28: val_loss did not improve from 1.04288\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.7248 - loss: 0.8068 - val_accuracy: 0.6535 - val_loss: 1.0469 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7375 - loss: 0.7718\n",
      "Epoch 29: val_loss improved from 1.04288 to 1.03488, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.7374 - loss: 0.7720 - val_accuracy: 0.6822 - val_loss: 1.0349 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7376 - loss: 0.7606\n",
      "Epoch 30: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.7377 - loss: 0.7606 - val_accuracy: 0.6667 - val_loss: 1.0728 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7475 - loss: 0.7363\n",
      "Epoch 31: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.7476 - loss: 0.7363 - val_accuracy: 0.6930 - val_loss: 1.0665 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7651 - loss: 0.7201\n",
      "Epoch 32: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.7650 - loss: 0.7199 - val_accuracy: 0.6882 - val_loss: 1.0940 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7525 - loss: 0.7300\n",
      "Epoch 33: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - accuracy: 0.7526 - loss: 0.7301 - val_accuracy: 0.6595 - val_loss: 1.1412 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7631 - loss: 0.6983\n",
      "Epoch 34: val_loss did not improve from 1.03488\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.7629 - loss: 0.6987 - val_accuracy: 0.6870 - val_loss: 1.1555 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7716 - loss: 0.6792\n",
      "Epoch 35: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.7716 - loss: 0.6793 - val_accuracy: 0.6798 - val_loss: 1.0718 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7675 - loss: 0.6883\n",
      "Epoch 36: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.7677 - loss: 0.6880 - val_accuracy: 0.6726 - val_loss: 1.0946 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7766 - loss: 0.6467\n",
      "Epoch 37: val_loss did not improve from 1.03488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.7766 - loss: 0.6474 - val_accuracy: 0.6882 - val_loss: 1.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7807 - loss: 0.6584\n",
      "Epoch 38: val_loss improved from 1.03488 to 1.02055, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.7807 - loss: 0.6586 - val_accuracy: 0.7025 - val_loss: 1.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7921 - loss: 0.6272\n",
      "Epoch 39: val_loss improved from 1.02055 to 1.00266, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7915 - loss: 0.6282 - val_accuracy: 0.6941 - val_loss: 1.0027 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7818 - loss: 0.6577\n",
      "Epoch 40: val_loss improved from 1.00266 to 0.99401, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.7818 - loss: 0.6577 - val_accuracy: 0.6846 - val_loss: 0.9940 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7801 - loss: 0.6618\n",
      "Epoch 41: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.7801 - loss: 0.6616 - val_accuracy: 0.6894 - val_loss: 1.0185 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7868 - loss: 0.6386\n",
      "Epoch 42: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7868 - loss: 0.6386 - val_accuracy: 0.7097 - val_loss: 1.0129 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7943 - loss: 0.6187\n",
      "Epoch 43: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.7944 - loss: 0.6188 - val_accuracy: 0.7097 - val_loss: 1.0104 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7921 - loss: 0.6214\n",
      "Epoch 44: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.7922 - loss: 0.6217 - val_accuracy: 0.6989 - val_loss: 1.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7948 - loss: 0.6136\n",
      "Epoch 45: val_loss did not improve from 0.99401\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.7947 - loss: 0.6142 - val_accuracy: 0.6822 - val_loss: 1.1234 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7830 - loss: 0.6253\n",
      "Epoch 46: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.7832 - loss: 0.6253 - val_accuracy: 0.6894 - val_loss: 1.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7987 - loss: 0.6045\n",
      "Epoch 47: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.7988 - loss: 0.6043 - val_accuracy: 0.6918 - val_loss: 1.0411 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8045 - loss: 0.6052\n",
      "Epoch 48: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8044 - loss: 0.6051 - val_accuracy: 0.6965 - val_loss: 1.0506 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8031 - loss: 0.5915\n",
      "Epoch 49: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8031 - loss: 0.5916 - val_accuracy: 0.6965 - val_loss: 1.0192 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8042 - loss: 0.5997\n",
      "Epoch 50: val_loss did not improve from 0.99401\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8043 - loss: 0.5996 - val_accuracy: 0.7049 - val_loss: 1.0192 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8051 - loss: 0.5974\n",
      "Epoch 51: val_loss did not improve from 0.99401\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8051 - loss: 0.5973 - val_accuracy: 0.7049 - val_loss: 1.0278 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8093 - loss: 0.5771\n",
      "Epoch 52: val_loss improved from 0.99401 to 0.98917, saving model to saved_models/weights.fold10.best.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8092 - loss: 0.5774 - val_accuracy: 0.7073 - val_loss: 0.9892 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8144 - loss: 0.5751\n",
      "Epoch 53: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8142 - loss: 0.5757 - val_accuracy: 0.7061 - val_loss: 1.0274 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8051 - loss: 0.5821\n",
      "Epoch 54: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8052 - loss: 0.5822 - val_accuracy: 0.7025 - val_loss: 1.0113 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8194 - loss: 0.5820\n",
      "Epoch 55: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8193 - loss: 0.5820 - val_accuracy: 0.7001 - val_loss: 1.0044 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8080 - loss: 0.5912\n",
      "Epoch 56: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8080 - loss: 0.5910 - val_accuracy: 0.7085 - val_loss: 0.9994 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8161 - loss: 0.5824\n",
      "Epoch 57: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.8160 - loss: 0.5825 - val_accuracy: 0.7109 - val_loss: 1.0153 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8119 - loss: 0.5678\n",
      "Epoch 58: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8119 - loss: 0.5680 - val_accuracy: 0.7085 - val_loss: 0.9990 - learning_rate: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8182 - loss: 0.5771\n",
      "Epoch 59: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8182 - loss: 0.5771 - val_accuracy: 0.7109 - val_loss: 1.0026 - learning_rate: 6.2500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8149 - loss: 0.5754\n",
      "Epoch 60: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8150 - loss: 0.5753 - val_accuracy: 0.7097 - val_loss: 1.0073 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8120 - loss: 0.5782\n",
      "Epoch 61: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8120 - loss: 0.5781 - val_accuracy: 0.7061 - val_loss: 1.0059 - learning_rate: 6.2500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8050 - loss: 0.5937\n",
      "Epoch 62: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8052 - loss: 0.5933 - val_accuracy: 0.7013 - val_loss: 1.0212 - learning_rate: 6.2500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8093 - loss: 0.5842\n",
      "Epoch 63: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8095 - loss: 0.5839 - val_accuracy: 0.7061 - val_loss: 1.0115 - learning_rate: 3.1250e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8123 - loss: 0.5614\n",
      "Epoch 64: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8122 - loss: 0.5619 - val_accuracy: 0.7085 - val_loss: 1.0099 - learning_rate: 3.1250e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8200 - loss: 0.5694\n",
      "Epoch 65: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8199 - loss: 0.5695 - val_accuracy: 0.7109 - val_loss: 1.0029 - learning_rate: 3.1250e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8105 - loss: 0.5708\n",
      "Epoch 66: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8105 - loss: 0.5708 - val_accuracy: 0.7097 - val_loss: 1.0117 - learning_rate: 3.1250e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8138 - loss: 0.5631\n",
      "Epoch 67: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.8137 - loss: 0.5635 - val_accuracy: 0.7073 - val_loss: 1.0021 - learning_rate: 3.1250e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8209 - loss: 0.5490\n",
      "Epoch 68: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8209 - loss: 0.5496 - val_accuracy: 0.7097 - val_loss: 1.0066 - learning_rate: 1.5625e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8033 - loss: 0.5922\n",
      "Epoch 69: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8037 - loss: 0.5916 - val_accuracy: 0.7097 - val_loss: 1.0073 - learning_rate: 1.5625e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8117 - loss: 0.5759\n",
      "Epoch 70: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8118 - loss: 0.5757 - val_accuracy: 0.7097 - val_loss: 1.0083 - learning_rate: 1.5625e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8146 - loss: 0.5649\n",
      "Epoch 71: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8147 - loss: 0.5650 - val_accuracy: 0.7085 - val_loss: 1.0056 - learning_rate: 1.5625e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8197 - loss: 0.5646\n",
      "Epoch 72: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.8196 - loss: 0.5647 - val_accuracy: 0.7109 - val_loss: 1.0048 - learning_rate: 1.5625e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8170 - loss: 0.5531\n",
      "Epoch 73: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8167 - loss: 0.5539 - val_accuracy: 0.7097 - val_loss: 1.0081 - learning_rate: 7.8125e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8112 - loss: 0.5801\n",
      "Epoch 74: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 0.8113 - loss: 0.5797 - val_accuracy: 0.7097 - val_loss: 1.0066 - learning_rate: 7.8125e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8074 - loss: 0.5811\n",
      "Epoch 75: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.8077 - loss: 0.5807 - val_accuracy: 0.7097 - val_loss: 1.0022 - learning_rate: 7.8125e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8109 - loss: 0.5788\n",
      "Epoch 76: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.8110 - loss: 0.5788 - val_accuracy: 0.7085 - val_loss: 1.0038 - learning_rate: 7.8125e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8109 - loss: 0.5762\n",
      "Epoch 77: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8109 - loss: 0.5762 - val_accuracy: 0.7109 - val_loss: 1.0055 - learning_rate: 7.8125e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8121 - loss: 0.5842\n",
      "Epoch 78: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8121 - loss: 0.5841 - val_accuracy: 0.7109 - val_loss: 1.0064 - learning_rate: 3.9063e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8234 - loss: 0.5446\n",
      "Epoch 79: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8232 - loss: 0.5453 - val_accuracy: 0.7109 - val_loss: 1.0061 - learning_rate: 3.9063e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8131 - loss: 0.5715\n",
      "Epoch 80: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 0.8132 - loss: 0.5714 - val_accuracy: 0.7085 - val_loss: 1.0058 - learning_rate: 3.9063e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8119 - loss: 0.5759\n",
      "Epoch 81: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.8120 - loss: 0.5759 - val_accuracy: 0.7109 - val_loss: 1.0081 - learning_rate: 3.9063e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8185 - loss: 0.5594\n",
      "Epoch 82: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8184 - loss: 0.5598 - val_accuracy: 0.7109 - val_loss: 1.0079 - learning_rate: 3.9063e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8087 - loss: 0.5701\n",
      "Epoch 83: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.8088 - loss: 0.5701 - val_accuracy: 0.7097 - val_loss: 1.0071 - learning_rate: 1.9531e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8079 - loss: 0.5776\n",
      "Epoch 84: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - accuracy: 0.8081 - loss: 0.5775 - val_accuracy: 0.7109 - val_loss: 1.0059 - learning_rate: 1.9531e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8078 - loss: 0.5603\n",
      "Epoch 85: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8078 - loss: 0.5609 - val_accuracy: 0.7109 - val_loss: 1.0058 - learning_rate: 1.9531e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8061 - loss: 0.5927\n",
      "Epoch 86: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8063 - loss: 0.5924 - val_accuracy: 0.7097 - val_loss: 1.0067 - learning_rate: 1.9531e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8143 - loss: 0.5708\n",
      "Epoch 87: val_loss did not improve from 0.98917\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8144 - loss: 0.5708 - val_accuracy: 0.7085 - val_loss: 1.0055 - learning_rate: 1.9531e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.8126 - loss: 0.5640\n",
      "Epoch 88: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.8125 - loss: 0.5643 - val_accuracy: 0.7097 - val_loss: 1.0060 - learning_rate: 1.0000e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8190 - loss: 0.5696\n",
      "Epoch 89: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8189 - loss: 0.5696 - val_accuracy: 0.7097 - val_loss: 1.0060 - learning_rate: 1.0000e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8084 - loss: 0.5683\n",
      "Epoch 90: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.8085 - loss: 0.5683 - val_accuracy: 0.7097 - val_loss: 1.0056 - learning_rate: 1.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8178 - loss: 0.5693\n",
      "Epoch 91: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8177 - loss: 0.5693 - val_accuracy: 0.7097 - val_loss: 1.0062 - learning_rate: 1.0000e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8129 - loss: 0.5741\n",
      "Epoch 92: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8130 - loss: 0.5740 - val_accuracy: 0.7097 - val_loss: 1.0062 - learning_rate: 1.0000e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8254 - loss: 0.5580\n",
      "Epoch 93: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.8250 - loss: 0.5586 - val_accuracy: 0.7097 - val_loss: 1.0063 - learning_rate: 1.0000e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8180 - loss: 0.5747\n",
      "Epoch 94: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.8180 - loss: 0.5746 - val_accuracy: 0.7097 - val_loss: 1.0061 - learning_rate: 1.0000e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8107 - loss: 0.5722\n",
      "Epoch 95: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.8108 - loss: 0.5722 - val_accuracy: 0.7097 - val_loss: 1.0060 - learning_rate: 1.0000e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8145 - loss: 0.5710\n",
      "Epoch 96: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - accuracy: 0.8144 - loss: 0.5711 - val_accuracy: 0.7097 - val_loss: 1.0063 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8147 - loss: 0.5706\n",
      "Epoch 97: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.8148 - loss: 0.5703 - val_accuracy: 0.7097 - val_loss: 1.0065 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8156 - loss: 0.5655\n",
      "Epoch 98: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.8155 - loss: 0.5657 - val_accuracy: 0.7097 - val_loss: 1.0071 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8144 - loss: 0.5704\n",
      "Epoch 99: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - accuracy: 0.8144 - loss: 0.5704 - val_accuracy: 0.7097 - val_loss: 1.0062 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8115 - loss: 0.5624\n",
      "Epoch 100: val_loss did not improve from 0.98917\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8116 - loss: 0.5624 - val_accuracy: 0.7097 - val_loss: 1.0064 - learning_rate: 1.0000e-06\n",
      "Fold 10 training completed in time: 0:10:34.276915\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Fold 10 Post-Training Train Accuracy: 0.8148\n",
      "Fold 10 Post-Training Test Accuracy: 0.7073\n",
      "[0.9891705513000488, 0.7072879076004028]\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = run_fold(10)\n",
    "train_accuracies.append(train_accuracy)\n",
    "fold_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 11), train_accuracies, 'x-', label=\"Train Acc\")\n",
    "plt.plot(range(1, 11), fold_accuracies, 'o-', label=\"Test Acc\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"10-Fold Cross-Validation Accuracies\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train Accuracies:\", train_accuracies)\n",
    "print(\"Test Accuracies:\", fold_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff481d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final metrics\n",
    "print(f\"\\nAverage Training Accuracy over 10 folds: {np.mean(train_accuracies):.4f}\")\n",
    "print(f\"Average Test Accuracy over 10 folds: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Training Accuracies for each fold: {train_accuracies}\")\n",
    "print(f\"Test Accuracies for each fold: {fold_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_path, model_path='saved_models/urban_sound_model_fold1.keras'):\n",
    "    model = load_model(model_path)\n",
    "    feature = extract_features(file_path)\n",
    "\n",
    "    if feature is None:\n",
    "        print(\"Error extracting features.\")\n",
    "        return\n",
    "\n",
    "    feature = feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    prediction = model.predict(feature)[0]  # shape: (num_classes,)\n",
    "\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_class = le.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class}\\n\")\n",
    "\n",
    "    print(\"Class probabilities:\")\n",
    "    class_labels = le.classes_\n",
    "    for i, prob in enumerate(prediction):\n",
    "        label = class_labels[i]\n",
    "        print(f\"{str(label):20s}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_across_folds(file_path, output_file=\"fold_predictions.txt\"):\n",
    "    feature = extract_features(file_path)\n",
    "    if feature is None:\n",
    "        print(\"Error extracting features.\")\n",
    "        return\n",
    "\n",
    "    feature = feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "    all_predictions = []\n",
    "\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(f\"Predictions for audio file: {file_path}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "        for fold in range(1, 11):\n",
    "            model_path = f\"saved_models/urban_sound_model_fold{fold}.final.keras\"\n",
    "            try:\n",
    "                model = load_model(model_path)\n",
    "                prediction = model.predict(feature)[0]  # shape: (num_classes,)\n",
    "                all_predictions.append(prediction)\n",
    "\n",
    "                predicted_index = np.argmax(prediction)\n",
    "                predicted_class = le.inverse_transform([predicted_index])[0]\n",
    "\n",
    "                f.write(f\"Fold {fold} Prediction: {predicted_class} (class index: {predicted_index})\\n\")\n",
    "            except Exception as e:\n",
    "                f.write(f\"Fold {fold} Prediction Error: {str(e)}\\n\")\n",
    "\n",
    "        if all_predictions:\n",
    "            # Aggregate predictions\n",
    "            avg_prediction = np.mean(all_predictions, axis=0)\n",
    "            final_index = np.argmax(avg_prediction)\n",
    "            final_class = le.inverse_transform([final_index])[0]\n",
    "\n",
    "            f.write(\"\\nAverage Prediction Probabilities:\\n\")\n",
    "            for i, prob in enumerate(avg_prediction):\n",
    "                class_name = le.classes_[i]\n",
    "                f.write(f\"{class_name:20s}: {prob:.4f}\\n\")\n",
    "\n",
    "            f.write(f\"\\nFinal Predicted Class (Avg): {final_class} (class index: {final_index})\\n\")\n",
    "\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "        print(f\"Predictions written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./audio/fold5/100852-0-0-0.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/dog_bark_1.wav\", output_file=\"fold_predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71503e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/weights.fold1.best.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/drilling_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/drilling_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57227ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/gun_shot_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/gun_shot_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1886281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/siren_1.wav', model_path='./saved_models/weights.fold1.best.keras')\n",
    "print_prediction('./EvaluationAudio/siren_1.wav', model_path='./saved_models/urban_sound_model_fold1.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf50824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold6.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold7.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb25674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold8.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ac19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold9.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_prediction('./EvaluationAudio/dog_bark_1.wav', model_path='./saved_models/urban_sound_model_fold10.final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/dog_bark_1.wav\", output_file=\"fold_predictions_dog_bark.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/drilling_1.wav\", output_file=\"fold_predictions_drilling.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/siren_1.wav\", output_file=\"fold_predictions_siren.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_across_folds(\"./EvaluationAudio/gun_shot_1.wav\", output_file=\"fold_predictions_gun_shot.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a2996",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "A custom CNN model was built using Keras with the following structure:\n",
    "\n",
    "1. Conv Layer 1: 24 filters, 5×5 kernel, ReLU, L2 regularization, followed by 3×3 max pooling\n",
    "2. Conv Layer 2: 36 filters, 4×4 kernel, ReLU, L2 regularization, followed by 2×2 max pooling\n",
    "3. Conv Layer 3: 48 filters, 3×3 kernel, ReLU\n",
    "4. GlobalAveragePooling2D\n",
    "5. Dense Layer 1: 60 units, ReLU + Dropout (0.5)\n",
    "6. Output Layer: 10 units (softmax for 10-class classification)\n",
    "\n",
    "---\n",
    "\n",
    "- Loss: Categorical Crossentropy\n",
    "- Optimizer: Adam\n",
    "- Metrics: Accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### Training Details\n",
    "\n",
    "1. **Epochs**: Training is scheduled for **100 epochs**.\n",
    "2. **Batch Size**: Model trained using a batch size of `num_batch_size`.\n",
    "3. **Optimizer**: Adam optimizer used with default learning rate.\n",
    "4. **Loss Function**: Categorical Crossentropy (since it's a multi-class classification task).\n",
    "5. **Callbacks Used**:\n",
    "   - **ModelCheckpoint**: Saves the best weights based on validation loss for each fold and combined run.\n",
    "   - **EarlyStopping**: Monitors `val_loss` with a patience of **50** epochs and restores the best weights.\n",
    "   - **ReduceLROnPlateau**: Reduces learning rate by a factor of 0.5 if `val_loss` plateaus for 3–5 epochs.\n",
    "6. **Class Weights**: Automatically computed from training data to handle **class imbalance** using `compute_class_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d793b45",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### Objective\n",
    "To classify environmental sound categories using MFCC features and a Convolutional Neural Network. We use both **10-fold cross-validation** and **combined training** on the full dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Combined Dataset Performance\n",
    "\n",
    "| Metric                | Value       |\n",
    "|-----------------------|-------------|\n",
    "| Final Train Accuracy  | **0.8204**  |\n",
    "| Final Test Accuracy   | **0.8535**  |\n",
    "| Final Test Loss       | **0.5304**  |\n",
    "\n",
    "**Interpretation**:\n",
    "- The combined model achieves **85.35% test accuracy**, indicating strong generalization.\n",
    "- The relatively low loss (0.53) suggests good convergence.\n",
    "- Slight overfitting might be present (train acc: 82.04%).\n",
    "\n",
    "---\n",
    "\n",
    "### 10-Fold Cross-Validation Performance\n",
    "\n",
    "| Fold | Train Accuracy | Test Accuracy | Test Loss |\n",
    "|------|----------------|---------------|-----------|\n",
    "| 1    | 0.8077         | 0.6231        | 1.3709    |\n",
    "| 2    | 0.7501         | 0.6453        | 1.0904    |\n",
    "| 3    | 0.6576         | 0.5135        | 1.5230    |\n",
    "| 4    | 0.7626         | 0.5929        | 1.2102    |\n",
    "| 5    | 0.7977         | 0.6378        | 1.1396    |\n",
    "| 6    | 0.7584         | 0.5200        | 1.4187    |\n",
    "| 7    | 0.8351         | 0.7339        | 0.8124    |\n",
    "| 8    | 0.7234         | 0.5906        | 1.4039    |\n",
    "| 9    | 0.7932         | 0.6507        | 1.1607    |\n",
    "| 10   | 0.8148         | 0.7073        | 0.9892    |\n",
    "\n",
    "#### Average Metrics (10-Fold)\n",
    "- **Average Train Accuracy**: `0.7701`\n",
    "- **Average Test Accuracy**: `0.6215`\n",
    "- **Average Test Loss**: `1.2117`\n",
    "\n",
    "---\n",
    "\n",
    "### Observations\n",
    "\n",
    "1. **Combined Model Outperforms Individual Folds**  \n",
    "   The combined dataset model shows significantly **better accuracy (85.35%)** than the average of individual folds (~62.15%).\n",
    "\n",
    "2. **Variance Across Folds**  \n",
    "   Fold 3 and Fold 6 perform the worst in test accuracy (~51–52%), suggesting possible issues with those data splits (e.g., class imbalance or noisy samples).  \n",
    "   Fold 7 and Fold 10 perform the best with test accuracies of **73.4%** and **70.7%**, respectively.\n",
    "\n",
    "3. **Possible Overfitting**  \n",
    "   Folds like 1, 5, and 10 show a noticeable **train-test gap**, which may point to mild overfitting. Use of dropout and L2 regularization helped.\n",
    "\n",
    "4. **Class Imbalance Handling**  \n",
    "   Use of `compute_class_weight` helped mitigate bias during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
